<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>对比学习综述 | WPIRONMAN</title><meta name="author" content="WP"><meta name="copyright" content="WP"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="对比学习综述：从理论到实践全面解析 引言 对比学习（Contrastive Learning） 是近年来自监督学习领域最重要的突破之一，它通过&quot;拉近正样本、推远负样本&quot;的简单思想，在无需大量标注数据的情况下学习到强大的视觉表示。从2020年的SimCLR、MoCo开始，对比学习在ImageNet等基准上取得了与监督学习相当甚至更好的性能，彻底改变了我们对无监督表示学习的认知。"><meta property="og:type" content="article"><meta property="og:title" content="对比学习综述"><meta property="og:url" content="https://wp-a.github.io/2025/11/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/index.html"><meta property="og:site_name" content="WPIRONMAN"><meta property="og:description" content="对比学习综述：从理论到实践全面解析 引言 对比学习（Contrastive Learning） 是近年来自监督学习领域最重要的突破之一，它通过&quot;拉近正样本、推远负样本&quot;的简单思想，在无需大量标注数据的情况下学习到强大的视觉表示。从2020年的SimCLR、MoCo开始，对比学习在ImageNet等基准上取得了与监督学习相当甚至更好的性能，彻底改变了我们对无监督表示学习的认知。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://wpironman.oss-cn-qingdao.aliyuncs.com/1.webp"><meta property="article:published_time" content="2025-11-13T10:52:23.000Z"><meta property="article:modified_time" content="2025-11-23T14:26:13.839Z"><meta property="article:author" content="WP"><meta property="article:tag" content="自监督学习"><meta property="article:tag" content="对比学习"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="无监督学习"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://wpironman.oss-cn-qingdao.aliyuncs.com/1.webp"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "对比学习综述",
  "url": "https://wp-a.github.io/2025/11/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/",
  "image": "https://wpironman.oss-cn-qingdao.aliyuncs.com/1.webp",
  "datePublished": "2025-11-13T10:52:23.000Z",
  "dateModified": "2025-11-23T14:26:13.839Z",
  "author": [
    {
      "@type": "Person",
      "name": "WP",
      "url": "https://wp-a.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="https://wpironman.oss-cn-qingdao.aliyuncs.com/favicon.png"><link rel="canonical" href="https://wp-a.github.io/2025/11/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/index.html"><link rel="preconnect" href="//cdnjs.cloudflare.com"><link rel="preconnect" href="//fonts.googleapis.com" crossorigin=""><link rel="manifest" href="/null"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css"><script>(()=>{var e={set:(e,t,a)=>{a&&(a=Date.now()+864e5*a,localStorage.setItem(e,JSON.stringify({value:t,expiry:a})))},get:e=>{var t=localStorage.getItem(e);if(t){var{value:t,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return t;localStorage.removeItem(e)}}},t=(window.btf={saveToLocal:e,getScript:(o,n={})=>new Promise((e,t)=>{let a=document.createElement("script");a.src=o,a.async=!0,Object.entries(n).forEach(([e,t])=>a.setAttribute(e,t)),a.onload=a.onreadystatechange=()=>{a.readyState&&!/loaded|complete/.test(a.readyState)||e()},a.onerror=t,document.head.appendChild(a)}),getCSS:(o,n)=>new Promise((e,t)=>{let a=document.createElement("link");a.rel="stylesheet",a.href=o,n&&(a.id=n),a.onload=a.onreadystatechange=()=>{a.readyState&&!/loaded|complete/.test(a.readyState)||e()},a.onerror=t,document.head.appendChild(a)}),addGlobalFn:(e,t,a=!1,o=window)=>{var n=o.globalFn||{};n[e]=n[e]||{},n[e][a||Object.keys(n[e]).length]=t,o.globalFn=n}},()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")}),a=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")},o=(btf.activateDarkMode=t,btf.activateLightMode=a,e.get("theme")),t=("dark"===o?t():"light"===o&&a(),e.get("aside-status"));void 0!==t&&document.documentElement.classList.toggle("hide-aside","hide"===t);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Roboto+Slab&amp;display=swap" media="print" onload="this.media=&quot;all&quot;"><script>let GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.json",preload:!1,top_n_per_article:1,unescape:!1,languages:{hits_empty:"未找到符合您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:void 0,highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1,highlightFullpage:!1,highlightMacStyle:!0},copy:{success:"复制成功",error:"复制失败",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"null",Snackbar:void 0,infinitegrid:{js:"https://cdnjs.cloudflare.com/ajax/libs/egjs-infinitegrid/4.12.0/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!0,islazyloadPlugin:!1,isAnchor:!0,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"对比学习综述",isHighlightShrink:!1,isToc:!0,pageType:"post"}</script><link rel="stylesheet" href="/css/_custom/category/categories.css"><link rel="stylesheet" href="/css/categories.css"><link rel="stylesheet" href="/css/valine.css"><link rel="stylesheet" href="/css/mobile-optimize.css"><link rel="stylesheet" href="/css/transpancy.css"><link href="https://fonts.loli.net/css2?family=Noto+Sans+SC&amp;family=JetBrains+Mono&amp;display=swap" rel="stylesheet"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Roboto+Slab&amp;display=swap" media="print" onload="this.media=&quot;all&quot;"><script>fetch("https://wpironman.top/pv").then(e=>e.json()).then(e=>{document.getElementById("my-pv").innerText=e.pv}).catch(()=>{document.getElementById("my-pv").innerText="获取失败"})</script><link rel="preload" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" as="style" onload="this.rel=&quot;stylesheet&quot;"><link href="https://wpironman.oss-cn-qingdao.aliyuncs.com/1.webp" as="image" crossorigin="anonymous"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image:url(https://wpironman.oss-cn-qingdao.aliyuncs.com/10year.webp)"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://wpironman.oss-cn-qingdao.aliyuncs.com/head.png" onerror="this.onerror=null,this.src=&quot;https://wpironman.oss-cn-qingdao.aliyuncs.com/head.gif&quot;" alt="avatar" loading="lazy"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">36</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">73</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">11</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/construction-detection/"><i class="fa-fw fas fa-hard-hat"></i><span> 工地检测</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-user-group"></i><span> 友链</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fa-solid fa-user-tie"></i><span> 本站友链</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i><span> 随机开往</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://travel.moe/go.html?travel=on"><i class="fa-fw fa fa-taxi"></i><span> 异次元之旅</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/academic/"><i class="fa-fw fas fa-graduation-cap"></i><span> 学术主页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://wpironman.oss-cn-qingdao.aliyuncs.com/1.webp)"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/favicon.png" alt="Logo" loading="lazy"><span class="site-name">WPIRONMAN</span></a><a class="nav-page-title" href="/"><span class="site-name">对比学习综述</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/construction-detection/"><i class="fa-fw fas fa-hard-hat"></i><span> 工地检测</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-user-group"></i><span> 友链</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fa-solid fa-user-tie"></i><span> 本站友链</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i><span> 随机开往</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://travel.moe/go.html?travel=on"><i class="fa-fw fa fa-taxi"></i><span> 异次元之旅</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/academic/"><i class="fa-fw fas fa-graduation-cap"></i><span> 学术主页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">对比学习综述<a class="post-edit-link" href="null_posts/对比学习综述.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2025-11-13T10:52:23.000Z" title="发表于 2025-11-13 18:52:23">2025-11-13</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">论文精读</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">7.6k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>26分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1>对比学习综述：从理论到实践全面解析</h1><h2 id="引言">引言</h2><p><strong>对比学习（Contrastive Learning）</strong> 是近年来自监督学习领域最重要的突破之一，它通过"拉近正样本、推远负样本"的简单思想，在无需大量标注数据的情况下学习到强大的视觉表示。从2020年的SimCLR、MoCo开始，对比学习在ImageNet等基准上取得了与监督学习相当甚至更好的性能，彻底改变了我们对无监督表示学习的认知。</p><p>对比学习的核心优势在于：</p><ul><li><strong>无需标注数据</strong>：可以在海量无标注图像上预训练</li><li><strong>学习鲁棒表示</strong>：对数据增强、噪声等具有强鲁棒性</li><li><strong>迁移能力强</strong>：预训练的特征在下游任务上表现优异</li><li><strong>可扩展性好</strong>：可以轻松扩展到大规模数据和模型</li></ul><h2 id="什么是对比学习？">什么是对比学习？</h2><h3 id="核心思想">核心思想</h3><p>对比学习的核心思想可以用一句话概括：<strong>通过对比正样本对和负样本对，学习到区分性的表示</strong>。</p><p><strong>正样本对（Positive Pairs）</strong>：应该相似的样本对</p><ul><li>无监督：同一图像的不同增强视图</li><li>有监督：同一类别的不同样本</li></ul><p><strong>负样本对（Negative Pairs）</strong>：应该不相似的样本对</p><ul><li>无监督：不同图像的增强视图</li><li>有监督：不同类别的样本</li></ul><p><strong>学习目标</strong>：让模型学习到的特征空间中，正样本对的距离近，负样本对的距离远。</p><h3 id="为什么需要对比学习？">为什么需要对比学习？</h3><p><strong>1. 标注数据稀缺问题</strong></p><ul><li>获取大规模标注数据成本高昂（ImageNet标注花费数百万美元）</li><li>很多领域缺乏专家标注（医疗、卫星图像等）</li><li>标注质量难以保证，存在标注噪声</li></ul><p><strong>2. 自监督学习的优势</strong></p><ul><li>利用数据自身的结构作为监督信号</li><li>可以在海量无标注数据上预训练</li><li>学习到的特征更通用，迁移性更好</li></ul><p><strong>3. 对比学习的独特价值</strong></p><ul><li><strong>判别性强</strong>：通过对比学习到的特征比重建任务（如自编码器）更有判别性</li><li><strong>计算高效</strong>：比生成模型（GAN、VAE）训练更稳定、收敛更快</li><li><strong>理论基础</strong>：有信息论的理论支撑（互信息最大化）</li></ul><h3 id="对比学习的工作原理">对比学习的工作原理</h3><p><strong>核心机制详解</strong>：</p><ol><li><p><strong>正负样本构造</strong></p><ul><li><strong>正样本对</strong>：同一图像通过不同数据增强得到的两个视图</li><li><strong>负样本对</strong>：来自不同图像的视图</li><li><strong>关键点</strong>：正样本共享语义信息，负样本语义不同</li></ul></li><li><p><strong>特征提取流程</strong></p></li><li><p><strong>特征提取流程</strong></p><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A[输入图像] --&gt; B[数据增强]</span><br><span class="line">B --&gt; C[编码器]</span><br><span class="line">C --&gt; D[特征向量]</span><br><span class="line">D --&gt; E[投影头]</span><br><span class="line">E --&gt; F[对比损失]</span><br></pre></td></tr></tbody></table></figure><ul><li>编码器：提取高维语义特征（如ResNet输出2048维）</li><li>投影头：映射到低维空间（通常128维），便于计算相似度</li></ul></li><li><p><strong>相似度计算</strong></p><ul><li>使用余弦相似度：$sim(z_i, z_j) = \frac{z_i \cdot z_j}{||z_i|| \cdot ||z_j||}$</li><li>温度缩放：$sim(z_i, z_j) / \tau$，控制分布的集中程度</li></ul></li><li><p><strong>优化目标</strong></p><ul><li>最大化正样本对的相似度</li><li>最小化负样本对的相似度</li><li>通过InfoNCE损失实现这一目标</li></ul></li></ol><h2 id="对比学习的发展历程">对比学习的发展历程</h2><h3 id="早期工作（2010s）">早期工作（2010s）</h3><ul><li><strong>Triplet Loss</strong>（2015）：最早的形式化对比学习思想</li><li><strong>NCE（Noise Contrastive Estimation）</strong>：从语言模型引入对比思想</li><li><strong>Instance Discrimination</strong>：将每个样本视为一个类别</li></ul><h3 id="现代对比学习（2020-）">现代对比学习（2020-）</h3><ul><li><strong>SimCLR</strong>（2020）：端到端训练，大batch size</li><li><strong>MoCo</strong>（2020）：动量编码器 + 队列机制</li><li><strong>SupCon</strong>（2020）：监督对比学习</li><li><strong>BYOL/SimSiam</strong>（2020-2021）：无需负样本的对比学习</li><li><strong>CLIP</strong>（2021）：跨模态对比学习</li></ul><h2 id="核心损失函数：InfoNCE-NT-Xent">核心损失函数：InfoNCE / NT-Xent</h2><h3 id="InfoNCE损失详解">InfoNCE损失详解</h3><p><strong>损失函数定义</strong>：</p><p>给定一个正样本对 $(x, x^+)$ 和 N-1 个负样本 ${x_i^-}_{i=1}^{N-1}$，InfoNCE损失定义为：</p><p>$$\mathcal{L}<em>{\text{InfoNCE}} = -\log \frac{\exp(sim(x, x^+) / \tau)}{\exp(sim(x, x^+) / \tau) + \sum</em>{i=1}^{N-1} \exp(sim(x, x_i^-) / \tau)}$$</p><p><strong>逐步理解损失函数</strong>：</p><ol><li><p><strong>相似度计算</strong> $sim(x, x^+)$：</p><ul><li>计算查询样本$x$与正样本$x^+$的余弦相似度</li><li>值域：[-1, 1]，1表示完全相同，-1表示完全相反</li></ul></li><li><p><strong>温度缩放</strong> $sim/\tau$：</p><ul><li>$\tau$通常设置为0.07-0.5</li><li>较小的$\tau$让模型更关注困难负样本</li><li>较大的$\tau$让优化更平滑</li></ul></li><li><p><strong>Softmax归一化</strong>：</p><ul><li>将相似度转换为概率分布</li><li>正样本的"概率"应该接近1</li><li>每个负样本的"概率"应该接近0</li></ul></li><li><p><strong>负对数似然</strong>：</p><ul><li>最小化损失 = 最大化正样本的概率</li><li>这等价于N分类问题，正确类别是正样本</li></ul></li></ol><p><strong>为什么InfoNCE有效？</strong></p><ul><li>归一化：特征先进行L2归一化</li><li>温度缩放：$\tau$ 控制softmax分布的尖锐程度</li></ul><h3 id="温度参数-tau-的作用">温度参数 $\tau$ 的作用</h3><p>温度参数 $\tau$ 是对比学习中的关键超参数：</p><ul><li><p><strong>$\tau$ 较小（如0.05）</strong>：</p><ul><li>分布更尖锐，模型更关注困难负样本</li><li>学习到的表示区分性更强</li><li>但可能训练不稳定</li></ul></li><li><p><strong>$\tau$ 较大（如0.2）</strong>：</p><ul><li>分布更平滑，对所有样本的关注更均匀</li><li>训练更稳定</li><li>但区分性可能较弱</li></ul></li><li><p><strong>典型取值</strong>：0.07（SimCLR、MoCo等常用）</p></li></ul><h2 id="主要方法详解">主要方法详解</h2><h3 id="1-SimCLR（A-Simple-Framework-for-Contrastive-Learning）">1. SimCLR（A Simple Framework for Contrastive Learning）</h3><p><strong>论文</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2002.05709">https://arxiv.org/pdf/2002.05709</a><br><strong>代码</strong>：<a target="_blank" rel="noopener" href="https://github.com/google-research/simclr">https://github.com/google-research/simclr</a></p><h4 id="核心思想-2">核心思想</h4><p>SimCLR提出了一个简单而有效的对比学习框架：</p><ol><li>对每个样本应用两次随机增强，得到两个视图</li><li>使用共享编码器提取特征</li><li>通过投影头映射到对比空间</li><li>使用NT-Xent损失进行对比学习</li></ol><h4 id="关键创新">关键创新</h4><ol><li><strong>强数据增强</strong>：发现数据增强是对比学习成功的关键</li><li><strong>投影头</strong>：在编码器和损失之间加入非线性投影头</li><li><strong>大batch size</strong>：需要大量负样本（batch size ≥ 4096）</li></ol><h4 id="架构">架构</h4><h4 id="架构-2">架构</h4><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    subgraph SimCLR架构</span><br><span class="line">    I[输入图像] --&gt; T1[增强视图 1]</span><br><span class="line">    I --&gt; T2[增强视图 2]</span><br><span class="line">    T1 --&gt; E1[编码器 f]</span><br><span class="line">    T2 --&gt; E2[编码器 f]</span><br><span class="line">    E1 --&gt; H1[投影头 g]</span><br><span class="line">    E2 --&gt; H2[投影头 g]</span><br><span class="line">    H1 --&gt; Z1[特征 z1]</span><br><span class="line">    H2 --&gt; Z2[特征 z2]</span><br><span class="line">    Z1 &lt;--&gt; L[对比损失]</span><br><span class="line">    Z2 &lt;--&gt; L</span><br><span class="line">    end</span><br></pre></td></tr></tbody></table></figure><h4 id="优缺点">优缺点</h4><p><strong>优点</strong>：</p><ul><li>框架简单，易于实现</li><li>端到端训练，无需额外机制</li><li>性能优异</li></ul><p><strong>缺点</strong>：</p><ul><li>需要大batch size，对计算资源要求高</li><li>对数据增强策略敏感</li></ul><h3 id="2-MoCo（Momentum-Contrast）">2. MoCo（Momentum Contrast）</h3><p><strong>论文</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1911.05722">https://arxiv.org/pdf/1911.05722</a><br><strong>代码</strong>：<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/moco">https://github.com/facebookresearch/moco</a></p><h4 id="核心思想-3">核心思想</h4><p>MoCo将对比学习看作<strong>字典查找</strong>任务：</p><ul><li>Query：当前样本的编码</li><li>Key：字典中的样本编码</li><li>目标：Query与匹配的Key相似，与其他Key不相似</li></ul><h4 id="关键创新-2">关键创新</h4><ol><li><strong>动量编码器</strong>：使用动量更新维护一个缓慢变化的编码器</li><li><strong>队列机制</strong>：用队列存储历史样本的特征，提供大量负样本</li><li><strong>一致性</strong>：动量更新保证字典中Key的一致性</li></ol><h4 id="架构-3">架构</h4><h4 id="架构-4">架构</h4><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    subgraph MoCo架构</span><br><span class="line">    Q[Query图像] --&gt; EQ[编码器]</span><br><span class="line">    EQ --&gt; QF[Query特征]</span><br><span class="line">    K[Key图像] --&gt; EK[动量编码器]</span><br><span class="line">    EK --&gt; KF[Key特征]</span><br><span class="line">    KF --&gt; Que[队列 Dictionary]</span><br><span class="line">    QF &lt;--&gt; Loss[对比损失]</span><br><span class="line">    Que &lt;--&gt; Loss</span><br><span class="line">    end</span><br></pre></td></tr></tbody></table></figure><h4 id="优缺点-2">优缺点</h4><p><strong>优点</strong>：</p><ul><li>不依赖大batch size</li><li>训练稳定，收敛快</li><li>内存效率高</li></ul><p><strong>缺点</strong>：</p><ul><li>实现相对复杂</li><li>需要维护队列和动量编码器</li></ul><h3 id="3-SupCon（Supervised-Contrastive-Learning）">3. SupCon（Supervised Contrastive Learning）</h3><p><strong>论文</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2004.11362">https://arxiv.org/pdf/2004.11362</a><br><strong>代码</strong>：<a target="_blank" rel="noopener" href="https://github.com/HobbitLong/SupContrast">https://github.com/HobbitLong/SupContrast</a></p><h4 id="核心思想-4">核心思想</h4><p>将标签信息融入对比学习：</p><ul><li><strong>正样本</strong>：同一类别的所有样本</li><li><strong>负样本</strong>：不同类别的样本</li></ul><h4 id="损失函数">损失函数</h4><p>$$<br>\mathcal{L}<em>{sup}^i = -\frac{1}{|P(i)|} \sum</em>{p \in P(i)} \log \frac{\exp(z_i \cdot z_p / \tau)}{\sum_{a \in A(i)} \exp(z_i \cdot z_a / \tau)}<br>$$</p><p>其中 $P(i)$ 是与样本 $i$ 同类的样本集合。</p><h4 id="优缺点-3">优缺点</h4><p><strong>优点</strong>：</p><ul><li>利用标签信息，性能更优</li><li>鲁棒性显著提升</li><li>在长尾学习、少样本学习上表现优异</li></ul><p><strong>缺点</strong>：</p><ul><li>需要标注数据</li><li>计算复杂度较高（$O(N^2)$）</li></ul><h3 id="4-BYOL-SimSiam（无需负样本）">4. BYOL / SimSiam（无需负样本）</h3><p><strong>BYOL论文</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.07733">https://arxiv.org/pdf/2006.07733</a><br><strong>SimSiam论文</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2011.10566">https://arxiv.org/pdf/2011.10566</a></p><h4 id="核心思想-5">核心思想</h4><p>通过<strong>预测任务</strong>替代对比任务，无需负样本：</p><ul><li>一个视图预测另一个视图</li><li>使用停止梯度（stop-gradient）防止崩溃</li></ul><h4 id="关键机制">关键机制</h4><ol><li><strong>预测头</strong>：预测一个视图的特征</li><li><strong>停止梯度</strong>：防止模型学习到平凡解（所有特征相同）</li><li><strong>对称损失</strong>：同时优化两个方向</li></ol><h4 id="优缺点-4">优缺点</h4><p><strong>优点</strong>：</p><ul><li>无需负样本，计算更高效</li><li>训练更稳定</li></ul><p><strong>缺点</strong>：</p><ul><li>理论理解仍在发展中</li><li>性能可能略低于有负样本的方法</li></ul><h3 id="5-SwAV-Swapping-Assignments-between-Views">5. SwAV (Swapping Assignments between Views)</h3><p><strong>论文</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.09882">https://arxiv.org/pdf/2006.09882</a><br><strong>代码</strong>：<a target="_blank" rel="noopener" href="https://github.com/facebookresearch/swav">https://github.com/facebookresearch/swav</a></p><h4 id="核心思想-6">核心思想</h4><p>SwAV 将对比学习与<strong>聚类</strong>相结合。它不直接对比两个视图的特征，而是对比它们在聚类中心的<strong>分配（Assignment）</strong>。</p><ul><li>核心假设：同一图像的两个视图应该属于同一个聚类中心。</li><li>机制：用一个视图的特征去预测另一个视图的聚类分配。</li></ul><h4 id="架构-5">架构</h4><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    subgraph SwAV架构</span><br><span class="line">    I[输入图像] --&gt; V1[视图 1]</span><br><span class="line">    I --&gt; V2[视图 2]</span><br><span class="line">    V1 --&gt; E1[编码器]</span><br><span class="line">    V2 --&gt; E2[编码器]</span><br><span class="line">    E1 --&gt; Z1[特征 Z1]</span><br><span class="line">    E2 --&gt; Z2[特征 Z2]</span><br><span class="line">    Z1 --&gt; P1[原型 Prototypes]</span><br><span class="line">    Z2 --&gt; P2[原型 Prototypes]</span><br><span class="line">    P1 --&gt; C1[聚类分配 Q1]</span><br><span class="line">    P2 --&gt; C2[聚类分配 Q2]</span><br><span class="line">    Z1 -.预测.-&gt; C2</span><br><span class="line">    Z2 -.预测.-&gt; C1</span><br><span class="line">    end</span><br></pre></td></tr></tbody></table></figure><h4 id="优缺点-5">优缺点</h4><ul><li><strong>优点</strong>：无需大量负样本，无需大batch size，训练效率高。</li><li><strong>缺点</strong>：需要在线聚类，实现稍复杂。</li></ul><h3 id="6-CLIP-Contrastive-Language-Image-Pre-training">6. CLIP (Contrastive Language-Image Pre-training)</h3><p><strong>论文</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.00020">https://arxiv.org/pdf/2103.00020</a><br><strong>代码</strong>：<a target="_blank" rel="noopener" href="https://github.com/openai/CLIP">https://github.com/openai/CLIP</a></p><h4 id="核心思想-7">核心思想</h4><p>将对比学习扩展到<strong>多模态</strong>领域。使用海量的（图像，文本）对进行训练。</p><ul><li>正样本：匹配的（图像，文本）对。</li><li>负样本：不匹配的（图像，文本）对。</li></ul><h4 id="架构-6">架构</h4><figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">    subgraph CLIP架构</span><br><span class="line">    Img[图像] --&gt; ImgEnc[图像编码器]</span><br><span class="line">    Txt[文本] --&gt; TxtEnc[文本编码器]</span><br><span class="line">    ImgEnc --&gt; ImgFeat[图像特征]</span><br><span class="line">    TxtEnc --&gt; TxtFeat[文本特征]</span><br><span class="line">    ImgFeat &lt;--&gt; Loss[对比损失]</span><br><span class="line">    TxtFeat &lt;--&gt; Loss</span><br><span class="line">    end</span><br></pre></td></tr></tbody></table></figure><h4 id="影响">影响</h4><p>CLIP 的出现标志着对比学习从单纯的视觉表示学习走向了通用的多模态理解，为后来的 DALL-E、Stable Diffusion 等生成模型奠定了基础。</p><h2 id="技术细节与实践指南">技术细节与实践指南</h2><h3 id="数据增强策略详解">数据增强策略详解</h3><p><strong>核心增强技术</strong>：</p><ol><li><p><strong>随机裁剪（RandomResizedCrop）</strong></p><ul><li>最重要的增强，强制模型学习局部-整体关系</li><li>参数：scale=(0.08, 1.0)，ratio=(0.75, 1.33)</li><li>作用：模拟不同视角和距离</li></ul></li><li><p><strong>颜色抖动（ColorJitter）</strong></p><ul><li>调整亮度、对比度、饱和度、色相</li><li>参数：brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1</li><li>作用：学习颜色不变的特征</li></ul></li><li><p><strong>高斯模糊（GaussianBlur）</strong></p><ul><li>SimCLR发现这是关键增强之一</li><li>参数：kernel_size=图像宽度的1/10，sigma=[0.1, 2.0]</li><li>作用：强制关注高层语义而非纹理细节</li></ul></li><li><p><strong>随机灰度化（RandomGrayscale）</strong></p><ul><li>概率：通常设为0.2</li><li>作用：学习不依赖颜色的形状特征</li></ul></li></ol><p><strong>增强组合的重要性</strong>：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SimCLR推荐的增强pipeline</span></span><br><span class="line">transforms = [</span><br><span class="line">    RandomResizedCrop(<span class="number">224</span>, scale=(<span class="number">0.08</span>, <span class="number">1.0</span>)),</span><br><span class="line">    RandomHorizontalFlip(p=<span class="number">0.5</span>),</span><br><span class="line">    RandomApply([ColorJitter(<span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0.4</span>, <span class="number">0.1</span>)], p=<span class="number">0.8</span>),</span><br><span class="line">    RandomGrayscale(p=<span class="number">0.2</span>),</span><br><span class="line">    RandomApply([GaussianBlur(kernel_size=<span class="number">23</span>)], p=<span class="number">0.5</span>),</span><br><span class="line">    ToTensor(),</span><br><span class="line">    Normalize(mean, std)</span><br><span class="line">]</span><br></pre></td></tr></tbody></table></figure><h3 id="投影头设计原理">投影头设计原理</h3><p><strong>为什么需要投影头？</strong></p><ol><li><p><strong>信息瓶颈作用</strong></p><ul><li>编码器输出包含丰富信息（2048维）</li><li>投影到低维（128维）强制提取关键信息</li><li>防止模型记住无关细节</li></ul></li><li><p><strong>任务分离</strong></p><ul><li>编码器学习通用表示（用于下游任务）</li><li>投影头学习对比特定表示（训练后丢弃）</li><li>保护编码器特征不被对比任务"污染"</li></ul></li><li><p><strong>实验发现</strong></p><ul><li>无投影头：下游任务性能下降约10%</li><li>线性投影头：有改善但不够</li><li>非线性投影头（2层MLP）：最佳性能</li></ul></li></ol><p><strong>投影头架构</strong>：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 典型的投影头设计</span></span><br><span class="line">projection_head = nn.Sequential(</span><br><span class="line">    nn.Linear(<span class="number">2048</span>, <span class="number">2048</span>),  <span class="comment"># 隐藏层</span></span><br><span class="line">    nn.ReLU(),</span><br><span class="line">    nn.Linear(<span class="number">2048</span>, <span class="number">128</span>)    <span class="comment"># 输出层</span></span><br><span class="line">)</span><br></pre></td></tr></tbody></table></figure><h3 id="训练技巧">训练技巧</h3><ol><li><p><strong>学习率</strong>：</p><ul><li>大batch size时使用大学习率（如0.3）</li><li>使用LARS优化器（大batch）或AdamW</li></ul></li><li><p><strong>学习率调度</strong>：</p><ul><li>Cosine annealing</li><li>Warmup（10%的训练步数）</li></ul></li><li><p><strong>Batch Size</strong>：</p><ul><li>SimCLR：≥ 4096</li><li>MoCo：256-1024即可</li><li>SupCon：根据类别数调整</li></ul></li><li><p><strong>训练时长</strong>：</p><ul><li>通常需要较长的训练（100-1000 epochs）</li><li>使用更多数据可以缩短训练时间</li></ul></li></ol><h3 id="特征归一化">特征归一化</h3><p><strong>为什么需要归一化？</strong></p><ul><li>控制特征尺度，避免某些维度 dominate</li><li>使余弦相似度计算有意义</li><li>提高训练稳定性</li></ul><p><strong>归一化方式</strong>：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">z = F.normalize(features, p=<span class="number">2</span>, dim=<span class="number">1</span>)  <span class="comment"># L2归一化</span></span><br></pre></td></tr></tbody></table></figure><h2 id="代码实现">代码实现</h2><h3 id="InfoNCE损失实现">InfoNCE损失实现</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">InfoNCELoss</span>(nn.Module):</span><br><span class="line">    <span class="string">"""InfoNCE损失函数"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, temperature=<span class="number">0.07</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.temperature = temperature</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, z1, z2</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            z1, z2: [batch_size, feature_dim] 归一化后的特征</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            loss: scalar</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        batch_size = z1.size(<span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 合并所有特征</span></span><br><span class="line">        z = torch.cat([z1, z2], dim=<span class="number">0</span>)  <span class="comment"># [2*batch_size, feature_dim]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算相似度矩阵</span></span><br><span class="line">        sim_matrix = torch.mm(z, z.t()) / <span class="variable language_">self</span>.temperature  <span class="comment"># [2*batch_size, 2*batch_size]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 构建正样本mask</span></span><br><span class="line">        labels = torch.arange(batch_size, device=z.device)</span><br><span class="line">        labels = torch.cat([labels + batch_size, labels], dim=<span class="number">0</span>)  <span class="comment"># [2*batch_size]</span></span><br><span class="line">        mask = torch.eq(labels.unsqueeze(<span class="number">1</span>), labels.unsqueeze(<span class="number">0</span>)).<span class="built_in">float</span>()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 移除自身相似度</span></span><br><span class="line">        logits_mask = torch.scatter(</span><br><span class="line">            torch.ones_like(mask),</span><br><span class="line">            <span class="number">1</span>,</span><br><span class="line">            torch.arange(<span class="number">2</span> * batch_size, device=z.device).view(-<span class="number">1</span>, <span class="number">1</span>),</span><br><span class="line">            <span class="number">0</span></span><br><span class="line">        )</span><br><span class="line">        mask = mask * logits_mask</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算exp</span></span><br><span class="line">        exp_logits = torch.exp(sim_matrix) * logits_mask</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算log_prob</span></span><br><span class="line">        log_prob = sim_matrix - torch.log(exp_logits.<span class="built_in">sum</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>) + <span class="number">1e-8</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 平均正样本的log_prob</span></span><br><span class="line">        mean_log_prob_pos = (mask * log_prob).<span class="built_in">sum</span>(<span class="number">1</span>) / mask.<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 损失（取负）</span></span><br><span class="line">        loss = -mean_log_prob_pos.mean()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></tbody></table></figure><h3 id="完整的对比学习训练示例">完整的对比学习训练示例</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ContrastiveModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, encoder, projection_dim=<span class="number">128</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.encoder = encoder</span><br><span class="line">        <span class="comment"># 移除分类头</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(encoder, <span class="string">'fc'</span>):</span><br><span class="line">            <span class="variable language_">self</span>.encoder.fc = nn.Identity()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 投影头</span></span><br><span class="line">        encoder_dim = <span class="number">2048</span>  <span class="comment"># ResNet-50的输出维度</span></span><br><span class="line">        <span class="variable language_">self</span>.projector = nn.Sequential(</span><br><span class="line">            nn.Linear(encoder_dim, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, projection_dim)</span><br><span class="line">        )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        features = <span class="variable language_">self</span>.encoder(x)</span><br><span class="line">        projections = <span class="variable language_">self</span>.projector(features)</span><br><span class="line">        <span class="keyword">return</span> F.normalize(projections, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_contrastive</span>(<span class="params">model, dataloader, num_epochs=<span class="number">100</span></span>):</span><br><span class="line">    criterion = InfoNCELoss(temperature=<span class="number">0.07</span>)</span><br><span class="line">    optimizer = optim.AdamW(model.parameters(), lr=<span class="number">3e-4</span>, weight_decay=<span class="number">0.1</span>)</span><br><span class="line">    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)</span><br><span class="line">    </span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">        <span class="keyword">for</span> batch_idx, (images, _) <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataloader):</span><br><span class="line">            <span class="comment"># 数据增强（假设已经在dataloader中完成）</span></span><br><span class="line">            <span class="comment"># images: [batch_size, 2, C, H, W] (两个增强视图)</span></span><br><span class="line">            batch_size = images.size(<span class="number">0</span>)</span><br><span class="line">            images = images.view(batch_size * <span class="number">2</span>, *images.shape[<span class="number">2</span>:])</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 前向传播</span></span><br><span class="line">            projections = model(images)  <span class="comment"># [2*batch_size, projection_dim]</span></span><br><span class="line">            z1, z2 = projections.chunk(<span class="number">2</span>, dim=<span class="number">0</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算损失</span></span><br><span class="line">            loss = criterion(z1, z2)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 反向传播</span></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f'Epoch <span class="subst">{epoch}</span>, Batch <span class="subst">{batch_idx}</span>, Loss: <span class="subst">{loss.item():<span class="number">.4</span>f}</span>'</span>)</span><br><span class="line">        </span><br><span class="line">        scheduler.step()</span><br></pre></td></tr></tbody></table></figure><h2 id="应用场景">应用场景</h2><h3 id="1-图像分类">1. 图像分类</h3><ul><li><strong>预训练</strong>：在ImageNet等大规模数据集上预训练</li><li><strong>微调</strong>：在下游分类任务上微调编码器</li><li><strong>性能</strong>：可以达到或超越监督预训练的性能</li></ul><h3 id="2-目标检测">2. 目标检测</h3><ul><li><strong>Backbone预训练</strong>：使用对比学习预训练检测器的backbone</li><li><strong>迁移学习</strong>：将预训练特征迁移到检测任务</li><li><strong>性能提升</strong>：显著提升检测精度，特别是少样本场景</li></ul><h3 id="3-语义分割">3. 语义分割</h3><ul><li><strong>特征提取器预训练</strong>：预训练分割网络的特征提取部分</li><li><strong>少样本分割</strong>：在少样本分割任务上表现优异</li></ul><h3 id="4-图像检索">4. 图像检索</h3><ul><li><strong>特征学习</strong>：学习到适合检索的判别性特征</li><li><strong>相似度计算</strong>：直接使用学习到的特征进行检索</li></ul><h3 id="5-长尾学习">5. 长尾学习</h3><ul><li><strong>SupCon优势</strong>：监督对比学习在长尾分布上表现优异</li><li><strong>类间分离</strong>：显式推远异类样本，提高尾部类别性能</li></ul><h2 id="对比学习-vs-其他方法">对比学习 vs 其他方法</h2><h3 id="vs-监督学习">vs. 监督学习</h3><table><thead><tr><th>特性</th><th>监督学习</th><th>对比学习</th></tr></thead><tbody><tr><td>数据需求</td><td>需要大量标注</td><td>无需标注</td></tr><tr><td>表示质量</td><td>任务相关</td><td>通用性强</td></tr><tr><td>鲁棒性</td><td>一般</td><td>更强</td></tr><tr><td>计算成本</td><td>较低</td><td>较高（大batch）</td></tr></tbody></table><h3 id="vs-生成式方法（VAE、GAN）">vs. 生成式方法（VAE、GAN）</h3><table><thead><tr><th>特性</th><th>生成式方法</th><th>对比学习</th></tr></thead><tbody><tr><td>目标</td><td>重建/生成</td><td>表示学习</td></tr><tr><td>训练稳定性</td><td>不稳定</td><td>较稳定</td></tr><tr><td>表示质量</td><td>可能包含无关信息</td><td>更聚焦判别性</td></tr><tr><td>计算效率</td><td>较低</td><td>较高</td></tr></tbody></table><h3 id="vs-自编码器">vs. 自编码器</h3><table><thead><tr><th>特性</th><th>自编码器</th><th>对比学习</th></tr></thead><tbody><tr><td>目标</td><td>重建输入</td><td>区分样本</td></tr><tr><td>表示性质</td><td>可能包含冗余</td><td>更紧凑</td></tr><tr><td>下游任务</td><td>需要额外设计</td><td>直接可用</td></tr></tbody></table><h2 id="扩展领域：NLP中的对比学习">扩展领域：NLP中的对比学习</h2><p>对比学习不仅在CV领域大放异彩，在NLP领域也同样重要。</p><h3 id="SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings">SimCSE (Simple Contrastive Learning of Sentence Embeddings)</h3><p><strong>论文</strong>：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2104.08821">https://arxiv.org/pdf/2104.08821</a></p><p><strong>核心思想</strong>：</p><ul><li><strong>无监督 SimCSE</strong>：利用 Dropout 作为数据增强。将同一个句子输入预训练模型（如BERT）两次，由于 Dropout 的存在，得到两个略有不同的 embedding，作为正样本对。</li><li><strong>有监督 SimCSE</strong>：利用 NLI 数据集中的（蕴含，前提）作为正样本，（矛盾，前提）作为负样本。</li></ul><p><strong>影响</strong>：SimCSE 极大地提升了句向量的质量，成为 NLP 句向量表示的标准基线。</p><h2 id="前沿探讨：对比学习-vs-掩码图像建模-MIM">前沿探讨：对比学习 vs 掩码图像建模 (MIM)</h2><p>随着 <strong>MAE (Masked Autoencoders)</strong> 和 <strong>BEiT</strong> 的提出，视觉预训练领域出现了新的范式竞争。</p><h3 id="掩码图像建模-MIM">掩码图像建模 (MIM)</h3><ul><li><strong>代表作</strong>：MAE, BEiT, SimMIM</li><li><strong>核心思想</strong>：类似 BERT，遮挡图像的一部分 patch，让模型重建被遮挡的像素或特征。</li><li><strong>优势</strong>：<ul><li>训练效率高（只需处理可见 patch）。</li><li>学习到的特征包含更多细节信息，利于检测和分割任务。</li><li>扩展性极强（Scaling Law）。</li></ul></li></ul><h3 id="对比学习-CL-vs-MIM">对比学习 (CL) vs MIM</h3><table><thead><tr><th>特性</th><th>对比学习 (CL)</th><th>掩码图像建模 (MIM)</th></tr></thead><tbody><tr><td><strong>核心目标</strong></td><td>区分样本 (全局语义)</td><td>重建细节 (局部关系)</td></tr><tr><td><strong>数据增强</strong></td><td>极其依赖 (强增强)</td><td>不太依赖 (仅需 Mask)</td></tr><tr><td><strong>特征性质</strong></td><td>线性可分性好，适合分类</td><td>细节丰富，适合定位/分割</td></tr><tr><td><strong>训练效率</strong></td><td>较低 (需处理全图)</td><td>较高 (仅处理部分)</td></tr><tr><td><strong>当前趋势</strong></td><td>多模态对齐 (CLIP)</td><td>视觉基础模型 (ViT Pretraining)</td></tr></tbody></table><p><strong>结论</strong>：两者并非对立，正在趋于融合（如 <strong>IBOT</strong>, <strong>EVA</strong> 等工作尝试结合两者的优势）。</p><h2 id="当前挑战与解决方案">当前挑战与解决方案</h2><h3 id="主要技术挑战">主要技术挑战</h3><p><strong>1. 大批次训练的硬件需求</strong></p><p><strong>问题</strong>：</p><ul><li>SimCLR需要4096-8192的batch size才能达到最佳性能</li><li>需要多GPU训练，单GPU难以实现</li></ul><p><strong>解决方案</strong>：</p><ul><li><strong>MoCo方法</strong>：使用队列存储负样本，减少GPU内存需求</li><li><strong>梯度累积</strong>：多次前向传播累积梯度，模拟大batch</li><li><strong>混合精度训练</strong>：使用FP16减少内存使用</li></ul><p><strong>2. 负样本的质量问题</strong></p><p><strong>问题</strong>：</p><ul><li>随机采样的负样本可能包含语义相似的样本（假负样本）</li><li>简单负样本提供的学习信号有限</li></ul><p><strong>解决方案</strong>：</p><ul><li><strong>困难负样本挖掘</strong>：选择相似度较高的负样本</li><li><strong>去偏采样</strong>：使用先验知识避免假负样本</li><li><strong>自适应温度</strong>：动态调整温度参数关注困难样本</li></ul><p><strong>3. 数据增强的设计</strong></p><p><strong>问题</strong>：</p><ul><li>不同任务需要不同的增强策略</li><li>过强增强可能破坏语义信息</li></ul><p><strong>解决方案</strong>：</p><ul><li><strong>AutoAugment</strong>：自动搜索最优增强策略</li><li><strong>任务特定增强</strong>：根据下游任务设计增强</li><li><strong>增强强度调度</strong>：训练过程中逐渐增强强度</li></ul><h3 id="常见问题与调试">常见问题与调试</h3><p><strong>1. 模型崩溃（所有样本映射到同一点）</strong></p><p><strong>症状</strong>：损失快速下降到0，所有特征相同</p><p><strong>解决</strong>：</p><ul><li>检查是否有stop-gradient操作</li><li>确保使用了负样本</li><li>添加正则化项</li></ul><p><strong>2. 性能不提升</strong></p><p><strong>可能原因</strong>：</p><ul><li>Batch size太小（&lt; 256）</li><li>温度参数设置不当</li><li>数据增强太弱或太强</li></ul><p><strong>调试步骤</strong>：</p><ol><li>可视化增强后的图像，确保保留语义</li><li>监控正负样本相似度分布</li><li>尝试不同的温度参数（0.05-0.5）</li></ol><p><strong>3. 下游任务性能差</strong></p><p><strong>原因分析</strong>：</p><ul><li>预训练与下游任务domain gap</li><li>使用了投影头的特征而非编码器特征</li><li>预训练不充分</li></ul><p><strong>改进方法</strong>：</p><ul><li>在目标domain数据上预训练</li><li>使用编码器特征进行下游任务</li><li>增加预训练epochs</li></ul><h2 id="总结">总结</h2><p>对比学习通过"拉近正样本、推远负样本"的简单思想，在无需大量标注数据的情况下学习到强大的视觉表示。从SimCLR、MoCo到SupCon，对比学习的方法不断演进，性能不断提升。</p><p><strong>关键要点</strong>：</p><ol><li><strong>数据增强是关键</strong>：强数据增强是对比学习成功的重要因素</li><li><strong>负样本数量很重要</strong>：需要足够的负样本才能学到好的表示</li><li><strong>温度参数需要调优</strong>：$\tau$ 对性能有重要影响</li><li><strong>投影头很重要</strong>：在编码器和损失之间加入投影头能提升性能</li><li><strong>可以结合监督信号</strong>：SupCon证明了标签信息可以进一步提升性能</li></ol><p>对比学习的成功证明了<strong>无监督表示学习的巨大潜力</strong>，为未来的研究指明了方向。</p><h2 id="参考文献">参考文献</h2><ol><li><p>Chen, T., et al. (2020). A Simple Framework for Contrastive Learning of Visual Representations. ICML 2020. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2002.05709">https://arxiv.org/pdf/2002.05709</a></p></li><li><p>He, K., et al. (2020). Momentum Contrast for Unsupervised Visual Representation Learning. CVPR 2020. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1911.05722">https://arxiv.org/pdf/1911.05722</a></p></li><li><p>Khosla, P., et al. (2020). Supervised Contrastive Learning. NeurIPS 2020. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2004.11362">https://arxiv.org/pdf/2004.11362</a></p></li><li><p>Grill, J. B., et al. (2020). Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning. NeurIPS 2020. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2006.07733">https://arxiv.org/pdf/2006.07733</a></p></li><li><p>Chen, X., &amp; He, K. (2021). Exploring Simple Siamese Representation Learning. CVPR 2021. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2011.10566">https://arxiv.org/pdf/2011.10566</a></p></li><li><p>Radford, A., et al. (2021). Learning Transferable Visual Models From Natural Language Supervision. ICML 2021. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2103.00020">https://arxiv.org/pdf/2103.00020</a></p></li></ol><h2 id="思考题">思考题</h2><ol><li>为什么对比学习需要大量的负样本？负样本数量如何影响学习效果？</li><li>温度参数 $\tau$ 的物理意义是什么？如何根据任务选择合适的 $\tau$？</li><li>数据增强在对比学习中的作用是什么？为什么某些增强（如crop）比其他增强更重要？</li><li>MoCo的动量编码器和队列机制是如何解决SimCLR的大batch size问题的？</li><li>监督对比学习（SupCon）相比无监督对比学习（SimCLR/MoCo）的优势和劣势是什么？</li><li>为什么BYOL和SimSiam可以在没有负样本的情况下工作？停止梯度机制的作用是什么？</li></ol><h2 id="思考题答案">思考题答案</h2><h3 id="1-为什么对比学习需要大量的负样本？负样本数量如何影响学习效果？">1. 为什么对比学习需要大量的负样本？负样本数量如何影响学习效果？</h3><p><strong>为什么需要大量负样本？</strong></p><ol><li><strong>提供对比信号</strong>：负样本提供了"什么不应该相似"的信息，帮助模型学习区分性</li><li><strong>防止崩溃</strong>：足够的负样本防止模型学习到平凡解（所有特征相同）</li><li><strong>提高表示质量</strong>：更多负样本意味着更丰富的对比信号，学习到的表示更具判别性</li></ol><p><strong>负样本数量的影响</strong>：</p><ul><li><strong>太少（&lt; 64）</strong>：对比信号不足，模型难以学习到好的表示</li><li><strong>适中（256-4096）</strong>：性能随负样本数量增加而提升</li><li><strong>太多（&gt; 8192）</strong>：收益递减，计算成本显著增加</li></ul><p><strong>实验发现</strong>：</p><ul><li>SimCLR：batch size从256增加到8192，性能持续提升</li><li>MoCo：队列大小从128增加到65536，性能提升但收益递减</li></ul><h3 id="2-温度参数-tau-的物理意义是什么？如何根据任务选择合适的-tau-？">2. 温度参数 $\tau$ 的物理意义是什么？如何根据任务选择合适的 $\tau$？</h3><p><strong>物理意义</strong>：</p><p>温度参数 $\tau$ 控制softmax分布的<strong>尖锐程度</strong>（entropy）：</p><ul><li><strong>$\tau \to 0$</strong>：分布接近one-hot，模型只关注最相似的样本</li><li><strong>$\tau \to \infty$</strong>：分布接近均匀，模型对所有样本的关注相等</li></ul><p><strong>数学上</strong>：$\tau$ 是softmax中的缩放因子，影响梯度的尺度</p><p><strong>选择策略</strong>：</p><ol><li><strong>起始值</strong>：0.07（SimCLR、MoCo等常用）</li><li><strong>任务特性</strong>：<ul><li>细粒度分类（类别相似）→ 较小的$\tau$（0.05）</li><li>粗粒度分类（类别差异大）→ 较大的$\tau$（0.1-0.15）</li></ul></li><li><strong>观察训练</strong>：<ul><li>损失下降快但验证性能差 → 降低$\tau$</li><li>训练不稳定 → 提高$\tau$</li></ul></li><li><strong>网格搜索</strong>：在[0.05, 0.07, 0.1, 0.15, 0.2]范围内搜索</li></ol><h3 id="3-数据增强在对比学习中的作用是什么？为什么某些增强（如crop）比其他增强更重要？">3. 数据增强在对比学习中的作用是什么？为什么某些增强（如crop）比其他增强更重要？</h3><p><strong>数据增强的作用</strong>：</p><ol><li><strong>构造正样本对</strong>：通过增强同一图像得到不同的视图，作为正样本</li><li><strong>提高鲁棒性</strong>：学习对增强不变的表示，提高泛化能力</li><li><strong>增加数据多样性</strong>：在有限数据上模拟更多场景</li></ol><p><strong>为什么crop最重要？</strong></p><ol><li><strong>语义保持</strong>：crop保留了图像的主要语义内容</li><li><strong>视角变化</strong>：模拟了不同的观察视角，是自然的变化</li><li><strong>空间不变性</strong>：帮助模型学习空间不变的特征</li></ol><p><strong>增强的重要性排序</strong>（SimCLR实验）：</p><ol><li>RandomResizedCrop（最重要）</li><li>RandomHorizontalFlip</li><li>ColorJitter</li><li>RandomGrayscale</li><li>GaussianBlur</li></ol><p><strong>组合效应</strong>：多个增强的组合效果 &gt; 单个增强的简单叠加</p><h3 id="4-MoCo的动量编码器和队列机制是如何解决SimCLR的大batch-size问题的？">4. MoCo的动量编码器和队列机制是如何解决SimCLR的大batch size问题的？</h3><p><strong>SimCLR的问题</strong>：</p><ul><li>需要大batch size（≥ 4096）提供足够负样本</li><li>对GPU内存和计算资源要求高</li></ul><p><strong>MoCo的解决方案</strong>：</p><ol><li><p><strong>队列机制</strong>：</p><ul><li>维护一个FIFO队列存储历史样本的特征</li><li>队列大小可以很大（如65536），远超batch size</li><li>每次用新batch的特征替换最旧的队列元素</li></ul></li><li><p><strong>动量编码器</strong>：</p><ul><li>Key编码器通过动量更新：$\theta_k \leftarrow m \theta_k + (1-m) \theta_q$</li><li>保证队列中Key的一致性（不会因为编码器快速变化而失效）</li><li>动量系数通常为0.999</li></ul></li></ol><p><strong>优势</strong>：</p><ul><li>不需要大batch size（256-1024即可）</li><li>队列提供大量且一致的负样本</li><li>内存效率高（只存储特征，不存储图像）</li></ul><h3 id="5-监督对比学习（SupCon）相比无监督对比学习（SimCLR-MoCo）的优势和劣势是什么？">5. 监督对比学习（SupCon）相比无监督对比学习（SimCLR/MoCo）的优势和劣势是什么？</h3><p><strong>优势</strong>：</p><ol><li><strong>正样本更明确</strong>：同类样本作为正样本，比增强视图更可靠</li><li><strong>性能更优</strong>：在分类任务上通常超越无监督方法</li><li><strong>鲁棒性更强</strong>：对对抗样本、噪声等更鲁棒</li><li><strong>长尾学习</strong>：在类别不平衡数据上表现优异</li><li><strong>少样本学习</strong>：学习到的表示泛化能力更强</li></ol><p><strong>劣势</strong>：</p><ol><li><strong>需要标注数据</strong>：无法利用无标注数据</li><li><strong>计算成本高</strong>：需要计算所有样本对的相似度（$O(N^2)$）</li><li><strong>任务相关</strong>：学习到的表示可能更偏向特定任务</li><li><strong>类别依赖</strong>：需要知道类别信息，限制了应用场景</li></ol><p><strong>适用场景</strong>：</p><ul><li><strong>SupCon</strong>：有标注数据，关注分类性能和鲁棒性</li><li><strong>无监督</strong>：无标注数据，需要通用表示</li></ul><h3 id="6-为什么BYOL和SimSiam可以在没有负样本的情况下工作？停止梯度机制的作用是什么？">6. 为什么BYOL和SimSiam可以在没有负样本的情况下工作？停止梯度机制的作用是什么？</h3><p><strong>为什么可以工作？</strong></p><ol><li><strong>预测任务替代对比</strong>：通过预测一个视图的特征来学习表示</li><li><strong>对称损失</strong>：同时优化两个方向的预测</li><li><strong>停止梯度</strong>：防止模型学习到平凡解</li></ol><p><strong>停止梯度机制</strong>：</p><p>在BYOL/SimSiam中，一个分支的梯度被停止：</p><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># SimSiam示例</span></span><br><span class="line">z1 = encoder(x1)</span><br><span class="line">z2 = encoder(x2)</span><br><span class="line">p1 = predictor(z1)</span><br><span class="line">p2 = predictor(z2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止z2的梯度</span></span><br><span class="line">loss = <span class="number">0.5</span> * (d(p1, z2.detach()) + d(p2, z1.detach()))</span><br></pre></td></tr></tbody></table></figure><p><strong>作用</strong>：</p><ol><li><strong>防止崩溃</strong>：如果没有停止梯度，两个分支可能学习到相同的表示（平凡解）</li><li><strong>非对称性</strong>：创造非对称的学习信号，使模型必须学习有意义的表示</li><li><strong>稳定训练</strong>：避免两个分支相互"追逐"，训练更稳定</li></ol><p><strong>理论理解</strong>：</p><ul><li>停止梯度创造了一个"教师-学生"的关系</li><li>一个分支作为"教师"提供目标，另一个作为"学生"学习</li><li>这种非对称性防止了表示空间的坍塌</li></ul><h2 id="深度思考与实践经验">深度思考与实践经验</h2><ul><li><strong>对比信号的本质</strong>：无论是SimCLR还是MoCo，本质上都在重建一个“相似样本的局部图结构”。从这个角度看，数据增强、负样本采样、温度参数都是在调节局部图的形状。实践中可以通过构建邻接矩阵或最近邻图来检查模型学习到的结构是否符合预期。</li><li><strong>大batch与动量编码器的权衡</strong>：SimCLR依赖大batch，MoCo依赖动量编码器与队列。前者更适合TPU或多节点GPU环境，后者对资源要求更低但需要额外调节动量系数。在工业部署时，可根据硬件与延迟要求选择不同方案。</li><li><strong>Projection Head的价值</strong>：许多工程实践表明，只要下游任务不是k-NN检索，就应当保留投影头并在微调时丢弃。投影头相当于一个“噪声抑制器”，把与对比任务高度相关但与下游任务无关的因素隔离开。</li><li><strong>数据增强的语义边界</strong>：对比学习依赖“语义不变”的增强。如果增强破坏了语义一致性（例如在细粒度识别中使用过强的随机裁剪），模型可能误学到错误关联。设计增强时应结合业务常识：什么变化对用户看来仍是同一对象？</li><li><strong>InfoNCE作为下界</strong>：InfoNCE提供了互信息的可计算下界。下界松紧程度受负样本数量、温度、特征容量、优化状态影响。若训练良好却仍觉得效果不足，可以尝试提高下界（更多负样本、更低温度）或改用其他目标（如Barlow Twins、VICReg）。</li></ul><h2 id="开放问题">开放问题</h2><ol><li><strong>困难负样本自动发现</strong>：目前多靠随机采样，能否结合难例挖掘或生成模型来构建更具区分度的负样本？</li><li><strong>跨模态对比的统一框架</strong>：CLIP等方法表明文本-图像对比极具潜力，是否存在统一的对比学习范式涵盖视觉、语言、音频？</li><li><strong>长序列与视频</strong>：视频对比学习如何解决时间维度的冗余与语义错配问题？现有工作（VideoMAE、TimeSformer）仍在探索。</li><li><strong>理论上界与可解释性</strong>：对比学习能否提供误差上界或泛化保证？如何解释实例判别自动聚类的现象？</li><li><strong>增量与联邦场景</strong>：当数据分布随时间变化或分散在不同客户端时，如何稳定地维护对比学习的记忆（队列/Memory Bank）？</li></ol></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://wp-a.github.io">WP</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://wp-a.github.io/2025/11/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/">https://wp-a.github.io/2025/11/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://wp-a.github.io" target="_blank">WPIRONMAN</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%87%AA%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">自监督学习</a><a class="post-meta__tags" href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">对比学习</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">无监督学习</a></div><div class="post-share"><div class="social-share" data-image="https://wpironman.oss-cn-qingdao.aliyuncs.com/1.webp" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.4/sharejs/dist/css/share.min.css" media="print" onload="this.media=&quot;all&quot;"><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.4/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/123.JPG" target="_blank"><img class="post-qr-code-img" src="/img/123.JPG" alt="微信" loading="lazy"></a><div class="post-qr-code-desc">微信</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/11/LeetCode%E5%88%B7%E9%A2%98%E6%97%A5%E5%BF%97%E6%A8%A1%E6%9D%BF/" title="LeetCode 两个变量 - 2025.11.13"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/1.webp" onerror="onerror=null,src=&quot;/img/404.jpg&quot;" alt="cover of previous post" loading="lazy"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">LeetCode 两个变量 - 2025.11.13</div></div><div class="info-2"><div class="info-item-1">今日概览 日期：{2025-11-13} 题目数量：{共 2 题} 难度分布：简单 2 主要收获：自己的方法就是屎山，灵神的方法高端又通透 心情/状态：太久没刷了，已经把基本的语法忘记了，以后尝试用python刷题，学习一些比较好用的函数 题目列表与详解 1. Two Sum 题号 / 链接：#1 / 题目链接 难度：简单 题型标签：哈希表，数组 题目描述（简要）： 就是查找一下哪两个数相加等于target，返回下标。 思路分析 两个方法，不同的时间复杂度 方法一：暴力写法。 复杂度 时间：O(*n*2) 空间：O(1) 123456class Solution: def twoSum(self, nums: List[int], target: int) -&gt; List[int]: for i, x in enumerate(nums): for j in range(i + 1, len(nums)): if...</div></div></div></a><a class="pagination-related" href="/2025/11/%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" title="监督对比学习"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/202511111359964.png" onerror="onerror=null,src=&quot;/img/404.jpg&quot;" alt="cover of next post" loading="lazy"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">监督对比学习</div></div><div class="info-2"><div class="info-item-1">Supervised Contrastive Learning 论文地址：https://arxiv.org/pdf/2004.11362 代码地址：https://github.com/HobbitLong/SupContrast 引言 监督对比学习（Supervised Contrastive Learning, SupCon）...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/11/%E5%AE%9E%E4%BE%8B%E5%88%A4%E5%88%AB%E5%AD%A6%E4%B9%A0/" title="实例判别学习 - Non-Parametric Instance Discrimination精读"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/202511122017857.png" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-11</div><div class="info-item-2">实例判别学习 - Non-Parametric Instance Discrimination精读</div></div><div class="info-2"><div class="info-item-1">Unsupervised Feature Learning via Non-Parametric Instance Discrimination 论文地址：https://arxiv.org/pdf/1805.01978 代码地址：https://github.com/zhirongw/lemniscate.pytorch 引言 实例判别（Instance Discrimination）...</div></div></div></a><a class="pagination-related" href="/2025/11/%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/" title="监督对比学习"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/202511111359964.png" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-16</div><div class="info-item-2">监督对比学习</div></div><div class="info-2"><div class="info-item-1">Supervised Contrastive Learning 论文地址：https://arxiv.org/pdf/2004.11362 代码地址：https://github.com/HobbitLong/SupContrast 引言 监督对比学习（Supervised Contrastive Learning, SupCon）...</div></div></div></a><a class="pagination-related" href="/2025/11/MAE/" title="MAE详解 - Masked Autoencoders精读"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/202511102142380.png" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-09</div><div class="info-item-2">MAE详解 - Masked Autoencoders精读</div></div><div class="info-2"><div class="info-item-1">Masked Autoencoders Are Scalable Vision Learners 引言 MAE (Masked Autoencoders) 由He Kaiming团队在2021年提出，为视觉自监督学习带来了新的范式。论文标题“Masked Autoencoders Are Scalable Vision Learners”凸显了其两大特性：一是基于掩码的自重构任务；二是能在大规模数据和模型上稳定扩展。和SimCLR、MoCo等对比学习方法相比，MAE丢弃了昂贵的负样本构造环节，通过简单的遮挡-重建目标即可学习高质量的视觉特征。 在图像理解任务中，过去的自监督方法往往依赖对比学习或生成式建模。MAE将NLP中成熟的Masked Language Modeling理念迁移到视觉领域，将图片切分为patch token，然后随机遮挡大部分token，让模型仅凭剩余少量可见token推断出被遮挡的像素，从而学到上下文结构。 背景知识 自监督视觉预训练的演进 预文本任务 (Pretext...</div></div></div></a><a class="pagination-related" href="/2025/04/MoCo/" title="MoCo"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/20250425170023257.png" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-24</div><div class="info-item-2">MoCo</div></div><div class="info-2"><div class="info-item-1">MoCo Momentum Contrast for Unsupervised Visual Representation Learning (cvpr2020) 论文地址：https://arxiv.org/pdf/1911.05722 代码地址：https://github.com/facebookresearch/moco 概述 MoCo 将对比学习看作是一个字典查找任务 ：一个编码后的查询（query）应该与其匹配的键（正样本）相似，而与其他所有的键（负样本）不相似 。 对比学习的核心思想是训练一个编码器，使其能够区分相似（正样本）和不相似（负样本）的样本 。 传统方法 VS MoCo 端到端（End-to-end）方法（SimCLR，Inva Spread）：将当前 mini-batch 内的样本作为字典 。这种方法的优点是字典中的键编码是一致的（由同一个编码器生成），但缺点是字典的大小受限于 mini-batch 的大小，而 mini-batch 大小又受限于 GPU 内存 。过大的 mini-batch 也会带来优化难题 。 Memory Bank...</div></div></div></a><a class="pagination-related" href="/2025/04/%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" title="基于深度学习的图像分类"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/20250417222715500.png" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-15</div><div class="info-item-2">基于深度学习的图像分类</div></div><div class="info-2"><div class="info-item-1">使用ResNet18预训练模型 由于笔记本性能太差，所以在服务器上运行的，显卡配置为4090。经大量实验判断，初始学习率为0.01最后效果较差，所以初始学习率应设为0.001。全部代码代码已上传到：https://github.com/wp-a/-CIFAR10-.git 库函数导入 123456789import matplotlib.pyplot as pltimport torchimport torch.nn as nnimport torchvisionimport torchvision.transforms as transformsfrom sklearn.metrics import confusion_matrix, classification_reportfrom itertools import chainimport multiprocessingdevice = torch.device("cuda:0" if torch.cuda.is_available() else...</div></div></div></a></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div><h1 id="site-title" fetchpriority="high" style="font-display:swap">对比学习综述</h1></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">对比学习综述：从理论到实践全面解析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">1.1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%EF%BC%9F"><span class="toc-number">1.2.</span> <span class="toc-text">什么是对比学习？</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">1.2.1.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%EF%BC%9F"><span class="toc-number">1.2.2.</span> <span class="toc-text">为什么需要对比学习？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">1.2.3.</span> <span class="toc-text">对比学习的工作原理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%8F%91%E5%B1%95%E5%8E%86%E7%A8%8B"><span class="toc-number">1.3.</span> <span class="toc-text">对比学习的发展历程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%97%A9%E6%9C%9F%E5%B7%A5%E4%BD%9C%EF%BC%882010s%EF%BC%89"><span class="toc-number">1.3.1.</span> <span class="toc-text">早期工作（2010s）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%8E%B0%E4%BB%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%EF%BC%882020-%EF%BC%89"><span class="toc-number">1.3.2.</span> <span class="toc-text">现代对比学习（2020-）</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%EF%BC%9AInfoNCE-NT-Xent"><span class="toc-number">1.4.</span> <span class="toc-text">核心损失函数：InfoNCE / NT-Xent</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#InfoNCE%E6%8D%9F%E5%A4%B1%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.4.1.</span> <span class="toc-text">InfoNCE损失详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0-tau-%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">1.4.2.</span> <span class="toc-text">温度参数 $\tau$ 的作用</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E6%96%B9%E6%B3%95%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.5.</span> <span class="toc-text">主要方法详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-SimCLR%EF%BC%88A-Simple-Framework-for-Contrastive-Learning%EF%BC%89"><span class="toc-number">1.5.1.</span> <span class="toc-text">1. SimCLR（A Simple Framework for Contrastive Learning）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3-2"><span class="toc-number">1.5.1.1.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E5%88%9B%E6%96%B0"><span class="toc-number">1.5.1.2.</span> <span class="toc-text">关键创新</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84"><span class="toc-number">1.5.1.3.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84-2"><span class="toc-number">1.5.1.4.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9"><span class="toc-number">1.5.1.5.</span> <span class="toc-text">优缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-MoCo%EF%BC%88Momentum-Contrast%EF%BC%89"><span class="toc-number">1.5.2.</span> <span class="toc-text">2. MoCo（Momentum Contrast）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3-3"><span class="toc-number">1.5.2.1.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E5%88%9B%E6%96%B0-2"><span class="toc-number">1.5.2.2.</span> <span class="toc-text">关键创新</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84-3"><span class="toc-number">1.5.2.3.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84-4"><span class="toc-number">1.5.2.4.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9-2"><span class="toc-number">1.5.2.5.</span> <span class="toc-text">优缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-SupCon%EF%BC%88Supervised-Contrastive-Learning%EF%BC%89"><span class="toc-number">1.5.3.</span> <span class="toc-text">3. SupCon（Supervised Contrastive Learning）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3-4"><span class="toc-number">1.5.3.1.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="toc-number">1.5.3.2.</span> <span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9-3"><span class="toc-number">1.5.3.3.</span> <span class="toc-text">优缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-BYOL-SimSiam%EF%BC%88%E6%97%A0%E9%9C%80%E8%B4%9F%E6%A0%B7%E6%9C%AC%EF%BC%89"><span class="toc-number">1.5.4.</span> <span class="toc-text">4. BYOL / SimSiam（无需负样本）</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3-5"><span class="toc-number">1.5.4.1.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%85%B3%E9%94%AE%E6%9C%BA%E5%88%B6"><span class="toc-number">1.5.4.2.</span> <span class="toc-text">关键机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9-4"><span class="toc-number">1.5.4.3.</span> <span class="toc-text">优缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-SwAV-Swapping-Assignments-between-Views"><span class="toc-number">1.5.5.</span> <span class="toc-text">5. SwAV (Swapping Assignments between Views)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3-6"><span class="toc-number">1.5.5.1.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84-5"><span class="toc-number">1.5.5.2.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9-5"><span class="toc-number">1.5.5.3.</span> <span class="toc-text">优缺点</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-CLIP-Contrastive-Language-Image-Pre-training"><span class="toc-number">1.5.6.</span> <span class="toc-text">6. CLIP (Contrastive Language-Image Pre-training)</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3-7"><span class="toc-number">1.5.6.1.</span> <span class="toc-text">核心思想</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%9E%B6%E6%9E%84-6"><span class="toc-number">1.5.6.2.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BD%B1%E5%93%8D"><span class="toc-number">1.5.6.3.</span> <span class="toc-text">影响</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82%E4%B8%8E%E5%AE%9E%E8%B7%B5%E6%8C%87%E5%8D%97"><span class="toc-number">1.6.</span> <span class="toc-text">技术细节与实践指南</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E7%AD%96%E7%95%A5%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.6.1.</span> <span class="toc-text">数据增强策略详解</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8A%95%E5%BD%B1%E5%A4%B4%E8%AE%BE%E8%AE%A1%E5%8E%9F%E7%90%86"><span class="toc-number">1.6.2.</span> <span class="toc-text">投影头设计原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%8A%80%E5%B7%A7"><span class="toc-number">1.6.3.</span> <span class="toc-text">训练技巧</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%89%B9%E5%BE%81%E5%BD%92%E4%B8%80%E5%8C%96"><span class="toc-number">1.6.4.</span> <span class="toc-text">特征归一化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.7.</span> <span class="toc-text">代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#InfoNCE%E6%8D%9F%E5%A4%B1%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.7.1.</span> <span class="toc-text">InfoNCE损失实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%8C%E6%95%B4%E7%9A%84%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E8%AE%AD%E7%BB%83%E7%A4%BA%E4%BE%8B"><span class="toc-number">1.7.2.</span> <span class="toc-text">完整的对比学习训练示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.8.</span> <span class="toc-text">应用场景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB"><span class="toc-number">1.8.1.</span> <span class="toc-text">1. 图像分类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B"><span class="toc-number">1.8.2.</span> <span class="toc-text">2. 目标检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E8%AF%AD%E4%B9%89%E5%88%86%E5%89%B2"><span class="toc-number">1.8.3.</span> <span class="toc-text">3. 语义分割</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-%E5%9B%BE%E5%83%8F%E6%A3%80%E7%B4%A2"><span class="toc-number">1.8.4.</span> <span class="toc-text">4. 图像检索</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E9%95%BF%E5%B0%BE%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.8.5.</span> <span class="toc-text">5. 长尾学习</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-vs-%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95"><span class="toc-number">1.9.</span> <span class="toc-text">对比学习 vs 其他方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#vs-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.9.1.</span> <span class="toc-text">vs. 监督学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vs-%E7%94%9F%E6%88%90%E5%BC%8F%E6%96%B9%E6%B3%95%EF%BC%88VAE%E3%80%81GAN%EF%BC%89"><span class="toc-number">1.9.2.</span> <span class="toc-text">vs. 生成式方法（VAE、GAN）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vs-%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8"><span class="toc-number">1.9.3.</span> <span class="toc-text">vs. 自编码器</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%89%A9%E5%B1%95%E9%A2%86%E5%9F%9F%EF%BC%9ANLP%E4%B8%AD%E7%9A%84%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.10.</span> <span class="toc-text">扩展领域：NLP中的对比学习</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#SimCSE-Simple-Contrastive-Learning-of-Sentence-Embeddings"><span class="toc-number">1.10.1.</span> <span class="toc-text">SimCSE (Simple Contrastive Learning of Sentence Embeddings)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E6%B2%BF%E6%8E%A2%E8%AE%A8%EF%BC%9A%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-vs-%E6%8E%A9%E7%A0%81%E5%9B%BE%E5%83%8F%E5%BB%BA%E6%A8%A1-MIM"><span class="toc-number">1.11.</span> <span class="toc-text">前沿探讨：对比学习 vs 掩码图像建模 (MIM)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8E%A9%E7%A0%81%E5%9B%BE%E5%83%8F%E5%BB%BA%E6%A8%A1-MIM"><span class="toc-number">1.11.1.</span> <span class="toc-text">掩码图像建模 (MIM)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0-CL-vs-MIM"><span class="toc-number">1.11.2.</span> <span class="toc-text">对比学习 (CL) vs MIM</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BD%93%E5%89%8D%E6%8C%91%E6%88%98%E4%B8%8E%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88"><span class="toc-number">1.12.</span> <span class="toc-text">当前挑战与解决方案</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E6%8A%80%E6%9C%AF%E6%8C%91%E6%88%98"><span class="toc-number">1.12.1.</span> <span class="toc-text">主要技术挑战</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E4%B8%8E%E8%B0%83%E8%AF%95"><span class="toc-number">1.12.2.</span> <span class="toc-text">常见问题与调试</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.13.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">1.14.</span> <span class="toc-text">参考文献</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">1.15.</span> <span class="toc-text">思考题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98%E7%AD%94%E6%A1%88"><span class="toc-number">1.16.</span> <span class="toc-text">思考题答案</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%B8%BA%E4%BB%80%E4%B9%88%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E9%9C%80%E8%A6%81%E5%A4%A7%E9%87%8F%E7%9A%84%E8%B4%9F%E6%A0%B7%E6%9C%AC%EF%BC%9F%E8%B4%9F%E6%A0%B7%E6%9C%AC%E6%95%B0%E9%87%8F%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E5%AD%A6%E4%B9%A0%E6%95%88%E6%9E%9C%EF%BC%9F"><span class="toc-number">1.16.1.</span> <span class="toc-text">1. 为什么对比学习需要大量的负样本？负样本数量如何影响学习效果？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0-tau-%E7%9A%84%E7%89%A9%E7%90%86%E6%84%8F%E4%B9%89%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E5%A6%82%E4%BD%95%E6%A0%B9%E6%8D%AE%E4%BB%BB%E5%8A%A1%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84-tau-%EF%BC%9F"><span class="toc-number">1.16.2.</span> <span class="toc-text">2. 温度参数 $\tau$ 的物理意义是什么？如何根据任务选择合适的 $\tau$？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E5%9C%A8%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9F%90%E4%BA%9B%E5%A2%9E%E5%BC%BA%EF%BC%88%E5%A6%82crop%EF%BC%89%E6%AF%94%E5%85%B6%E4%BB%96%E5%A2%9E%E5%BC%BA%E6%9B%B4%E9%87%8D%E8%A6%81%EF%BC%9F"><span class="toc-number">1.16.3.</span> <span class="toc-text">3. 数据增强在对比学习中的作用是什么？为什么某些增强（如crop）比其他增强更重要？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-MoCo%E7%9A%84%E5%8A%A8%E9%87%8F%E7%BC%96%E7%A0%81%E5%99%A8%E5%92%8C%E9%98%9F%E5%88%97%E6%9C%BA%E5%88%B6%E6%98%AF%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3SimCLR%E7%9A%84%E5%A4%A7batch-size%E9%97%AE%E9%A2%98%E7%9A%84%EF%BC%9F"><span class="toc-number">1.16.4.</span> <span class="toc-text">4. MoCo的动量编码器和队列机制是如何解决SimCLR的大batch size问题的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%EF%BC%88SupCon%EF%BC%89%E7%9B%B8%E6%AF%94%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%EF%BC%88SimCLR-MoCo%EF%BC%89%E7%9A%84%E4%BC%98%E5%8A%BF%E5%92%8C%E5%8A%A3%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.16.5.</span> <span class="toc-text">5. 监督对比学习（SupCon）相比无监督对比学习（SimCLR/MoCo）的优势和劣势是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-%E4%B8%BA%E4%BB%80%E4%B9%88BYOL%E5%92%8CSimSiam%E5%8F%AF%E4%BB%A5%E5%9C%A8%E6%B2%A1%E6%9C%89%E8%B4%9F%E6%A0%B7%E6%9C%AC%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%E5%B7%A5%E4%BD%9C%EF%BC%9F%E5%81%9C%E6%AD%A2%E6%A2%AF%E5%BA%A6%E6%9C%BA%E5%88%B6%E7%9A%84%E4%BD%9C%E7%94%A8%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.16.6.</span> <span class="toc-text">6. 为什么BYOL和SimSiam可以在没有负样本的情况下工作？停止梯度机制的作用是什么？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B7%B1%E5%BA%A6%E6%80%9D%E8%80%83%E4%B8%8E%E5%AE%9E%E8%B7%B5%E7%BB%8F%E9%AA%8C"><span class="toc-number">1.17.</span> <span class="toc-text">深度思考与实践经验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%80%E6%94%BE%E9%97%AE%E9%A2%98"><span class="toc-number">1.18.</span> <span class="toc-text">开放问题</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">©2025 By WP</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><div id="runtime"></div></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js" defer=""></script><script src="/js/main.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module"></script><div class="js-pjax"><script>(()=>{var t=()=>{var t;window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise()):(window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"none"},chtml:{scale:1.1},options:{enableMenu:!0,renderActions:{findScript:[10,t=>{for(var e of document.querySelectorAll('script[type^="math/tex"]')){var a=!!e.type.match(/; *mode=display/),a=new t.options.MathItem(e.textContent,t.inputJax[0],a),n=document.createTextNode("");e.parentNode.replaceChild(n,e),a.start={node:n,delim:"",n:0},a.end={node:n,delim:"",n:0},t.math.push(a)}},""]}}},(t=document.createElement("script")).src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t))};btf.addGlobalFn("encrypt",t,"mathjax"),window.pjax?t():window.addEventListener("load",t)})()</script><script>(()=>{var e=()=>{var e;0!==(e=document.querySelectorAll("pre > code.mermaid")).length&&e.forEach(e=>{var t=document.createElement("pre"),a=(t.className="mermaid-src",t.hidden=!0,t.textContent=e.textContent,document.createElement("div"));a.className="mermaid-wrap",a.appendChild(t),e.parentNode.replaceWith(a)});let t=document.querySelectorAll("#article-container .mermaid-wrap");0!==t.length&&(e=()=>(e=>{window.loadMermaid=!0;let n="dark"===document.documentElement.getAttribute("data-theme")?"dark":"default";e.forEach((e,t)=>{let a=e.firstElementChild;e=`%%{init:{ 'theme':'${n}'}}%%
`+a.textContent,t=mermaid.render("mermaid-"+t,e);let d=e=>{a.insertAdjacentHTML("afterend",e)};"string"==typeof t?d(t):t.then(({svg:e})=>d(e))})})(t),btf.addGlobalFn("themeChange",e,"mermaid"),window.loadMermaid?e():btf.getScript("https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.1/mermaid.min.js").then(e))};btf.addGlobalFn("encrypt",e,"mermaid"),window.pjax?e():document.addEventListener("DOMContentLoaded",e)})()</script><script>(()=>{let n="shuoshuo"===GLOBAL_CONFIG_SITE.pageType,o=null,a=(t,e)=>{n&&(window.shuoshuoComment.destroyValine=()=>{t.children.length&&(t.innerHTML="",t.classList.add("no-comment"))});e={el:"#vcomment",appId:"FXG14lTbR0Yj3W2kb3tkAt4L-gzGzoHsz",appKey:"hohJIUW6lOhfboJzq5FvG8z7",avatar:"monsterid",serverURLs:"https://fxg14ltb.lc-cn-n1-shared.com",emojiMaps:"",visitor:!1,...o,path:n?e:o&&o.path||window.location.pathname};new Valine(e)};var t=async(t,e)=>{"function"==typeof Valine||await btf.getScript("https://unpkg.com/valine@1.5.1/dist/Valine.min.js"),a(t,e)};n?window.shuoshuoComment={loadComment:t}:setTimeout(t,0)})()</script></div><script type="text/javascript" src="/js/reward.js" defer=""></script><script async="" src="https://cdn.bootcss.com/jquery/3.4.1/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/echarts@5.4.1/dist/echarts.min.js"></script><script data-pjax="" src="/js/hexo_githubcalendar.js?v=20250920"></script><script src="/js/fix-avatar.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.4/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,POWERMODE.mobile=!1,document.body.addEventListener("input",POWERMODE)</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js" defer=""></script><script>(()=>{window.pjax=new Pjax({elements:'a:not([target="_blank"]):not([href="/music/"]):not([href="/gallery/"]):not([href="/about/"])',selectors:["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"],cacheBust:!1,analytics:!1,scrollRestoration:!1});let t=e=>{e&&Object.values(e).forEach(e=>e())};document.addEventListener("pjax:send",()=>{btf.removeGlobalFnEvent("pjaxSendOnce"),btf.removeGlobalFnEvent("themeChange");var e=document.body.classList;e.contains("read-mode")&&e.remove("read-mode"),t(window.globalFn.pjaxSend)}),document.addEventListener("pjax:complete",()=>{btf.removeGlobalFnEvent("pjaxCompleteOnce"),document.querySelectorAll("script[data-pjax]").forEach(e=>{let t=document.createElement("script");var a=e.text||e.textContent||e.innerHTML||"";Array.from(e.attributes).forEach(e=>t.setAttribute(e.name,e.value)),t.appendChild(document.createTextNode(a)),e.parentNode.replaceChild(t,e)}),t(window.globalFn.pjaxComplete)}),document.addEventListener("pjax:error",e=>{404===e.request.status&&pjax.loadUrl("/404.html")})})()</script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js" defer=""></script></div></div><script data-pjax="" src="/js/hexo_githubcalendar.js?v=20251124"></script><script data-pjax="">function GithubCalendarConfig(){var t=document.getElementById("recent-posts");t&&"/"==location.pathname&&(console.log("已挂载hexo-github-calendar https://github.com/Barry-Flynn/hexo-github-calendar"),t.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>')),GithubCalendar("https://github-calendar-api.meta-code.top/api?user=wp-a",["#ebedf0","#a2f7af","#6ce480","#54ad63","#469252","#31753c","#1f5f2a","#13531f","#084111","#032b09","#000000"],"wp-a")}document.getElementById("recent-posts")&&GithubCalendarConfig()</script><style>#github_container{min-height:280px}@media screen and (max-width:650px){#github_container{min-height:0}}</style><style></style></body></html>