<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>监督对比学习 | WPIRONMAN</title><meta name="author" content="WP"><meta name="copyright" content="WP"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="Supervised Contrastive Learning 论文地址：https://arxiv.org/pdf/2004.11362 代码地址：https://github.com/HobbitLong/SupContrast 引言 监督对比学习（Supervised Contrastive Learning, SupCon） 是2020年提出的一种结合监督学习和对比学习优势的深度学习方法。"><meta property="og:type" content="article"><meta property="og:title" content="监督对比学习"><meta property="og:url" content="https://wp-a.github.io/2025/11/%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/index.html"><meta property="og:site_name" content="WPIRONMAN"><meta property="og:description" content="Supervised Contrastive Learning 论文地址：https://arxiv.org/pdf/2004.11362 代码地址：https://github.com/HobbitLong/SupContrast 引言 监督对比学习（Supervised Contrastive Learning, SupCon） 是2020年提出的一种结合监督学习和对比学习优势的深度学习方法。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://wpironman.oss-cn-qingdao.aliyuncs.com/202511111359964.png"><meta property="article:published_time" content="2025-11-16T03:39:13.000Z"><meta property="article:modified_time" content="2025-11-24T15:30:52.705Z"><meta property="article:author" content="WP"><meta property="article:tag" content="对比学习"><meta property="article:tag" content="深度学习"><meta property="article:tag" content="监督学习"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://wpironman.oss-cn-qingdao.aliyuncs.com/202511111359964.png"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "监督对比学习",
  "url": "https://wp-a.github.io/2025/11/%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/",
  "image": "https://wpironman.oss-cn-qingdao.aliyuncs.com/202511111359964.png",
  "datePublished": "2025-11-16T03:39:13.000Z",
  "dateModified": "2025-11-24T15:30:52.705Z",
  "author": [
    {
      "@type": "Person",
      "name": "WP",
      "url": "https://wp-a.github.io/"
    }
  ]
}</script><link rel="shortcut icon" href="https://wpironman.oss-cn-qingdao.aliyuncs.com/favicon.png"><link rel="canonical" href="https://wp-a.github.io/2025/11/%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/index.html"><link rel="preconnect" href="//cdnjs.cloudflare.com"><link rel="manifest" href="/null"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css"><script>(()=>{var e={set:(e,t,a)=>{a&&(a=Date.now()+864e5*a,localStorage.setItem(e,JSON.stringify({value:t,expiry:a})))},get:e=>{var t=localStorage.getItem(e);if(t){var{value:t,expiry:a}=JSON.parse(t);if(!(Date.now()>a))return t;localStorage.removeItem(e)}}},t=(window.btf={saveToLocal:e,getScript:(o,n={})=>new Promise((e,t)=>{let a=document.createElement("script");a.src=o,a.async=!0,Object.entries(n).forEach(([e,t])=>a.setAttribute(e,t)),a.onload=a.onreadystatechange=()=>{a.readyState&&!/loaded|complete/.test(a.readyState)||e()},a.onerror=t,document.head.appendChild(a)}),getCSS:(o,n)=>new Promise((e,t)=>{let a=document.createElement("link");a.rel="stylesheet",a.href=o,n&&(a.id=n),a.onload=a.onreadystatechange=()=>{a.readyState&&!/loaded|complete/.test(a.readyState)||e()},a.onerror=t,document.head.appendChild(a)}),addGlobalFn:(e,t,a=!1,o=window)=>{var n=o.globalFn||{};n[e]=n[e]||{},n[e][a||Object.keys(n[e]).length]=t,o.globalFn=n}},()=>{document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")}),a=()=>{document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")},o=(btf.activateDarkMode=t,btf.activateLightMode=a,e.get("theme")),t=("dark"===o?t():"light"===o&&a(),e.get("aside-status"));void 0!==t&&document.documentElement.classList.toggle("hide-aside","hide"===t);/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)&&document.documentElement.classList.add("apple")})()</script><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Noto+Sans+SC:wght@400;500;600&amp;family=JetBrains+Mono:wght@400;500&amp;family=Roboto+Slab:wght@400;600;700&amp;display=swap" media="print" onload="this.media=&quot;all&quot;"><script>let GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"/search.xml",preload:!1,top_n_per_article:1,unescape:!1,languages:{hits_empty:"未找到符合您查询的内容：${query}",hits_stats:"共找到 ${hits} 篇文章"}},translate:void 0,highlight:{plugin:"highlight.js",highlightCopy:!0,highlightLang:!0,highlightHeightLimit:!1,highlightFullpage:!1,highlightMacStyle:!0},copy:{success:"复制成功",error:"复制失败",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",dateSuffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:void 0,lightbox:"null",Snackbar:void 0,infinitegrid:{js:"https://cdnjs.cloudflare.com/ajax/libs/egjs-infinitegrid/4.12.0/infinitegrid.min.js",buttonText:"加载更多"},isPhotoFigcaption:!0,islazyloadPlugin:!1,isAnchor:!0,percent:{toc:!0,rightside:!0},autoDarkmode:!1}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"监督对比学习",isHighlightShrink:!1,isToc:!0,pageType:"post"}</script><link rel="stylesheet" href="/css/_custom/category/categories.css"><link rel="preconnect" href="https://fonts.loli.net" crossorigin=""><link rel="stylesheet" href="/css/categories.css"><link rel="stylesheet" href="/css/valine.css"><link rel="stylesheet" href="/css/transpancy.css"><link rel="stylesheet" href="/css/medium-style.css"><script>window.addEventListener("DOMContentLoaded",()=>{let e=document.getElementById("my-pv");e&&fetch("https://wpironman.top/pv").then(t=>t.json()).then(t=>{e.textContent=t.pv}).catch(()=>{e.textContent="获取失败"})})</script><link rel="preload" href="https://lf6-cdn-tos.bytecdntp.com/cdn/expire-1-M/font-awesome/6.0.0/css/all.min.css" as="style" onload="this.rel=&quot;stylesheet&quot;"><link href="https://wpironman.oss-cn-qingdao.aliyuncs.com/1.webp" as="image" crossorigin="anonymous"><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image:url(https://wpironman.oss-cn-qingdao.aliyuncs.com/10year.webp)"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="https://wpironman.oss-cn-qingdao.aliyuncs.com/head.png" onerror="this.onerror=null,this.src=&quot;https://wpironman.oss-cn-qingdao.aliyuncs.com/head.gif&quot;" alt="avatar" loading="lazy"></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">43</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">85</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/construction-detection/"><i class="fa-fw fas fa-hard-hat"></i><span> 工地检测</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-user-group"></i><span> 友链</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fa-solid fa-user-tie"></i><span> 本站友链</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i><span> 随机开往</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://travel.moe/go.html?travel=on"><i class="fa-fw fa fa-taxi"></i><span> 异次元之旅</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/academic/"><i class="fa-fw fas fa-graduation-cap"></i><span> 学术主页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://wpironman.oss-cn-qingdao.aliyuncs.com/202511111359964.png)"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="/img/favicon.png" alt="Logo" loading="lazy"><span class="site-name">WPIRONMAN</span></a><a class="nav-page-title" href="/"><span class="site-name">监督对比学习</span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-tools"></i><span> 工具</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/construction-detection/"><i class="fa-fw fas fa-hard-hat"></i><span> 工地检测</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa-solid fa-user-group"></i><span> 友链</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fa-solid fa-user-tie"></i><span> 本站友链</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fa fa-subway"></i><span> 随机开往</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://travel.moe/go.html?travel=on"><i class="fa-fw fa fa-taxi"></i><span> 异次元之旅</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/academic/"><i class="fa-fw fas fa-graduation-cap"></i><span> 学术主页</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">监督对比学习<a class="post-edit-link" href="null_posts/监督对比学习.md" title="编辑" target="_blank"><i class="fas fa-pencil-alt"></i></a></h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="fa-fw post-meta-icon far fa-calendar-alt"></i><span class="post-meta-label">发表于</span><time datetime="2025-11-16T03:39:13.000Z" title="发表于 2025-11-16 11:39:13">2025-11-16</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/">论文精读</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87%E7%B2%BE%E8%AF%BB/%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89/">计算机视觉</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">4.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>15分钟</span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><h1>Supervised Contrastive Learning</h1><p>论文地址：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2004.11362">https://arxiv.org/pdf/2004.11362</a></p><p>代码地址：<a target="_blank" rel="noopener" href="https://github.com/HobbitLong/SupContrast">https://github.com/HobbitLong/SupContrast</a></p><h2 id="引言">引言</h2><p><strong>监督对比学习（Supervised Contrastive Learning, SupCon）</strong> 是2020年提出的一种结合监督学习和对比学习优势的深度学习方法。与传统的交叉熵损失相比，SupCon通过显式地拉近同类样本、推远异类样本，在图像分类、鲁棒性学习等任务上取得了显著提升。</p><h3 id="为什么需要监督对比学习？">为什么需要监督对比学习？</h3><p><strong>传统交叉熵损失的局限</strong>：</p><ol><li><p><strong>只关注分类边界</strong></p><ul><li>交叉熵只要求正确分类，不关心特征空间的结构</li><li>导致同类样本在特征空间可能很分散</li><li>决策边界可能过于接近某些样本</li></ul></li><li><p><strong>忽略类间关系</strong></p><ul><li>将所有错误分类同等对待</li><li>"猫被分类为狗"和"猫被分类为汽车"的惩罚相同</li><li>无法利用类别间的语义相似性</li></ul></li><li><p><strong>对噪声标签敏感</strong></p><ul><li>错误标签直接影响分类边界</li><li>难以从噪声中恢复</li></ul></li></ol><p><strong>监督对比学习的优势</strong>：</p><ol><li><p><strong>更好的特征空间结构</strong></p><ul><li>同类样本紧密聚集</li><li>不同类样本明确分离</li><li>形成清晰的聚类结构</li></ul></li><li><p><strong>更强的鲁棒性</strong></p><ul><li>对标签噪声更鲁棒</li><li>对对抗样本更鲁棒</li><li>更好的泛化能力</li></ul></li><li><p><strong>灵活的应用</strong></p><ul><li>可以自然处理开放集识别</li><li>支持少样本学习</li><li>便于增量学习新类别</li></ul></li></ol><h3 id="方法对比">方法对比</h3><table><thead><tr><th>特性</th><th>交叉熵损失</th><th>监督对比损失</th></tr></thead><tbody><tr><td>优化目标</td><td>分类准确率</td><td>特征空间结构</td></tr><tr><td>类内约束</td><td>无</td><td>拉近同类样本</td></tr><tr><td>类间约束</td><td>间接（通过分类）</td><td>直接推远异类</td></tr><tr><td>特征分布</td><td>可能分散</td><td>紧密聚类</td></tr><tr><td>鲁棒性</td><td>一般</td><td>更强</td></tr><tr><td>计算复杂度</td><td>O(NC)</td><td>O(N²)</td></tr></tbody></table><p>其中N是batch size，C是类别数。</p><h2 id="背景知识">背景知识</h2><h3 id="对比学习简介">对比学习简介</h3><p>对比学习的核心思想是：<strong>通过对比正样本对和负样本对，学习到区分性的表示</strong>。</p><p><strong>无监督对比学习</strong>（如SimCLR、MoCo）：</p><ul><li>正样本：同一图像的不同增强视图</li><li>负样本：不同图像的增强视图</li><li>目标：学习到对数据增强不变的表示</li></ul><p><strong>关键挑战</strong>：</p><ul><li>需要大量负样本才能学到好的表示</li><li>对数据增强策略敏感</li><li>可能学到与下游任务无关的特征</li></ul><h3 id="监督学习与对比学习的结合">监督学习与对比学习的结合</h3><p><strong>传统监督学习（交叉熵）</strong>：</p><ul><li>只关注样本与标签的匹配</li><li>忽略了同类样本间的相似性</li><li>对对抗样本和噪声不够鲁棒</li></ul><p><strong>监督对比学习的优势</strong>：</p><ul><li>利用标签信息，正样本对更明确（同类样本）</li><li>负样本对更丰富（所有异类样本）</li><li>学习到的表示更具判别性和鲁棒性</li></ul><h2 id="论文核心思想">论文核心思想</h2><h3 id="主要贡献">主要贡献</h3><ol><li><strong>提出监督对比损失（Supervised Contrastive Loss）</strong>：将标签信息融入对比学习框架</li><li><strong>理论分析</strong>：证明了SupCon损失的梯度特性优于交叉熵</li><li><strong>实验验证</strong>：在ImageNet等数据集上取得SOTA性能，并显著提升鲁棒性</li></ol><h3 id="核心创新">核心创新</h3><p><strong>关键洞察</strong>：在监督学习中，同类样本应该聚集在一起，异类样本应该分离。这与对比学习的目标天然一致。</p><p><strong>方法</strong>：将同一类别的所有样本视为正样本，不同类别的样本视为负样本，构建对比学习目标。</p><h2 id="方法原理">方法原理</h2><h3 id="监督对比损失（Supervised-Contrastive-Loss）">监督对比损失（Supervised Contrastive Loss）</h3><p>给定一个batch的样本 ${x_1, x_2, …, x_N}$ 及其标签 ${y_1, y_2, …, y_N}$，对每个样本 $x_i$：</p><p>$$ \mathcal{L}_{sup} = \sum_{i=1}^{N} \mathcal{L}_{sup}^i $$</p><p>其中：</p><p>$$ \mathcal{L}_{sup}^i = -\frac{1}{|P(i)|} \sum_{p \in P(i)} \log \frac{\exp(z_i \cdot z_p / \tau)}{\sum_{a \in A(i)} \exp(z_i \cdot z_a / \tau)} $$</p><p><strong>符号说明</strong>：</p><ul><li>$z_i = f(x_i)$：样本 $x_i$ 的归一化特征表示</li><li>$P(i) = {p \in A(i): y_p = y_i}$：与 $x_i$ 同类的样本集合（正样本）</li><li>$A(i) = {1, 2, …, N} \backslash {i}$：除 $i$ 外的所有样本（正样本+负样本）</li><li>$\tau$：温度参数，控制分布的尖锐程度</li></ul><p><strong>直观理解</strong>：</p><ul><li>分子：拉近同类样本的相似度</li><li>分母：推远所有样本（包括异类和同类）的相似度</li><li>归一化：确保同类样本的贡献相等（$\frac{1}{|P(i)|}$）</li></ul><h3 id="与交叉熵损失的对比">与交叉熵损失的对比</h3><p><strong>交叉熵损失</strong>：</p><p>$$ \mathcal{L}_{CE} = -\log \frac{\exp(W_{y_i}^T z_i)}{\sum_{j=1}^{C} \exp(W_j^T z_i)} $$</p><p><strong>关键区别</strong>：</p><table><thead><tr><th>特性</th><th>交叉熵</th><th>监督对比损失</th></tr></thead><tbody><tr><td><strong>优化目标</strong></td><td>样本与分类器权重匹配</td><td>样本间相似性</td></tr><tr><td><strong>梯度特性</strong></td><td>只关注当前样本</td><td>同时考虑所有同类/异类样本</td></tr><tr><td><strong>表示学习</strong></td><td>间接（通过分类器）</td><td>直接（样本间关系）</td></tr><tr><td><strong>鲁棒性</strong></td><td>较弱</td><td>更强</td></tr></tbody></table><h3 id="训练流程">训练流程</h3><ol><li><strong>数据增强</strong>：对每个样本应用两次随机增强，得到两个视图</li><li><strong>特征提取</strong>：使用编码器 $f(\cdot)$ 提取特征</li><li><strong>归一化</strong>：对特征进行L2归一化</li><li><strong>计算损失</strong>：使用监督对比损失</li><li><strong>反向传播</strong>：更新编码器参数</li></ol><p><strong>注意</strong>：SupCon可以单独使用，也可以与交叉熵损失结合使用。</p><h2 id="损失函数详解">损失函数详解</h2><h3 id="温度参数-tau-的作用">温度参数 $\tau$ 的作用</h3><ul><li><strong>$\tau$ 较小</strong>：分布更尖锐，模型更关注困难样本</li><li><strong>$\tau$ 较大</strong>：分布更平滑，模型对所有样本的关注更均匀</li><li><strong>典型取值</strong>：0.07 或 0.1</li></ul><h3 id="梯度分析">梯度分析</h3><p><strong>SupCon损失的梯度特性</strong>：</p><p>$$ \frac{\partial \mathcal{L}_{sup}^i}{\partial z_i} = \frac{1}{\tau} \left[ \sum_{p \in P(i)} \frac{z_p}{|P(i)|} - \sum_{a \in A(i)} w_a z_a \right] $$</p><p>其中 $w_a$ 是softmax权重。</p><p><strong>关键观察</strong>：</p><ul><li>梯度包含<strong>所有同类样本</strong>的平均（第一项）</li><li>梯度包含<strong>所有样本</strong>的加权平均（第二项）</li><li>这比交叉熵只关注单个样本-权重匹配更丰富</li></ul><h3 id="与InfoNCE的关系">与InfoNCE的关系</h3><p>SupCon可以看作<strong>监督版本的InfoNCE</strong>：</p><ul><li>InfoNCE：正样本是同一图像的不同增强</li><li>SupCon：正样本是同一类别的所有样本</li></ul><h2 id="实验分析">实验分析</h2><h3 id="数据集">数据集</h3><p>论文在多个数据集上进行了实验：</p><ol><li><strong>ImageNet</strong>：大规模图像分类基准</li><li><strong>CIFAR-10/100</strong>：小规模图像分类</li><li><strong>STL-10</strong>：无监督/半监督学习基准</li></ol><h3 id="实验设置">实验设置</h3><p><strong>网络架构</strong>：</p><ul><li>ResNet-50/200 作为backbone</li><li>投影头：2层MLP（2048→128）</li></ul><p><strong>训练细节</strong>：</p><ul><li>优化器：LARS（ImageNet）或SGD</li><li>学习率：0.3（ImageNet）或0.1（CIFAR）</li><li>Batch size：1024（ImageNet）或256（CIFAR）</li><li>温度参数：$\tau = 0.07$</li><li>数据增强：RandomResizedCrop、ColorJitter、RandomHorizontalFlip等</li></ul><h3 id="实验结果">实验结果</h3><p><strong>ImageNet分类性能</strong>：</p><table><thead><tr><th>方法</th><th>Top-1 Acc</th><th>Top-5 Acc</th></tr></thead><tbody><tr><td>Cross-Entropy</td><td>76.5%</td><td>93.1%</td></tr><tr><td>SupCon</td><td><strong>78.0%</strong></td><td><strong>93.8%</strong></td></tr><tr><td>SupCon + CE</td><td><strong>78.4%</strong></td><td><strong>94.0%</strong></td></tr></tbody></table><p><strong>鲁棒性提升</strong>：</p><ul><li>对对抗攻击的鲁棒性显著提升</li><li>对常见数据损坏（噪声、模糊等）的鲁棒性更好</li><li>在长尾分布数据集上表现更优</li></ul><p><strong>消融实验</strong>：</p><ul><li>温度参数 $\tau$：0.07 效果最好</li><li>投影头维度：128维足够</li><li>数据增强：重要，但SupCon对增强策略的敏感性低于无监督对比学习</li></ul><h2 id="代码实现">代码实现</h2><h3 id="PyTorch实现">PyTorch实现</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SupConLoss</span>(nn.Module):</span><br><span class="line">    <span class="string">"""Supervised Contrastive Learning Loss"""</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, temperature=<span class="number">0.07</span>, base_temperature=<span class="number">0.07</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.temperature = temperature</span><br><span class="line">        <span class="variable language_">self</span>.base_temperature = base_temperature</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, features, labels</span>):</span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            features: hidden vector of shape [bsz, n_views, ...] or [bsz * n_views, ...].</span></span><br><span class="line"><span class="string">            labels: ground truth of shape [bsz].</span></span><br><span class="line"><span class="string">        Returns:</span></span><br><span class="line"><span class="string">            A loss scalar.</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        device = features.device</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 如果features是[batch_size, n_views, dim]，reshape为[batch_size * n_views, dim]</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(features.shape) &lt; <span class="number">3</span>:</span><br><span class="line">            features = features.unsqueeze(<span class="number">1</span>)</span><br><span class="line">        batch_size = features.shape[<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="comment"># 扩展labels以匹配增强后的样本数</span></span><br><span class="line">            labels = labels.contiguous().view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">            <span class="keyword">if</span> labels.shape[<span class="number">0</span>] != batch_size:</span><br><span class="line">                <span class="keyword">raise</span> ValueError(<span class="string">'Num of labels does not match num of features'</span>)</span><br><span class="line">            mask = torch.eq(labels, labels.T).<span class="built_in">float</span>().to(device)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 无监督情况：同一图像的增强视图为正样本</span></span><br><span class="line">            mask = torch.eye(batch_size, dtype=torch.float32).to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 归一化特征</span></span><br><span class="line">        features = F.normalize(features, dim=-<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算相似度矩阵</span></span><br><span class="line">        contrast_feature = features</span><br><span class="line">        anchor_feature = features</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算所有样本对之间的相似度</span></span><br><span class="line">        anchor_dot_contrast = torch.div(</span><br><span class="line">            torch.matmul(anchor_feature, contrast_feature.T),</span><br><span class="line">            <span class="variable language_">self</span>.temperature</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 数值稳定性：减去最大值</span></span><br><span class="line">        logits_max, _ = torch.<span class="built_in">max</span>(anchor_dot_contrast, dim=<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        logits = anchor_dot_contrast - logits_max.detach()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算exp</span></span><br><span class="line">        exp_logits = torch.exp(logits)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算log_prob</span></span><br><span class="line">        log_prob = logits - torch.log(exp_logits.<span class="built_in">sum</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算每个样本的正样本平均log_prob</span></span><br><span class="line">        mask = mask.repeat(<span class="number">1</span>, <span class="number">1</span>)  <span class="comment"># 扩展mask以匹配batch_size</span></span><br><span class="line">        mean_log_prob_pos = (mask * log_prob).<span class="built_in">sum</span>(<span class="number">1</span>) / mask.<span class="built_in">sum</span>(<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 损失</span></span><br><span class="line">        loss = - (<span class="variable language_">self</span>.temperature / <span class="variable language_">self</span>.base_temperature) * mean_log_prob_pos</span><br><span class="line">        loss = loss.mean()</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用示例</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SupConModel</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, encoder, projection_dim=<span class="number">128</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.encoder = encoder</span><br><span class="line">        <span class="variable language_">self</span>.projector = nn.Sequential(</span><br><span class="line">            nn.Linear(encoder.fc.in_features, <span class="number">2048</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.Linear(<span class="number">2048</span>, projection_dim)</span><br><span class="line">        )</span><br><span class="line">        <span class="comment"># 移除分类头（如果存在）</span></span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">hasattr</span>(encoder, <span class="string">'fc'</span>):</span><br><span class="line">            <span class="variable language_">self</span>.encoder.fc = nn.Identity()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        features = <span class="variable language_">self</span>.encoder(x)</span><br><span class="line">        projections = <span class="variable language_">self</span>.projector(features)</span><br><span class="line">        <span class="keyword">return</span> F.normalize(projections, dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练循环示例</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">model, images, labels, criterion, optimizer</span>):</span><br><span class="line">    <span class="comment"># 假设images已经是增强后的[batch_size, 2, C, H, W]</span></span><br><span class="line">    batch_size = images.shape[<span class="number">0</span>]</span><br><span class="line">    images = images.view(batch_size * <span class="number">2</span>, *images.shape[<span class="number">2</span>:])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    features = model(images)</span><br><span class="line">    features = features.view(batch_size, <span class="number">2</span>, -<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    loss = criterion(features, labels)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss.item()</span><br></pre></td></tr></tbody></table></figure><h3 id="简化版本">简化版本</h3><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">supervised_contrastive_loss</span>(<span class="params">features, labels, temperature=<span class="number">0.07</span></span>):</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    简化版监督对比损失</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        features: [batch_size, feature_dim] 归一化特征</span></span><br><span class="line"><span class="string">        labels: [batch_size] 标签</span></span><br><span class="line"><span class="string">        temperature: 温度参数</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    device = features.device</span><br><span class="line">    batch_size = features.shape[<span class="number">0</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算相似度矩阵</span></span><br><span class="line">    similarity_matrix = torch.matmul(features, features.T) / temperature</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 构建正样本mask（同类样本）</span></span><br><span class="line">    labels = labels.contiguous().view(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    mask = torch.eq(labels, labels.T).<span class="built_in">float</span>().to(device)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 移除自身</span></span><br><span class="line">    logits_mask = torch.scatter(</span><br><span class="line">        torch.ones_like(mask),</span><br><span class="line">        <span class="number">1</span>,</span><br><span class="line">        torch.arange(batch_size).view(-<span class="number">1</span>, <span class="number">1</span>).to(device),</span><br><span class="line">        <span class="number">0</span></span><br><span class="line">    )</span><br><span class="line">    mask = mask * logits_mask</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算exp</span></span><br><span class="line">    exp_logits = torch.exp(similarity_matrix) * logits_mask</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算log_prob</span></span><br><span class="line">    log_prob = similarity_matrix - torch.log(exp_logits.<span class="built_in">sum</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>) + <span class="number">1e-8</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 平均正样本的log_prob</span></span><br><span class="line">    mean_log_prob_pos = (mask * log_prob).<span class="built_in">sum</span>(<span class="number">1</span>) / (mask.<span class="built_in">sum</span>(<span class="number">1</span>) + <span class="number">1e-8</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 损失</span></span><br><span class="line">    loss = -mean_log_prob_pos.mean()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></tbody></table></figure><h2 id="技术细节与优化">技术细节与优化</h2><h3 id="数据增强策略">数据增强策略</h3><p>SupCon对数据增强的依赖低于无监督对比学习，但仍需要合理的增强：</p><p><strong>推荐增强</strong>：</p><ul><li>RandomResizedCrop</li><li>RandomHorizontalFlip</li><li>ColorJitter（适度）</li><li>RandomGrayscale（可选）</li></ul><p><strong>避免过度增强</strong>：过度增强可能破坏语义信息，反而降低性能。</p><h3 id="投影头设计">投影头设计</h3><ul><li><strong>层数</strong>：2层MLP通常足够</li><li><strong>维度</strong>：128-256维</li><li><strong>激活函数</strong>：ReLU或GELU</li><li><strong>归一化</strong>：输出层L2归一化</li></ul><h3 id="温度参数调优">温度参数调优</h3><ul><li><strong>起始值</strong>：0.07</li><li><strong>调优范围</strong>：0.05 - 0.2</li><li><strong>原则</strong>：如果模型难以区分困难样本，降低$\tau$；如果训练不稳定，提高$\tau$</li></ul><h2 id="优缺点分析">优缺点分析</h2><h3 id="优点">优点</h3><ol><li><strong>性能提升</strong>：在多个数据集上超越交叉熵损失</li><li><strong>鲁棒性强</strong>：对对抗样本、噪声、数据损坏更鲁棒</li><li><strong>表示质量高</strong>：学习到的特征更具判别性和泛化能力</li><li><strong>易于实现</strong>：损失函数简单，易于集成到现有框架</li></ol><h3 id="缺点">缺点</h3><ol><li><strong>计算成本</strong>：需要计算所有样本对的相似度，batch size较大时内存消耗高</li><li><strong>需要标签</strong>：相比无监督对比学习，需要标注数据</li><li><strong>超参数敏感</strong>：温度参数等需要仔细调优</li></ol><h2 id="与其他方法的关系">与其他方法的关系</h2><h3 id="vs-交叉熵损失">vs. 交叉熵损失</h3><ul><li><strong>交叉熵</strong>：关注样本-分类器匹配</li><li><strong>SupCon</strong>：关注样本-样本关系</li><li><strong>结合使用</strong>：SupCon + CE 通常效果最好</li></ul><h3 id="vs-无监督对比学习">vs. 无监督对比学习</h3><ul><li><strong>SimCLR/MoCo</strong>：正样本是同一图像的不同视图</li><li><strong>SupCon</strong>：正样本是同一类别的所有样本</li><li><strong>优势</strong>：SupCon利用标签信息，正样本对更明确</li></ul><h3 id="vs-三元组损失">vs. 三元组损失</h3><ul><li><strong>三元组损失</strong>：每次只考虑一个正样本和一个负样本</li><li><strong>SupCon</strong>：同时考虑所有正样本和负样本</li><li><strong>优势</strong>：SupCon的梯度更稳定，训练更高效</li></ul><h2 id="应用场景">应用场景</h2><ol><li><strong>图像分类</strong>：提升分类精度和鲁棒性</li><li><strong>长尾学习</strong>：在类别不平衡数据上表现优异</li><li><strong>少样本学习</strong>：学习到的表示泛化能力强</li><li><strong>鲁棒性训练</strong>：提升模型对对抗攻击的防御能力</li></ol><h2 id="总结">总结</h2><p>监督对比学习通过将标签信息融入对比学习框架，成功结合了监督学习和对比学习的优势。其核心思想是：<strong>同类样本应该聚集，异类样本应该分离</strong>。通过显式优化样本间的相似性关系，SupCon学习到的表示更具判别性、鲁棒性和泛化能力。</p><p>SupCon的提出证明了对比学习不仅适用于无监督场景，在监督学习中同样有效，为后续的对比学习研究提供了重要启发。</p><h2 id="参考文献">参考文献</h2><ol><li><p>Khosla, P., et al. (2020). Supervised Contrastive Learning. Advances in Neural Information Processing Systems, 33. <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2004.11362">https://arxiv.org/pdf/2004.11362</a></p></li><li><p>Chen, T., et al. (2020). A Simple Framework for Contrastive Learning of Visual Representations. ICML 2020.</p></li><li><p>He, K., et al. (2020). Momentum Contrast for Unsupervised Visual Representation Learning. CVPR 2020.</p></li><li><p>Hadsell, R., Chopra, S., &amp; LeCun, Y. (2006). Dimensionality reduction by learning an invariant mapping. CVPR 2006.</p></li></ol><h2 id="思考题">思考题</h2><ol><li>为什么监督对比学习比交叉熵损失更能提升模型的鲁棒性？</li><li>温度参数 $\tau$ 如何影响模型的学习？如何选择合适的 $\tau$？</li><li>在类别数量很多的情况下，SupCon损失的计算复杂度如何？如何优化？</li><li>SupCon与交叉熵损失结合使用时，如何平衡两者的权重？</li><li>监督对比学习在少样本学习场景下的优势是什么？</li></ol><h2 id="思考题答案">思考题答案</h2><h3 id="1-为什么监督对比学习比交叉熵损失更能提升模型的鲁棒性？">1. 为什么监督对比学习比交叉熵损失更能提升模型的鲁棒性？</h3><p><strong>原因分析</strong>：</p><ol><li><p><strong>表示学习方式不同</strong>：</p><ul><li>交叉熵：只关注样本与分类器权重的匹配，可能学到与分类器相关的脆弱特征</li><li>SupCon：直接优化样本间的相似性，学习到更本质的表示</li></ul></li><li><p><strong>梯度特性</strong>：</p><ul><li>交叉熵：梯度只来自当前样本与分类器的匹配</li><li>SupCon：梯度来自所有同类和异类样本，信息更丰富，训练更稳定</li></ul></li><li><p><strong>特征空间结构</strong>：</p><ul><li>交叉熵：可能形成不规则的决策边界</li><li>SupCon：显式地拉近同类、推远异类，形成更紧凑的类内分布和更大的类间间隔</li></ul></li><li><p><strong>对噪声的鲁棒性</strong>：</p><ul><li>SupCon通过对比学习，模型学会关注样本间的相对关系而非绝对特征，对噪声更鲁棒</li></ul></li></ol><h3 id="2-温度参数-tau-如何影响模型的学习？如何选择合适的-tau-？">2. 温度参数 $\tau$ 如何影响模型的学习？如何选择合适的 $\tau$？</h3><p><strong>$\tau$ 的影响</strong>：</p><ul><li><p><strong>$\tau$ 较小（如0.05）</strong>：</p><ul><li>分布更尖锐，模型更关注困难样本（hard negatives）</li><li>学习到的表示区分性更强</li><li>但可能训练不稳定，容易过拟合</li></ul></li><li><p><strong>$\tau$ 较大（如0.2）</strong>：</p><ul><li>分布更平滑，对所有样本的关注更均匀</li><li>训练更稳定</li><li>但可能学习到的表示区分性较弱</li></ul></li></ul><p><strong>选择策略</strong>：</p><ol><li><strong>起始值</strong>：从0.07开始（论文推荐值）</li><li><strong>观察训练曲线</strong>：<ul><li>如果损失下降很快但验证集性能差 → 降低$\tau$</li><li>如果训练不稳定或损失不下降 → 提高$\tau$</li></ul></li><li><strong>网格搜索</strong>：在[0.05, 0.1, 0.15, 0.2]范围内搜索</li><li><strong>任务相关</strong>：<ul><li>细粒度分类（类别相似度高）→ 较小的$\tau$</li><li>粗粒度分类（类别差异大）→ 较大的$\tau$</li></ul></li></ol><h3 id="3-在类别数量很多的情况下，SupCon损失的计算复杂度如何？如何优化？">3. 在类别数量很多的情况下，SupCon损失的计算复杂度如何？如何优化？</h3><p><strong>复杂度分析</strong>：</p><ul><li><strong>时间复杂度</strong>：$O(N^2 \cdot d)$，其中$N$是batch size，$d$是特征维度</li><li><strong>空间复杂度</strong>：$O(N^2)$（相似度矩阵）</li></ul><p><strong>优化策略</strong>：</p><ol><li><p><strong>减小batch size</strong>：</p><ul><li>使用梯度累积保持有效batch size</li><li>或使用负样本采样（但会损失部分性能）</li></ul></li><li><p><strong>混合精度训练</strong>：</p><ul><li>使用FP16/BF16降低内存和计算成本</li></ul></li><li><p><strong>分布式训练</strong>：</p><ul><li>将batch分散到多个GPU，每个GPU计算部分损失</li></ul></li><li><p><strong>近似方法</strong>：</p><ul><li>只计算部分负样本（如hard negative mining）</li><li>使用memory bank存储历史特征（类似MoCo）</li></ul></li><li><p><strong>损失近似</strong>：</p><ul><li>使用NCE（Noise Contrastive Estimation）近似</li><li>或使用采样方法估计分母</li></ul></li></ol><h3 id="4-SupCon与交叉熵损失结合使用时，如何平衡两者的权重？">4. SupCon与交叉熵损失结合使用时，如何平衡两者的权重？</h3><p><strong>结合方式</strong>：</p><p>$$ \mathcal{L}_{total} = \lambda_{sup} \mathcal{L}_{sup} + \lambda_{ce} \mathcal{L}_{ce} $$</p><p><strong>权重选择策略</strong>：</p><ol><li><p><strong>等权重</strong>：$\lambda_{sup} = \lambda_{ce} = 1.0$（常见起始点）</p></li><li><p><strong>动态调整</strong>：</p><ul><li>早期训练：$\lambda_{sup}$较大，学习好的表示</li><li>后期训练：$\lambda_{ce}$较大，微调分类边界</li></ul></li><li><p><strong>任务相关</strong>：</p><ul><li>如果表示学习更重要（如few-shot）→ 增大$\lambda_{sup}$</li><li>如果分类精度更重要 → 增大$\lambda_{ce}$</li></ul></li><li><p><strong>实验验证</strong>：</p><ul><li>在验证集上搜索：$\lambda_{sup} \in [0.5, 1.0, 1.5, 2.0]$</li><li>通常$\lambda_{sup} = 1.0, \lambda_{ce} = 0.5$效果较好</li></ul></li></ol><p><strong>注意事项</strong>：</p><ul><li>两个损失的尺度可能不同，需要归一化或调整权重</li><li>可以先用SupCon预训练，再用CE微调</li></ul><h3 id="5-监督对比学习在少样本学习场景下的优势是什么？">5. 监督对比学习在少样本学习场景下的优势是什么？</h3><p><strong>优势分析</strong>：</p><ol><li><p><strong>更好的表示学习</strong>：</p><ul><li>SupCon学习到的特征更具判别性和泛化能力</li><li>即使样本少，也能学到类别的本质特征</li></ul></li><li><p><strong>类内紧凑性</strong>：</p><ul><li>显式拉近同类样本，形成紧凑的类内分布</li><li>在少样本情况下，这有助于减少类内方差</li></ul></li><li><p><strong>类间分离性</strong>：</p><ul><li>显式推远异类样本，增大类间间隔</li><li>在少样本情况下，这有助于提高分类精度</li></ul></li><li><p><strong>数据效率</strong>：</p><ul><li>每个样本都参与多个正样本对和负样本对的学习</li><li>充分利用有限的标注数据</li></ul></li><li><p><strong>泛化能力</strong>：</p><ul><li>学习到的表示对数据增强、噪声等更鲁棒</li><li>在测试时遇到新样本时泛化更好</li></ul></li></ol><p><strong>实际应用</strong>：</p><ul><li>在few-shot learning中，先用SupCon在base classes上预训练</li><li>然后在novel classes上用few-shot learning方法微调</li><li>通常能取得比直接使用交叉熵更好的效果</li></ul></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://wp-a.github.io">WP</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://wp-a.github.io/2025/11/%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">https://wp-a.github.io/2025/11/%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://wp-a.github.io" target="_blank">WPIRONMAN</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/">对比学习</a><a class="post-meta__tags" href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><a class="post-meta__tags" href="/tags/%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/">监督学习</a></div><div class="post-share"><div class="social-share" data-image="https://wpironman.oss-cn-qingdao.aliyuncs.com/202511111359964.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.4/sharejs/dist/css/share.min.css" media="print" onload="this.media=&quot;all&quot;"><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.4/sharejs/dist/js/social-share.min.js" defer=""></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/123.JPG" target="_blank"><img class="post-qr-code-img" src="/img/123.JPG" alt="微信" loading="lazy"></a><div class="post-qr-code-desc">微信</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/11/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/" title="对比学习综述"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/1.webp" onerror="onerror=null,src=&quot;/img/404.jpg&quot;" alt="cover of previous post" loading="lazy"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">对比学习综述</div></div><div class="info-2"><div class="info-item-1">对比学习综述：从理论到实践全面解析 引言 对比学习（Contrastive Learning） 是近年来自监督学习领域最重要的突破之一，它通过"拉近正样本、推远负样本"的简单思想，在无需大量标注数据的情况下学习到强大的视觉表示。从2020年的SimCLR、MoCo开始，对比学习在ImageNet等基准上取得了与监督学习相当甚至更好的性能，彻底改变了我们对无监督表示学习的认知。 对比学习的核心优势在于： 无需标注数据：可以在海量无标注图像上预训练 学习鲁棒表示：对数据增强、噪声等具有强鲁棒性 迁移能力强：预训练的特征在下游任务上表现优异 可扩展性好：可以轻松扩展到大规模数据和模型 什么是对比学习？ 核心思想 对比学习的核心思想可以用一句话概括：通过对比正样本对和负样本对，学习到区分性的表示。 正样本对（Positive Pairs）：应该相似的样本对 无监督：同一图像的不同增强视图 有监督：同一类别的不同样本 负样本对（Negative...</div></div></div></a><a class="pagination-related" href="/2025/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%B0%88%EF%BC%9A%E6%AE%8B%E5%B7%AE%E3%80%81MAE%E4%B8%8E%E7%89%B9%E5%BE%81%E7%BB%B4%E5%BA%A6%E7%9A%84%E6%9C%AC%E8%B4%A8%E6%80%9D%E8%80%83/" title="深度学习杂谈：残差、MAE与特征维度的本质思考"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/2.webp" onerror="onerror=null,src=&quot;/img/404.jpg&quot;" alt="cover of next post" loading="lazy"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">深度学习杂谈：残差、MAE与特征维度的本质思考</div></div><div class="info-2"><div class="info-item-1">最近有一些问题，正好记录下来了一些，用AI探讨了一下这些问题。 1. 残差 (Residual) 的本质：仅仅是保留原始信息吗？ 问题： 残差的本质是什么？为什么有用？是因为保留了之前的原始信息的特征吗？那么添加动量 (Momentum) 也是保留之前的原始信息，和残差的本质有什么区别吗？ 残差连接 (Skip Connection) 残差网络 (ResNet) 的核心公式是 $y = F(x) + x$。 确实，从直观上看，$+x$ 这一项直接将上一层的原始信息“保留”并传递到了下一层。这使得网络在初始化阶段即使 $F(x)$ 接近于 0，整个网络也近似于一个恒等映射 (Identity Mapping)，梯度可以无损地反向传播。 本质区别： 残差 (ResNet) 解决的是 模型结构 (Model Architecture) 和 梯度流 (Gradient Flow) 的问题。它是在空间/层级维度上，让深层网络更容易训练，避免梯度消失。它让网络“有机会”去学习恒等映射，如果某一层是多余的，网络可以将 $F(x)$ 权重置为 0，自动“跳过”这一层。 动量...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/11/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/" title="对比学习综述"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/1.webp" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-13</div><div class="info-item-2">对比学习综述</div></div><div class="info-2"><div class="info-item-1">对比学习综述：从理论到实践全面解析 引言 对比学习（Contrastive Learning） 是近年来自监督学习领域最重要的突破之一，它通过"拉近正样本、推远负样本"的简单思想，在无需大量标注数据的情况下学习到强大的视觉表示。从2020年的SimCLR、MoCo开始，对比学习在ImageNet等基准上取得了与监督学习相当甚至更好的性能，彻底改变了我们对无监督表示学习的认知。 对比学习的核心优势在于： 无需标注数据：可以在海量无标注图像上预训练 学习鲁棒表示：对数据增强、噪声等具有强鲁棒性 迁移能力强：预训练的特征在下游任务上表现优异 可扩展性好：可以轻松扩展到大规模数据和模型 什么是对比学习？ 核心思想 对比学习的核心思想可以用一句话概括：通过对比正样本对和负样本对，学习到区分性的表示。 正样本对（Positive Pairs）：应该相似的样本对 无监督：同一图像的不同增强视图 有监督：同一类别的不同样本 负样本对（Negative...</div></div></div></a><a class="pagination-related" href="/2025/04/MoCo/" title="MoCo"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/20250425170023257.png" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-24</div><div class="info-item-2">MoCo</div></div><div class="info-2"><div class="info-item-1">MoCo Momentum Contrast for Unsupervised Visual Representation Learning (cvpr2020) 论文地址：https://arxiv.org/pdf/1911.05722 代码地址：https://github.com/facebookresearch/moco 概述 MoCo 将对比学习看作是一个字典查找任务 ：一个编码后的查询（query）应该与其匹配的键（正样本）相似，而与其他所有的键（负样本）不相似 。 对比学习的核心思想是训练一个编码器，使其能够区分相似（正样本）和不相似（负样本）的样本 。 传统方法 VS MoCo 端到端（End-to-end）方法（SimCLR，Inva Spread）：将当前 mini-batch 内的样本作为字典 。这种方法的优点是字典中的键编码是一致的（由同一个编码器生成），但缺点是字典的大小受限于 mini-batch 的大小，而 mini-batch 大小又受限于 GPU 内存 。过大的 mini-batch 也会带来优化难题 。 Memory Bank...</div></div></div></a><a class="pagination-related" href="/2025/11/%E5%AE%9E%E4%BE%8B%E5%88%A4%E5%88%AB%E5%AD%A6%E4%B9%A0/" title="实例判别学习 - Non-Parametric Instance Discrimination精读"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/202511122017857.png" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-11-11</div><div class="info-item-2">实例判别学习 - Non-Parametric Instance Discrimination精读</div></div><div class="info-2"><div class="info-item-1">Unsupervised Feature Learning via Non-Parametric Instance Discrimination 论文地址：https://arxiv.org/pdf/1805.01978 代码地址：https://github.com/zhirongw/lemniscate.pytorch 引言 实例判别（Instance Discrimination）...</div></div></div></a><a class="pagination-related" href="/2025/04/%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/" title="基于深度学习的图像分类"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/20250417222715500.png" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-04-15</div><div class="info-item-2">基于深度学习的图像分类</div></div><div class="info-2"><div class="info-item-1">使用ResNet18预训练模型 由于笔记本性能太差，所以在服务器上运行的，显卡配置为4090。经大量实验判断，初始学习率为0.01最后效果较差，所以初始学习率应设为0.001。全部代码代码已上传到：https://github.com/wp-a/-CIFAR10-.git 库函数导入 123456789import matplotlib.pyplot as pltimport torchimport torch.nn as nnimport torchvisionimport torchvision.transforms as transformsfrom sklearn.metrics import confusion_matrix, classification_reportfrom itertools import chainimport multiprocessingdevice = torch.device("cuda:0" if torch.cuda.is_available() else...</div></div></div></a><a class="pagination-related" href="/2025/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" title="深度学习损失函数：从 MSE 到 Focal Loss"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/202512032137895.png" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-03</div><div class="info-item-2">深度学习损失函数：从 MSE 到 Focal Loss</div></div><div class="info-2"><div class="info-item-1">在深度学习中，损失函数 (Loss Function) 是连接模型预测与真实标签的桥梁，它定义了模型的优化目标。选择合适的损失函数往往能起到事半功倍的效果。本文将对深度学习中常见的损失函数进行梳理，从基础的回归/分类到进阶的难例挖掘和度量学习。 1. 回归任务 (Regression) 回归任务的目标是预测连续值。 1.1 MSE (L2 Loss) 均方误差 (Mean Squared Error)： $$ L = (y - \hat{y})^2 $$ 特点：收敛快，但对异常值 (Outliers) 非常敏感（因为误差被平方放大了）。 1.2 MAE (L1 Loss) 平均绝对误差 (Mean Absolute Error)： $$ L = |y - \hat{y}| $$ 特点：对异常值鲁棒，但在 0 点处不可导，梯度恒定可能导致收敛困难。 1.3 Smooth L1 Loss 结合了 L1 和 L2 的优点： 在误差较小时（$|x| &lt; 1$）使用 L2（平滑，可导）。 在误差较大时（$|x| \ge 1$）使用...</div></div></div></a><a class="pagination-related" href="/2025/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BC%98%E5%8C%96%E5%99%A8/" title="深度学习优化器全家桶：从 SGD 到 AdamW 及未来"><img class="cover" src="https://wpironman.oss-cn-qingdao.aliyuncs.com/202512032137895.png" alt="cover" loading="lazy"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-12-03</div><div class="info-item-2">深度学习优化器全家桶：从 SGD 到 AdamW 及未来</div></div><div class="info-2"><div class="info-item-1">在深度学习的训练过程中，优化器 (Optimizer) 扮演着至关重要的角色。它决定了网络参数更新的方式，直接影响模型的收敛速度和最终性能。本文将深入剖析深度学习中常见的优化器，从最基础的 SGD 到目前最流行的 AdamW，以及一些前沿的变体。 1. 梯度下降家族 (Gradient Descent Variants) 1.1 BGD, SGD 与 Mini-batch SGD BGD (Batch Gradient Descent)：每次迭代使用全部样本计算梯度。 优点：梯度准确，收敛稳定。 缺点：计算量大，内存无法承受，无法在线更新。 SGD (Stochastic Gradient Descent)：每次迭代使用一个样本。 优点：计算快，引入噪声有助于跳出局部最优。 缺点：震荡剧烈，收敛慢，无法利用向量化加速。 Mini-batch SGD：折中方案，每次使用一批样本（如 32, 64）。这是实际中最常用的形式。 $$ w_{t+1} = w_t - \eta \cdot \nabla L(w_t) $$ 1.2 Momentum (动量法) 为了抑制...</div></div></div></a></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div><h1 id="site-title" fetchpriority="high" style="font-display:swap">监督对比学习</h1></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content is-expand"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">Supervised Contrastive Learning</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%A8%80"><span class="toc-number">1.1.</span> <span class="toc-text">引言</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%EF%BC%9F"><span class="toc-number">1.1.1.</span> <span class="toc-text">为什么需要监督对比学习？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E5%AF%B9%E6%AF%94"><span class="toc-number">1.1.2.</span> <span class="toc-text">方法对比</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%83%8C%E6%99%AF%E7%9F%A5%E8%AF%86"><span class="toc-number">1.2.</span> <span class="toc-text">背景知识</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B"><span class="toc-number">1.2.1.</span> <span class="toc-text">对比学习简介</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E4%B8%8E%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%9A%84%E7%BB%93%E5%90%88"><span class="toc-number">1.2.2.</span> <span class="toc-text">监督学习与对比学习的结合</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%BA%E6%96%87%E6%A0%B8%E5%BF%83%E6%80%9D%E6%83%B3"><span class="toc-number">1.3.</span> <span class="toc-text">论文核心思想</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BB%E8%A6%81%E8%B4%A1%E7%8C%AE"><span class="toc-number">1.3.1.</span> <span class="toc-text">主要贡献</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%B8%E5%BF%83%E5%88%9B%E6%96%B0"><span class="toc-number">1.3.2.</span> <span class="toc-text">核心创新</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%96%B9%E6%B3%95%E5%8E%9F%E7%90%86"><span class="toc-number">1.4.</span> <span class="toc-text">方法原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E6%8D%9F%E5%A4%B1%EF%BC%88Supervised-Contrastive-Loss%EF%BC%89"><span class="toc-number">1.4.1.</span> <span class="toc-text">监督对比损失（Supervised Contrastive Loss）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8E%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E7%9A%84%E5%AF%B9%E6%AF%94"><span class="toc-number">1.4.2.</span> <span class="toc-text">与交叉熵损失的对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E6%B5%81%E7%A8%8B"><span class="toc-number">1.4.3.</span> <span class="toc-text">训练流程</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.5.</span> <span class="toc-text">损失函数详解</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0-tau-%E7%9A%84%E4%BD%9C%E7%94%A8"><span class="toc-number">1.5.1.</span> <span class="toc-text">温度参数 $\tau$ 的作用</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A2%AF%E5%BA%A6%E5%88%86%E6%9E%90"><span class="toc-number">1.5.2.</span> <span class="toc-text">梯度分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8EInfoNCE%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.5.3.</span> <span class="toc-text">与InfoNCE的关系</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E5%88%86%E6%9E%90"><span class="toc-number">1.6.</span> <span class="toc-text">实验分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.6.1.</span> <span class="toc-text">数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE"><span class="toc-number">1.6.2.</span> <span class="toc-text">实验设置</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="toc-number">1.6.3.</span> <span class="toc-text">实验结果</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.7.</span> <span class="toc-text">代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#PyTorch%E5%AE%9E%E7%8E%B0"><span class="toc-number">1.7.1.</span> <span class="toc-text">PyTorch实现</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AE%80%E5%8C%96%E7%89%88%E6%9C%AC"><span class="toc-number">1.7.2.</span> <span class="toc-text">简化版本</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8A%80%E6%9C%AF%E7%BB%86%E8%8A%82%E4%B8%8E%E4%BC%98%E5%8C%96"><span class="toc-number">1.8.</span> <span class="toc-text">技术细节与优化</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%BC%BA%E7%AD%96%E7%95%A5"><span class="toc-number">1.8.1.</span> <span class="toc-text">数据增强策略</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8A%95%E5%BD%B1%E5%A4%B4%E8%AE%BE%E8%AE%A1"><span class="toc-number">1.8.2.</span> <span class="toc-text">投影头设计</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0%E8%B0%83%E4%BC%98"><span class="toc-number">1.8.3.</span> <span class="toc-text">温度参数调优</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BC%98%E7%BC%BA%E7%82%B9%E5%88%86%E6%9E%90"><span class="toc-number">1.9.</span> <span class="toc-text">优缺点分析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BC%98%E7%82%B9"><span class="toc-number">1.9.1.</span> <span class="toc-text">优点</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%BC%BA%E7%82%B9"><span class="toc-number">1.9.2.</span> <span class="toc-text">缺点</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%B8%8E%E5%85%B6%E4%BB%96%E6%96%B9%E6%B3%95%E7%9A%84%E5%85%B3%E7%B3%BB"><span class="toc-number">1.10.</span> <span class="toc-text">与其他方法的关系</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#vs-%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.10.1.</span> <span class="toc-text">vs. 交叉熵损失</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vs-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0"><span class="toc-number">1.10.2.</span> <span class="toc-text">vs. 无监督对比学习</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#vs-%E4%B8%89%E5%85%83%E7%BB%84%E6%8D%9F%E5%A4%B1"><span class="toc-number">1.10.3.</span> <span class="toc-text">vs. 三元组损失</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">1.11.</span> <span class="toc-text">应用场景</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">1.12.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE"><span class="toc-number">1.13.</span> <span class="toc-text">参考文献</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98"><span class="toc-number">1.14.</span> <span class="toc-text">思考题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%9D%E8%80%83%E9%A2%98%E7%AD%94%E6%A1%88"><span class="toc-number">1.15.</span> <span class="toc-text">思考题答案</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-%E4%B8%BA%E4%BB%80%E4%B9%88%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E6%AF%94%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E6%9B%B4%E8%83%BD%E6%8F%90%E5%8D%87%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%B2%81%E6%A3%92%E6%80%A7%EF%BC%9F"><span class="toc-number">1.15.1.</span> <span class="toc-text">1. 为什么监督对比学习比交叉熵损失更能提升模型的鲁棒性？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-%E6%B8%A9%E5%BA%A6%E5%8F%82%E6%95%B0-tau-%E5%A6%82%E4%BD%95%E5%BD%B1%E5%93%8D%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AD%A6%E4%B9%A0%EF%BC%9F%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9%E5%90%88%E9%80%82%E7%9A%84-tau-%EF%BC%9F"><span class="toc-number">1.15.2.</span> <span class="toc-text">2. 温度参数 $\tau$ 如何影响模型的学习？如何选择合适的 $\tau$？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-%E5%9C%A8%E7%B1%BB%E5%88%AB%E6%95%B0%E9%87%8F%E5%BE%88%E5%A4%9A%E7%9A%84%E6%83%85%E5%86%B5%E4%B8%8B%EF%BC%8CSupCon%E6%8D%9F%E5%A4%B1%E7%9A%84%E8%AE%A1%E7%AE%97%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%A6%82%E4%BD%95%EF%BC%9F%E5%A6%82%E4%BD%95%E4%BC%98%E5%8C%96%EF%BC%9F"><span class="toc-number">1.15.3.</span> <span class="toc-text">3. 在类别数量很多的情况下，SupCon损失的计算复杂度如何？如何优化？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-SupCon%E4%B8%8E%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1%E7%BB%93%E5%90%88%E4%BD%BF%E7%94%A8%E6%97%B6%EF%BC%8C%E5%A6%82%E4%BD%95%E5%B9%B3%E8%A1%A1%E4%B8%A4%E8%80%85%E7%9A%84%E6%9D%83%E9%87%8D%EF%BC%9F"><span class="toc-number">1.15.4.</span> <span class="toc-text">4. SupCon与交叉熵损失结合使用时，如何平衡两者的权重？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E5%9C%A8%E5%B0%91%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0%E5%9C%BA%E6%99%AF%E4%B8%8B%E7%9A%84%E4%BC%98%E5%8A%BF%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">1.15.5.</span> <span class="toc-text">5. 监督对比学习在少样本学习场景下的优势是什么？</span></a></li></ol></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">©2025 - 2026 By WP</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text"><div id="runtime"></div></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js" defer=""></script><script src="/js/main.js" defer=""></script><script src="https://cdn.jsdelivr.net/npm/instant.page@5.1.0/instantpage.min.js" type="module"></script><div class="js-pjax"><script>(()=>{var t=()=>{var t;window.MathJax?(MathJax.startup.document.state(0),MathJax.texReset(),MathJax.typesetPromise()):(window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],tags:"none"},chtml:{scale:1.1},options:{enableMenu:!0,renderActions:{findScript:[10,t=>{for(var e of document.querySelectorAll('script[type^="math/tex"]')){var a=!!e.type.match(/; *mode=display/),a=new t.options.MathItem(e.textContent,t.inputJax[0],a),n=document.createTextNode("");e.parentNode.replaceChild(n,e),a.start={node:n,delim:"",n:0},a.end={node:n,delim:"",n:0},t.math.push(a)}},""]}}},(t=document.createElement("script")).src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js",t.id="MathJax-script",t.async=!0,document.head.appendChild(t))};btf.addGlobalFn("encrypt",t,"mathjax"),window.pjax?t():window.addEventListener("load",t)})()</script><script>(()=>{var e=()=>{var e;0!==(e=document.querySelectorAll("pre > code.mermaid")).length&&e.forEach(e=>{var t=document.createElement("pre"),a=(t.className="mermaid-src",t.hidden=!0,t.textContent=e.textContent,document.createElement("div"));a.className="mermaid-wrap",a.appendChild(t),e.parentNode.replaceWith(a)});let t=document.querySelectorAll("#article-container .mermaid-wrap");0!==t.length&&(e=()=>(e=>{window.loadMermaid=!0;let n="dark"===document.documentElement.getAttribute("data-theme")?"dark":"default";e.forEach((e,t)=>{let a=e.firstElementChild;e=`%%{init:{ 'theme':'${n}'}}%%
`+a.textContent,t=mermaid.render("mermaid-"+t,e);let d=e=>{a.insertAdjacentHTML("afterend",e)};"string"==typeof t?d(t):t.then(({svg:e})=>d(e))})})(t),btf.addGlobalFn("themeChange",e,"mermaid"),window.loadMermaid?e():btf.getScript("https://cdnjs.cloudflare.com/ajax/libs/mermaid/11.4.1/mermaid.min.js").then(e))};btf.addGlobalFn("encrypt",e,"mermaid"),window.pjax?e():document.addEventListener("DOMContentLoaded",e)})()</script><script>(()=>{let n="shuoshuo"===GLOBAL_CONFIG_SITE.pageType,o=null,a=(t,e)=>{n&&(window.shuoshuoComment.destroyValine=()=>{t.children.length&&(t.innerHTML="",t.classList.add("no-comment"))});e={el:"#vcomment",appId:"FXG14lTbR0Yj3W2kb3tkAt4L-gzGzoHsz",appKey:"hohJIUW6lOhfboJzq5FvG8z7",avatar:"monsterid",serverURLs:"https://fxg14ltb.lc-cn-n1-shared.com",emojiMaps:"",visitor:!1,...o,path:n?e:o&&o.path||window.location.pathname};new Valine(e)};var t=async(t,e)=>{"function"==typeof Valine||await btf.getScript("https://unpkg.com/valine@1.5.1/dist/Valine.min.js"),a(t,e)};n?window.shuoshuoComment={loadComment:t}:setTimeout(t,0)})()</script></div><script type="text/javascript" src="/js/reward.js" defer=""></script><script src="/js/fix-avatar.js" defer=""></script><script src="/js/blog-cool-features.js" defer=""></script><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.4/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,POWERMODE.mobile=!1,document.body.addEventListener("input",POWERMODE)</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.min.js" defer=""></script><script>(()=>{window.pjax=new Pjax({elements:'a:not([target="_blank"]):not([href="/music/"]):not([href="/gallery/"]):not([href="/about/"])',selectors:["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"],cacheBust:!1,analytics:!1,scrollRestoration:!1});let t=e=>{e&&Object.values(e).forEach(e=>e())};document.addEventListener("pjax:send",()=>{btf.removeGlobalFnEvent("pjaxSendOnce"),btf.removeGlobalFnEvent("themeChange");var e=document.body.classList;e.contains("read-mode")&&e.remove("read-mode"),t(window.globalFn.pjaxSend)}),document.addEventListener("pjax:complete",()=>{btf.removeGlobalFnEvent("pjaxCompleteOnce"),document.querySelectorAll("script[data-pjax]").forEach(e=>{let t=document.createElement("script");var a=e.text||e.textContent||e.innerHTML||"";Array.from(e.attributes).forEach(e=>t.setAttribute(e.name,e.value)),t.appendChild(document.createTextNode(a)),e.parentNode.replaceChild(t,e)}),t(window.globalFn.pjaxComplete)}),document.addEventListener("pjax:error",e=>{404===e.request.status&&pjax.loadUrl("/404.html")})})()</script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js" defer=""></script></div></div><script data-pjax="" src="/js/githubcalendar-loader.js?v=20251124"></script><script data-pjax="">function GithubCalendarConfig(){var t=document.getElementById("recent-posts");t&&"/"==location.pathname&&(console.log("已挂载hexo-github-calendar https://github.com/Barry-Flynn/hexo-github-calendar"),t.insertAdjacentHTML("afterbegin",'<div class="recent-post-item" style="width:100%;height:auto;padding:10px;"><div id="github_loading" style="width:10%;height:100%;margin:0 auto;display: block"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"  viewBox="0 0 50 50" style="enable-background:new 0 0 50 50" xml:space="preserve"><path fill="#d0d0d0" d="M25.251,6.461c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615V6.461z" transform="rotate(275.098 25 25)"><animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform></path></svg></div><div id="github_container"></div></div>')),GithubCalendar("https://github-calendar-api.meta-code.top/api?user=wp-a",["#ebedf0","#a2f7af","#6ce480","#54ad63","#469252","#31753c","#1f5f2a","#13531f","#084111","#032b09","#000000"],"wp-a")}document.getElementById("recent-posts")&&GithubCalendarConfig()</script><style>#github_container{min-height:280px}@media screen and (max-width:650px){#github_container{min-height:0}}</style><style></style></body></html>