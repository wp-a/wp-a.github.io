<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>代码随想录--二叉树</title>
    <url>/2025/02/10day/</url>
    <content><![CDATA[二叉树层序遍历
二叉树层序遍历的模板

第一种方法看了一遍代码+写 花了16分钟，挺简单的，递归法就先不看了。
class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123;        queue&lt;TreeNode*&gt; q;        if(root!=NULL) q.push(root);        vector&lt;vector&lt;int&gt;&gt; res;        while(!q.empty())&#123;            int size=q.size();            vector&lt;int&gt; re;            for(int i=0;i&lt;size;i++)            &#123;                TreeNode* node = q.front();                q.pop();                re.push_back(node-&gt;val);                if(node-&gt;left) q.push(node-&gt;left);                if(node-&gt;right) q.push(node-&gt;right);            &#125;            res.push_back(re);        &#125;        return res;    &#125;&#125;;
# 递归法class Solution &#123;public:    void order(TreeNode* cur, vector&lt;vector&lt;int&gt;&gt;&amp; result, int depth)    &#123;        if (cur == nullptr) return;        if (result.size() == depth) result.push_back(vector&lt;int&gt;());        result[depth].push_back(cur-&gt;val);        order(cur-&gt;left, result, depth + 1);        order(cur-&gt;right, result, depth + 1);    &#125;    vector&lt;vector&lt;int&gt;&gt; levelOrder(TreeNode* root) &#123;        vector&lt;vector&lt;int&gt;&gt; result;        int depth = 0;        order(root, result, depth);        return result;    &#125;&#125;;
二叉树的层序遍历 II
题目链接：107. 二叉树的层序遍历 II
五分钟结束战斗，就是上一个代码翻一下。但是性能有点慢，又交了一次时间也是超100%了。
class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; levelOrderBottom(TreeNode* root) &#123;        queue&lt;TreeNode*&gt; q;        if(root!=NULL) q.push(root);        vector&lt;vector&lt;int&gt;&gt; res;        while(!q.empty())&#123;            int size=q.size();            vector&lt;int&gt; re;            for(int i=0;i&lt;size;i++)&#123;                TreeNode* node=q.front();                q.pop();                re.push_back(node-&gt;val);                if(node-&gt;left) q.push(node-&gt;left);                if(node-&gt;right) q.push(node-&gt;right);            &#125;            res.push_back(re);        &#125;        reverse(res.begin(),res.end());        return res;    &#125;&#125;;
二叉树的右视图
题目链接：199. 二叉树的右视图
四分钟解决战斗，思考了不到一分钟。
class Solution &#123;public:    vector&lt;int&gt; rightSideView(TreeNode* root) &#123;        queue&lt;TreeNode*&gt; q;        if(root!=NULL) q.push(root);        vector&lt;int&gt; res;        while(!q.empty())&#123;            int size=q.size();            vector&lt;int&gt; re;            for(int i=0;i&lt;size;i++)            &#123;                TreeNode* node=q.front();                q.pop();                re.push_back(node-&gt;val);                 //代码随想录 if (i == (size - 1)) result.push_back(node-&gt;val);                 if(node-&gt;left) q.push(node-&gt;left);                if(node-&gt;right) q.push(node-&gt;right);            &#125;            res.push_back(re[size-1]);        &#125;        return res;    &#125;&#125;;
二叉树的层平均值
题目链接：637. 二叉树的层平均值
出了一点小插曲，花了五分钟，前边写的q后边写成p了，double第一次用的int忘了改。
class Solution &#123;public:    vector&lt;double&gt; averageOfLevels(TreeNode* root) &#123;        queue&lt;TreeNode*&gt; q;        if(root!=NULL) q.push(root);        vector&lt;double&gt; res;        while(!q.empty())&#123;            int s=q.size();            double sum=0;            for(int i=0;i&lt;s;i++)&#123;                TreeNode* node=q.front();                q.pop();                sum+=node-&gt;val;                if(node-&gt;left) q.push(node-&gt;left);                if(node-&gt;right) q.push(node-&gt;right);            &#125;            res.push_back(sum/s);        &#125;        return res;    &#125;&#125;;
N 叉树的层序遍历
题目链接：429. N 叉树的层序遍历
乍一看以为是第一题，看了一下不太明白孩子是啥意思，就直接看的题解，其实也没多大区别。
class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; levelOrder(Node* root) &#123;        queue&lt;Node*&gt; que;        if (root != NULL) que.push(root);        vector&lt;vector&lt;int&gt;&gt; result;        while (!que.empty()) &#123;            int size = que.size();            vector&lt;int&gt; vec;            for (int i = 0; i &lt; size; i++) &#123;                Node* node = que.front();                que.pop();                vec.push_back(node-&gt;val);                for (int i = 0; i &lt; node-&gt;children.size(); i++) &#123; // 将节点孩子加入队列                    if (node-&gt;children[i]) que.push(node-&gt;children[i]);                &#125;            &#125;            result.push_back(vec);        &#125;        return result;    &#125;&#125;;
在每个树行中找最大值
题目链接：515. 在每个树行中找最大值
花了8分钟，因为INT_MIN不知道如何操作，本来用的int，然后改成long long一点一点试的。
class Solution &#123;public:    vector&lt;int&gt; largestValues(TreeNode* root) &#123;        queue&lt;TreeNode*&gt; q;        if(root!=NULL) q.push(root);        vector&lt;int&gt; res;        while(!q.empty())&#123;            int s=q.size();            long long m=-1e14;   //int maxValue = INT_MIN; // 取每一层的最大值            for(int i=0;i&lt;s;i++)            &#123;            TreeNode* node=q.front();            q.pop();            if(node-&gt;val&gt;m) m=node-&gt;val;            if(node-&gt;left) q.push(node-&gt;left);            if(node-&gt;right) q.push(node-&gt;right);            &#125;            res.push_back(m);        &#125;        return res;    &#125;&#125;;
填充每个节点的下一个右侧节点指针
题目链接：116. 填充每个节点的下一个右侧节点指针
这题没想明白怎么处理，我是应该新建一个什么类型的vector，用int,char,Node类型都不行，然后就直接看题解了。
class Solution &#123;public:    Node* connect(Node* root) &#123;        if (root == NULL) return NULL;        queue&lt;Node*&gt; q;        q.push(root);        while (!q.empty()) &#123;            int size = q.size();            Node* prev = NULL;  // 用来保存当前层级的前一个节点            for (int i = 0; i &lt; size; ++i) &#123;                Node* current = q.front();                q.pop();                // 连接前一个节点的next指针指向当前节点                if (prev != NULL) prev-&gt;next = current;                // 更新prev为当前节点                prev = current;                // 将左子树和右子树加入队列                if (current-&gt;left) q.push(current-&gt;left);                if (current-&gt;right) q.push(current-&gt;right);            &#125;            // 将当前层级最后一个节点的next指针设置为NULL            prev-&gt;next = NULL;        &#125;        return root;    &#125;&#125;;
利用next指针逐层处理（优化）
class Solution &#123;public:    Node* connect(Node* root) &#123;        if (!root) return nullptr;        Node* leftmost = root; // 当前层的最左节点        while (leftmost-&gt;left) &#123; // 直到叶子层            Node* curr = leftmost;            while (curr) &#123;                // 连接左子节点和右子节点                curr-&gt;left-&gt;next = curr-&gt;right;                // 连接右子节点和相邻节点的左子节点                if (curr-&gt;next) &#123;                    curr-&gt;right-&gt;next = curr-&gt;next-&gt;left;                &#125;                curr = curr-&gt;next; // 移动到同层下一节点            &#125;            leftmost = leftmost-&gt;left; // 移到下一层最左        &#125;        return root;    &#125;&#125;;
填充每个节点的下一个右侧节点指针 II
题目链接：117. 填充每个节点的下一个右侧节点指针 II
class Solution &#123;public:    Node* connect(Node* root) &#123;        if (root == NULL) return NULL;        queue&lt;Node*&gt; q;        q.push(root);        while (!q.empty()) &#123;            int size = q.size();            Node* prev = NULL;  // 用来保存当前层级的前一个节点            for (int i = 0; i &lt; size; ++i) &#123;                Node* current = q.front();                q.pop();                // 连接前一个节点的next指针指向当前节点                if (prev != NULL) prev-&gt;next = current;                // 更新prev为当前节点                prev = current;                // 将左子树和右子树加入队列                if (current-&gt;left) q.push(current-&gt;left);                if (current-&gt;right) q.push(current-&gt;right);            &#125;            // 将当前层级最后一个节点的next指针设置为NULL            prev-&gt;next = NULL;        &#125;        return root;    &#125;&#125;;
二叉树的最大深度
题目链接：104. 二叉树的最大深度
虽然简单，但是用这个方法有种高射炮打蚊子的感觉，感觉应该有更简单的方法。
class Solution &#123;public:    int maxDepth(TreeNode* root) &#123;        queue&lt;TreeNode*&gt; q;        if(root!=NULL) q.push(root);        int sum=0;        while(!q.empty())&#123;            int s=q.size();            sum=sum+1;            for(int i=0;i&lt;s;i++)&#123;                TreeNode* node=q.front();                q.pop();                if(node-&gt;right) q.push(node-&gt;right);                if(node-&gt;left) q.push(node-&gt;left);            &#125;                &#125;        return sum;    &#125;&#125;;
递归方法：后序遍历（DFS）
class Solution &#123;public:    int maxDepth(TreeNode* root) &#123;        if (root == nullptr) return 0;        return max(maxDepth(root-&gt;left), maxDepth(root-&gt;right)) + 1;    &#125;&#125;;
二叉树的最小深度
题目链接：111. 二叉树的最小深度
找第一个没有左右子树的节点的深度。
class Solution &#123;public:    int minDepth(TreeNode* root) &#123;        if (root == NULL) return 0;        int depth = 0;        queue&lt;TreeNode*&gt; que;        que.push(root);        while(!que.empty()) &#123;            int size = que.size();            depth++; // 记录最小深度            for (int i = 0; i &lt; size; i++) &#123;                TreeNode* node = que.front();                que.pop();                if (node-&gt;left) que.push(node-&gt;left);                if (node-&gt;right) que.push(node-&gt;right);                if (!node-&gt;left &amp;&amp; !node-&gt;right) &#123; // 当左右孩子都为空的时候，说明是最低点的一层了，退出                    return depth;                &#125;            &#125;        &#125;        return depth;    &#125;&#125;;
递归
如果 node 是空节点，由于没有节点，返回 0。
如果 node 没有右儿子，那么深度就是左子树的深度加一，即 dfs(node)=dfs(node.left)+1。
如果 node 没有左儿子，那么深度就是右子树的深度加一，即 dfs(node)=dfs(node.right)+1。
如果 node 左右儿子都有，那么分别递归计算左子树的深度，以及右子树的深度，二者取最小值再加一，即 dfs(node)=min(dfs(node.left),dfs(node.right))+1

class Solution &#123;public:    int minDepth(TreeNode *root) &#123;        if (root == nullptr) return 0;        if (root-&gt;right == nullptr) return minDepth(root-&gt;left) + 1;        if (root-&gt;left == nullptr) return minDepth(root-&gt;right) + 1;        return min(minDepth(root-&gt;left), minDepth(root-&gt;right)) + 1;    &#125;&#125;;
翻转二叉树
题目链接：226. 翻转二叉树
迭代法：深度优先遍历
class Solution &#123;public:    TreeNode* invertTree(TreeNode* root) &#123;        if (root == nullptr) return nullptr;        queue&lt;TreeNode*&gt; q;        q.push(root);        while (!q.empty()) &#123;            TreeNode* node = q.front();            q.pop();            // 使用临时变量交换左右子节点            TreeNode* temp = node-&gt;left;            node-&gt;left = node-&gt;right;            node-&gt;right = temp;            // 如果左右子节点不为空，则加入队列            if (node-&gt;left) q.push(node-&gt;left);            if (node-&gt;right) q.push(node-&gt;right);        &#125;        return root;    &#125;&#125;;
递归法：
class Solution &#123;public:    TreeNode* invertTree(TreeNode* root) &#123;        if (root == NULL) return root;        swap(root-&gt;left, root-&gt;right);  // 中        invertTree(root-&gt;left);         // 左        invertTree(root-&gt;right);        // 右        return root;    &#125;&#125;;
对称二叉树
题目链接：101. 对称二叉树

迭代队列法：
class Solution &#123;public:    bool isSymmetric(TreeNode* root) &#123;        if (root == NULL) return true;        queue&lt;TreeNode*&gt; que;        que.push(root-&gt;left);   // 将左子树头结点加入队列        que.push(root-&gt;right);  // 将右子树头结点加入队列                while (!que.empty()) &#123;  // 接下来就要判断这两个树是否相互翻转            TreeNode* leftNode = que.front(); que.pop();            TreeNode* rightNode = que.front(); que.pop();            if (!leftNode &amp;&amp; !rightNode) &#123;  // 左节点为空、右节点为空，此时说明是对称的                continue;            &#125;            // 左右一个节点不为空，或者都不为空但数值不相同，返回false            if ((!leftNode || !rightNode || (leftNode-&gt;val != rightNode-&gt;val))) &#123;                return false;            &#125;            que.push(leftNode-&gt;left);   // 加入左节点左孩子            que.push(rightNode-&gt;right); // 加入右节点右孩子            que.push(leftNode-&gt;right);  // 加入左节点右孩子            que.push(rightNode-&gt;left);  // 加入右节点左孩子        &#125;        return true;    &#125;&#125;;
迭代栈法：
class Solution &#123;public:    bool isSymmetric(TreeNode* root) &#123;        if (root == NULL) return true;        stack&lt;TreeNode*&gt; st; // 这里改成了栈        st.push(root-&gt;left);        st.push(root-&gt;right);        while (!st.empty()) &#123;            TreeNode* rightNode = st.top(); st.pop();            TreeNode* leftNode = st.top(); st.pop();            if (!leftNode &amp;&amp; !rightNode) &#123;                continue;            &#125;            if ((!leftNode || !rightNode || (leftNode-&gt;val != rightNode-&gt;val))) &#123;                return false;            &#125;            st.push(leftNode-&gt;left);            st.push(rightNode-&gt;right);            st.push(leftNode-&gt;right);            st.push(rightNode-&gt;left);        &#125;        return true;    &#125;&#125;;
递归法：
class Solution &#123;public:    bool compare(TreeNode* left, TreeNode* right) &#123;        // 首先排除空节点的情况        if (left == NULL &amp;&amp; right != NULL) return false;        else if (left != NULL &amp;&amp; right == NULL) return false;        else if (left == NULL &amp;&amp; right == NULL) return true;        // 排除了空节点，再排除数值不相同的情况        else if (left-&gt;val != right-&gt;val) return false;        // 此时就是：左右节点都不为空，且数值相同的情况        // 此时才做递归，做下一层的判断        bool outside = compare(left-&gt;left, right-&gt;right);   // 左子树：左、 右子树：右        bool inside = compare(left-&gt;right, right-&gt;left);    // 左子树：右、 右子树：左        bool isSame = outside &amp;&amp; inside;                    // 左子树：中、 右子树：中 （逻辑处理）        return isSame;    &#125;    bool isSymmetric(TreeNode* root) &#123;        if (root == NULL) return true;        return compare(root-&gt;left, root-&gt;right);    &#125;&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>二叉树</tag>
        <tag>二叉树遍历</tag>
        <tag>递归</tag>
        <tag>迭代</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--二叉树</title>
    <url>/2025/02/11day/</url>
    <content><![CDATA[二叉树
完全二叉树的节点个数
题目链接：222. 完全二叉树的节点个数
迭代法：
class Solution &#123;public:    int countNodes(TreeNode* root) &#123;        queue&lt;TreeNode*&gt; q;        if(root!=NULL) q.push(root);        int sum=0;        while(!q.empty())&#123;            int s=q.size();            for(int i=0;i&lt;s;i++)&#123;                TreeNode* node=q.front();                q.pop();                sum+=1;                if(node-&gt;right) q.push(node-&gt;right);                if(node-&gt;left) q.push(node-&gt;left);            &#125;        &#125;        return sum;    &#125;&#125;;
平衡二叉树
题目链接：110. 平衡二叉树
class Solution &#123;    int get_height(TreeNode* node)&#123;        if(node==NULL) return 0;        int left=get_height(node-&gt;left);        if(left==-1) return -1;        int right=get_height(node-&gt;right);        if(right==-1 || abs(left-right)&gt;1) return -1;        return max(left,right)+1;    &#125;public:     bool isBalanced(TreeNode* root) &#123;        return get_height(root) != -1;    &#125;&#125;;
二叉树的所有路径
题目链接：257. 二叉树的所有路径
回溯和递归是一一对应的，有一个递归，就要有一个回溯
class Solution &#123;private:    void traversal(TreeNode* cur, string path, vector&lt;string&gt;&amp; result) &#123;        path += to_string(cur-&gt;val); // 中        if (cur-&gt;left == NULL &amp;&amp; cur-&gt;right == NULL) &#123;            result.push_back(path);            return;        &#125;        if (cur-&gt;left) traversal(cur-&gt;left, path + &quot;-&gt;&quot;, result); // 左        if (cur-&gt;right) traversal(cur-&gt;right, path + &quot;-&gt;&quot;, result); // 右    &#125;public:    vector&lt;string&gt; binaryTreePaths(TreeNode* root) &#123;        vector&lt;string&gt; result;        string path;        if (root == NULL) return result;        traversal(root, path, result);        return result;    &#125;&#125;;
class Solution &#123;public:    vector&lt;string&gt; binaryTreePaths(TreeNode* root) &#123;        stack&lt;TreeNode*&gt; treeSt;         stack&lt;string&gt; path;        vector&lt;string&gt; ans;        if(root!=NULL) treeSt.push(root);        path.push(to_string(root-&gt;val));        while(!treeSt.empty())&#123;            TreeNode* node=treeSt.top();            treeSt.pop();            string p=path.top();            path.pop();            if(node-&gt;right==NULL &amp;&amp; node-&gt;left==NULL) ans.push_back(p);            if(node-&gt;left)&#123;                treeSt.push(node-&gt;left);                path.push(p+&quot;-&gt;&quot;+to_string(node-&gt;left-&gt;val));            &#125;            if(node-&gt;right)&#123;                treeSt.push(node-&gt;right);                path.push(p+&quot;-&gt;&quot;+to_string(node-&gt;right-&gt;val));            &#125;        &#125;        return ans;    &#125;&#125;;
左叶子之和
题目链接：404. 左叶子之和
感觉还是迭代法简单好想
class Solution &#123;public:    int sumOfLeftLeaves(TreeNode* root) &#123;        stack&lt;TreeNode*&gt; s;        if(root!=NULL) s.push(root);        int sum=0;        while(!s.empty())&#123;            TreeNode* node=s.top();            s.pop();            if(node-&gt;left &amp;&amp; node-&gt;left-&gt;left==NULL &amp;&amp; node-&gt;left-&gt;right==NULL) sum+=node-&gt;left-&gt;val;            if(node-&gt;left) s.push(node-&gt;left);            if(node-&gt;right) s.push(node-&gt;right);        &#125;        return sum;    &#125;&#125;;
递归法：
class Solution &#123;public:    int sumOfLeftLeaves(TreeNode* root) &#123;        if (root == NULL) return 0;        if (root-&gt;left == NULL &amp;&amp; root-&gt;right== NULL) return 0;        int leftValue = sumOfLeftLeaves(root-&gt;left);    // 左        if (root-&gt;left &amp;&amp; !root-&gt;left-&gt;left &amp;&amp; !root-&gt;left-&gt;right) &#123; // 左子树就是一个左叶子的情况            leftValue = root-&gt;left-&gt;val;        &#125;        int rightValue = sumOfLeftLeaves(root-&gt;right);  // 右        int sum = leftValue + rightValue;               // 中        return sum;    &#125;&#125;;
找树左下角的值
题目链接：513. 找树左下角的值
迭代法
class Solution &#123;public:    int findBottomLeftValue(TreeNode* root) &#123;        queue&lt;TreeNode*&gt; q;        int ans=0;        if(root!=NULL) q.push(root);        while(!q.empty())&#123;            int s=q.size();            for(int i=0;i&lt;s;i++)            &#123;                TreeNode* node = q.front();                q.pop();                if(i==0) ans=node-&gt;val;                if(node-&gt;left) q.push(node-&gt;left);                if(node-&gt;right) q.push(node-&gt;right);            &#125;        &#125;        return ans;    &#125;&#125;;
路径总和
题目链接：112. 路径总和
迭代法
这题和二叉树的所有路径很像，就是把存储路径改成存储路径和。
版本一
class Solution &#123;public:    bool hasPathSum(TreeNode* root, int targetSum) &#123;        stack&lt;TreeNode*&gt; s;        stack&lt;int&gt; sums;  // 用来存储每个节点的路径和        if (root != NULL) &#123;            s.push(root);  // 将根节点压入栈            sums.push(root-&gt;val);  // 将根节点的值作为初始路径和压入路径和栈        &#125;          while (!s.empty()) &#123;            TreeNode* node = s.top();            int sum = sums.top();  // 获取当前节点的路径和            s.pop();            sums.pop();                        // 判断是否是叶子节点并且路径和等于目标值            if (node-&gt;left == NULL &amp;&amp; node-&gt;right == NULL &amp;&amp; sum == targetSum) &#123;                return true;            &#125;                        // 继续将左右子节点和更新后的路径和压入栈中            if (node-&gt;right) &#123;                s.push(node-&gt;right);                sums.push(sum + node-&gt;right-&gt;val);            &#125;            if (node-&gt;left) &#123;                s.push(node-&gt;left);                sums.push(sum + node-&gt;left-&gt;val);            &#125;        &#125;                return false;    &#125;&#125;;
版本二
class Solution &#123;public:    bool hasPathSum(TreeNode* root, int targetSum) &#123;        if (root == NULL) return false;               stack&lt;pair&lt;TreeNode*, int&gt;&gt; s; // 使用栈存储节点和当前的路径和        s.push(&#123;root, root-&gt;val&#125;); // 初始化，根节点和它的值              while (!s.empty()) &#123;            TreeNode* node = s.top().first;            int currentSum = s.top().second;            s.pop();               // 判断是否是叶子节点，并且路径和是否等于目标值            if (node-&gt;left == NULL &amp;&amp; node-&gt;right == NULL &amp;&amp; currentSum == targetSum) &#123;                return true;            &#125;                   // 将子节点和更新后的路径和压入栈中            if (node-&gt;right) s.push(&#123;node-&gt;right, currentSum + node-&gt;right-&gt;val&#125;);            if (node-&gt;left) s.push(&#123;node-&gt;left, currentSum + node-&gt;left-&gt;val&#125;);        &#125;             return false;    &#125;&#125;;
递归法
路径总和 II
题目链接：113. 路径总和 II
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>二叉树</tag>
        <tag>二叉树遍历</tag>
        <tag>递归</tag>
        <tag>迭代</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--回溯算法</title>
    <url>/2025/03/12day/</url>
    <content><![CDATA[回溯
组合
题目链接：77. 组合

class Solution &#123;private:    vector&lt;vector&lt;int&gt;&gt; result; // 存放符合条件结果的集合    vector&lt;int&gt; path; // 用来存放符合条件结果    void backtracking(int n, int k, int startIndex) &#123;        if (path.size() == k) &#123;            result.push_back(path);            return;        &#125;        for (int i = startIndex; i &lt;= n; i++) &#123;            path.push_back(i); // 处理节点            backtracking(n, k, i + 1); // 递归            path.pop_back(); // 回溯，撤销处理的节点        &#125;    &#125;public:    vector&lt;vector&lt;int&gt;&gt; combine(int n, int k) &#123;        result.clear(); // 可以不写        path.clear();   // 可以不写        backtracking(n, k, 1);        return result;    &#125;&#125;;
回溯剪枝
剪枝的地方就在递归中每一层的for循环所选择的起始位置。
如果for循环选择的起始位置之后的元素个数 已经不足 我们需要的元素个数了，那么就没有必要搜索了。

class Solution &#123;private:    vector&lt;vector&lt;int&gt;&gt; result;    vector&lt;int&gt; path;    void backtracking(int n, int k, int startIndex) &#123;        if (path.size() == k) &#123;            result.push_back(path);            return;        &#125;        for (int i = startIndex; i &lt;= n - (k - path.size()) + 1; i++) &#123; // 优化的地方            path.push_back(i); // 处理节点            backtracking(n, k, i + 1);            path.pop_back(); // 回溯，撤销处理的节点        &#125;    &#125;public:    vector&lt;vector&lt;int&gt;&gt; combine(int n, int k) &#123;        backtracking(n, k, 1);        return result;    &#125;&#125;;
组合总和 III
题目链接：216. 组合总和 III
class Solution &#123;private:    vector&lt;vector&lt;int&gt;&gt; ans;    vector&lt;int&gt; an;    int sum=0;    void track(int n,int k,int s)&#123;        if(an.size()==k &amp;&amp; sum==n)&#123;            ans.push_back(an);            return;        &#125;        if(sum&gt;n) return;        for(int i=s;i&lt;=9;i++)&#123;            an.push_back(i);            sum+=i;            track(n,k,i+1);            sum-=i;            an.pop_back();        &#125;    &#125;public:    vector&lt;vector&lt;int&gt;&gt; combinationSum3(int k, int n) &#123;        track(n,k,1);        return ans;    &#125;&#125;;
电话号码的字母组合
题目链接：17. 电话号码的字母组合
class Solution &#123;private:    vector&lt;string&gt; ans; // 存储最终结果，字符串组合    string combination;   // 当前正在构建的字符串组合    string phoneMap[10] = &#123;&quot;&quot;, &quot;&quot;, &quot;abc&quot;, &quot;def&quot;, &quot;ghi&quot;, &quot;jkl&quot;, &quot;mno&quot;, &quot;pqrs&quot;, &quot;tuv&quot;, &quot;wxyz&quot;&#125;; // 电话号码数字到字母的映射    void backtracking(string digits, int index) &#123;        if (index == digits.size()) &#123; // 递归终止条件：当处理完所有数字时            ans.push_back(combination); // 将当前组合添加到结果集            return;        &#125;        char digitChar = digits[index]; // 获取当前处理的数字字符        int digitIndex = digitChar - &#x27;0&#x27;; // 将数字字符转换为整数索引 (0-9)        string letters = phoneMap[digitIndex]; // 获取数字对应的字母字符串        for (char letter : letters) &#123; // 遍历当前数字对应的每个字母            combination.push_back(letter); // 将当前字母添加到组合中            backtracking(digits, index + 1); // 递归处理下一个数字，索引 + 1            combination.pop_back(); // 回溯：移除最后一个添加的字母，尝试下一个字母        &#125;    &#125;public:    vector&lt;string&gt; letterCombinations(string digits) &#123;        ans.clear(); // 清空结果集        combination.clear(); // 清空当前组合        if (digits.empty()) &#123; // 如果输入 digits 为空，直接返回空结果集            return ans;        &#125;        backtracking(digits, 0); // 从 digits 的第一个数字开始回溯，索引从 0 开始        return ans;    &#125;&#125;;
组合总和
题目链接：39. 组合总和
class Solution &#123;private:    vector&lt;vector&lt;int&gt;&gt; ans;    vector&lt;int&gt; an;    void track(vector&lt;int&gt;&amp; candidates, int target, int startIndex)&#123;        if(target == 0)&#123;            ans.push_back(an);            return;        &#125;        if(target &lt; 0) return;        for(int i = startIndex; i &lt; candidates.size(); i++)&#123;            an.push_back(candidates[i]);            track(candidates, target - candidates[i], i); // 注意这里是 i，允许重复使用同一元素            an.pop_back();        &#125;    &#125;public:    vector&lt;vector&lt;int&gt;&gt; combinationSum(vector&lt;int&gt;&amp; candidates, int target) &#123;        ans.clear();        an.clear();        track(candidates, target, 0);        return ans;    &#125;&#125;;
组合总和 II
题目链接：40. 组合总和 II
class Solution &#123;private:    vector&lt;vector&lt;int&gt;&gt; ans;    vector&lt;int&gt; an;    void track(vector&lt;int&gt;&amp; candidates, int target, int inx) &#123;        if (target == 0) &#123;            ans.push_back(an);            return;        &#125;        if (target &lt; 0) return;        for (int i = inx; i &lt; candidates.size(); i++) &#123;            if (i &gt; inx &amp;&amp; candidates[i] == candidates[i - 1]) continue; // 如果该元素与左边元素相等，说明该搜索分支重复，直接跳过            an.push_back(candidates[i]);            track(candidates, target - candidates[i], i + 1);             an.pop_back();        &#125;    &#125;public:    vector&lt;vector&lt;int&gt;&gt; combinationSum2(vector&lt;int&gt;&amp; candidates, int target) &#123;        sort(candidates.begin(), candidates.end());        track(candidates, target, 0);        return ans;    &#125;&#125;;
子集
题目链接：78. 子集
class Solution &#123;private:    vector&lt;vector&lt;int&gt;&gt; ans;    vector&lt;int&gt; an;    void track(vector&lt;int&gt;&amp; nums,int idx)&#123;        int n=nums.size();        ans.push_back(an);        for(int i=idx;i&lt;n;i++)&#123;            an.push_back(nums[i]);            track(nums,i+1);            an.pop_back();        &#125;    &#125;public:    vector&lt;vector&lt;int&gt;&gt; subsets(vector&lt;int&gt;&amp; nums) &#123;        track(nums,0);        return ans;    &#125;&#125;;
子集 II
题目链接：90. 子集 II
class Solution &#123;private:    vector&lt;vector&lt;int&gt;&gt; ans;    vector&lt;int&gt; an;    void track(vector&lt;int&gt;&amp; nums,int idx)&#123;        int n=nums.size();        ans.push_back(an);        for(int i=idx;i&lt;n;i++)&#123;            if(i&gt;idx &amp;&amp; nums[i]==nums[i-1]) continue;            an.push_back(nums[i]);            track(nums,i+1);            an.pop_back();        &#125;    &#125;public:    vector&lt;vector&lt;int&gt;&gt; subsetsWithDup(vector&lt;int&gt;&amp; nums) &#123;        sort(nums.begin(),nums.end());        track(nums,0);        return ans;    &#125;&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>递归</tag>
        <tag>回溯</tag>
        <tag>剪枝</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--图论</title>
    <url>/2025/03/13day/</url>
    <content><![CDATA[图论
图的存储方式
邻接矩阵
邻接矩阵 使用 二维数组来表示图结构。 邻接矩阵是从节点的角度来表示图，有多少节点就申请多大的二维数组。
有n 个节点，因为节点标号是从1开始的，为了节点标号和下标对齐，申请 n + 1 * n + 1  这么大的二维数组。
vector&lt;vector&lt;int&gt;&gt; graph(n + 1, vector&lt;int&gt;(n + 1, 0));while (m--) &#123;    cin &gt;&gt; s &gt;&gt; t    // 使用邻接矩阵 ，1 表示 节点s 指向 节点t    graph[s][t] = 1;&#125;
邻接表
邻接表 使用 数组 + 链表的方式来表示。 邻接表是从边的数量来表示图，有多少边 才会申请对应大小的链表。
邻接表的构造相对邻接矩阵难理解一些。

// 节点编号从1到n，所以申请 n+1 这么大的数组vector&lt;list&lt;int&gt;&gt; graph(n + 1); // 邻接表，list为C++里的链表while (m--) &#123;    cin &gt;&gt; s &gt;&gt; t;    // 使用邻接表 ，表示 s -&gt; t 是相连的    graph[s].push_back(t);&#125;
深度优先搜索三部曲

确认递归函数，参数

vector&lt;vector&lt;int&gt;&gt; result; // 收集符合条件的路径vector&lt;int&gt; path; // 0节点到终点的路径// x：目前遍历的节点// graph：存当前的图// n：终点void dfs (const vector&lt;vector&lt;int&gt;&gt;&amp; graph, int x, int n) &#123;

确认终止条件

// 当前遍历的节点x 到达节点n if (x == n) &#123; // 找到符合条件的一条路径    result.push_back(path);    return;&#125;

处理目前搜索节点出发的路径

for (int i = 1; i &lt;= n; i++) &#123; // 遍历节点x链接的所有节点    if (graph[x][i] == 1) &#123; // 找到 x链接的节点        path.push_back(i); // 遍历到的节点加入到路径中来        dfs(graph, i, n); // 进入下一层递归        path.pop_back(); // 回溯，撤销本节点    &#125;&#125;

打印结果

// 输出结果if (result.size() == 0) cout &lt;&lt; -1 &lt;&lt; endl;for (const vector&lt;int&gt; &amp;pa : result) &#123;    for (int i = 0; i &lt; pa.size() - 1; i++) &#123; // 这里指打印到倒数第二个        cout &lt;&lt; pa[i] &lt;&lt; &quot; &quot;;    &#125;    cout &lt;&lt; pa[pa.size() - 1]  &lt;&lt; endl; // 这里再打印倒数第一个，控制最后一个元素后面没有空格&#125;
例题：所有可能的路径
题目链接：797. 所有可能的路径
邻接矩阵写法
#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;vector&lt;vector&lt;int&gt;&gt; result; // 收集符合条件的路径vector&lt;int&gt; path; // 1节点到终点的路径void dfs (const vector&lt;vector&lt;int&gt;&gt;&amp; graph, int x, int n) &#123;    // 当前遍历的节点x 到达节点n     if (x == n) &#123; // 找到符合条件的一条路径        result.push_back(path);        return;    &#125;    for (int i = 1; i &lt;= n; i++) &#123; // 遍历节点x链接的所有节点        if (graph[x][i] == 1) &#123; // 找到 x链接的节点            path.push_back(i); // 遍历到的节点加入到路径中来            dfs(graph, i, n); // 进入下一层递归            path.pop_back(); // 回溯，撤销本节点        &#125;    &#125;&#125;int main() &#123;    int n, m, s, t;    cin &gt;&gt; n &gt;&gt; m;    // 节点编号从1到n，所以申请 n+1 这么大的数组    vector&lt;vector&lt;int&gt;&gt; graph(n + 1, vector&lt;int&gt;(n + 1, 0));    while (m--) &#123;        cin &gt;&gt; s &gt;&gt; t;        // 使用邻接矩阵 表示无线图，1 表示 s 与 t 是相连的        graph[s][t] = 1;    &#125;    path.push_back(1); // 无论什么路径已经是从0节点出发    dfs(graph, 1, n); // 开始遍历    // 输出结果    if (result.size() == 0) cout &lt;&lt; -1 &lt;&lt; endl;    for (const vector&lt;int&gt; &amp;pa : result) &#123;        for (int i = 0; i &lt; pa.size() - 1; i++) &#123;            cout &lt;&lt; pa[i] &lt;&lt; &quot; &quot;;        &#125;        cout &lt;&lt; pa[pa.size() - 1]  &lt;&lt; endl;    &#125;&#125;
邻接表写法
#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;list&gt;using namespace std;vector&lt;vector&lt;int&gt;&gt; result; // 收集符合条件的路径vector&lt;int&gt; path; // 1节点到终点的路径void dfs (const vector&lt;list&lt;int&gt;&gt;&amp; graph, int x, int n) &#123;    if (x == n) &#123; // 找到符合条件的一条路径        result.push_back(path);        return;    &#125;    for (int i : graph[x]) &#123; // 找到 x指向的节点        path.push_back(i); // 遍历到的节点加入到路径中来        dfs(graph, i, n); // 进入下一层递归        path.pop_back(); // 回溯，撤销本节点    &#125;&#125;int main() &#123;    int n, m, s, t;    cin &gt;&gt; n &gt;&gt; m;    // 节点编号从1到n，所以申请 n+1 这么大的数组    vector&lt;list&lt;int&gt;&gt; graph(n + 1); // 邻接表    while (m--) &#123;        cin &gt;&gt; s &gt;&gt; t;        // 使用邻接表 ，表示 s -&gt; t 是相连的        graph[s].push_back(t);    &#125;    path.push_back(1); // 无论什么路径已经是从0节点出发    dfs(graph, 1, n); // 开始遍历    // 输出结果    if (result.size() == 0) cout &lt;&lt; -1 &lt;&lt; endl;    for (const vector&lt;int&gt; &amp;pa : result) &#123;        for (int i = 0; i &lt; pa.size() - 1; i++) &#123;            cout &lt;&lt; pa[i] &lt;&lt; &quot; &quot;;        &#125;        cout &lt;&lt; pa[pa.size() - 1]  &lt;&lt; endl;    &#125;&#125;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--动态规划</title>
    <url>/2025/03/14day/</url>
    <content><![CDATA[动态规划
动态规划，英文：Dynamic Programming，简称DP，如果某一问题有很多重叠子问题，使用动态规划是最有效的。所以动态规划中每一个状态一定是由上一个状态推导出来的，这一点就区分于贪心，贪心没有状态推导，而是从局部直接选最优的。
斐波那契数
题目链接：509. 斐波那契数
前几天做过一个斐波那契用递归超时，动态规划感觉就是递归加剪枝。
class Solution &#123;public:    int fib(int N) &#123;        if (N &lt;= 1) return N;        int dp[2];        dp[0] = 0;        dp[1] = 1;        for (int i = 2; i &lt;= N; i++) &#123;            int sum = dp[0] + dp[1];            dp[0] = dp[1];            dp[1] = sum;        &#125;        return dp[1];    &#125;&#125;;
爬楼梯
题目链接：70. 爬楼梯
按照题意，要上楼梯的话，第一步只有两种上法，要么走一级台阶要么走两级台阶，走了一级台阶之后，等于是还要上一个n-1级台阶的楼梯，同理，走了两级台阶的话就等于是还要上一个n-2级台阶的楼梯，以此类推这样动态规划的思想就体现出来了。
class Solution &#123;public:    int climbStairs(int n) &#123;        if (n &lt;= 1) return n;        int dp[3];        dp[1] = 1;        dp[2] = 2;        for (int i = 3; i &lt;= n; i++) &#123;            int sum = dp[1] + dp[2];            dp[1] = dp[2];            dp[2] = sum;        &#125;        return dp[2];    &#125;&#125;;
使用最小花费爬楼梯
题目链接：746. 使用最小花费爬楼梯
class Solution &#123;public:    int minCostClimbingStairs(vector&lt;int&gt;&amp; cost) &#123;        vector&lt;int&gt; dp(cost.size()+1);        for(int i=2;i&lt;=cost.size();i++)        &#123;            dp[i]=min(dp[i-1]+cost[i-1],dp[i-2]+cost[i-2]);        &#125;        return dp[cost.size()];    &#125;&#125;;
不同路径
题目链接：62. 不同路径
class Solution &#123;public:    int uniquePaths(int m, int n) &#123;        vector f(m + 1, vector&lt;int&gt;(n + 1));        f[0][1] = 1;        for (int i = 0; i &lt; m; i++) &#123;            for (int j = 0; j &lt; n; j++) &#123;                f[i + 1][j + 1] = f[i][j + 1] + f[i + 1][j];            &#125;        &#125;        return f[m][n];    &#125;&#125;;
比特位计数
题目链接：LCR 003. 比特位计数
除以2
如果 i 是偶数，那么 i 的二进制表示中 1 的个数与 i / 2 的二进制表示中 1 的个数相同。
如果 i 是奇数，那么 i 的二进制表示中 1 的个数比 i / 2 的二进制表示中 1 的个数多 1。
class Solution &#123;public:    vector&lt;int&gt; countBits(int n) &#123;        vector&lt;int&gt; ans(n + 1);        ans[0] = 0;        for (int i = 1; i &lt;= n; ++i) &#123;            if (i % 2 == 0) &#123;                ans[i] = ans[i / 2];            &#125; else &#123;                ans[i] = ans[i / 2] + 1;            &#125;        &#125;        return ans;    &#125;&#125;;
位运算
进行按位与运算 i &amp; (i - 1) 后，从最右边的 1 开始的所有位都会变成 0，而其左边的位保持不变。因此，i &amp; (i - 1) 的结果就是将 i 最右边的 1 去掉后得到的数字。
class Solution &#123;public:    vector&lt;int&gt; countBits(int n) &#123;        vector&lt;int&gt; ans(n + 1);        ans[0] = 0;        for (int i = 1; i &lt;= n; ++i) &#123;            ans[i] = ans[i &amp; (i - 1)] + 1;        &#125;        return ans;    &#125;&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>动态规划</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--数组</title>
    <url>/2025/01/1day/</url>
    <content><![CDATA[二分查找
每次去除当前区间一半的元素，时间复杂度O(logn)，注意处理好区间。
例题
题目链接：704. 二分查找
题目描述：在严格递增的序列中找到给定的数，并返回其下标。
左闭右闭 [left,right]
class Solution &#123;public:    int search(vector&lt;int&gt;&amp; nums, int target) &#123;        int l=0,r=nums.size()-1;        while(l&lt;=r)        &#123;            int mid=(l+r)/2;            if(nums[mid]&gt;target) r=mid-1;            else if(nums[mid]&lt;target) l=mid+1;            else return mid;        &#125;        return -1;    &#125;&#125;;
左闭右开 [left,right)
class Solution &#123;public:    int search(vector&lt;int&gt;&amp; nums, int target) &#123;        int l=0,r=nums.size()-1;        while(l&lt;r) //当l=r时没有意义，所以改为l&lt;r.        &#123;            int mid=(l+r)/2;            if(nums[mid]&gt;target) r=mid;            else if(nums[mid]&lt;target) l=mid+1;            else return mid;        &#125;        return -1;    &#125;&#125;;
相关题目
35. 搜索插入位置
比较简单，处理一下返回值就可以。
34. 在排序数组中查找元素的第一个和最后一个位置
需要进行两次操作，找到左右边界，较复杂，还需要多做做。
69. x 的平方根 
我的思路是当(l-r)&lt;=1,找到的l便是整数部分。
367. 有效的完全平方数
题目还未做
双指针
一种重要的编程思想，非常高效。
例题
题目链接：https://leetcode.cn/problems/remove-element/
题目描述：给定一个数组 nums 和一个值 val，原地移除所有数值等于 val 的元素，并返回移除后数组的新长度。
左右指针法
思路：从两头向中间移动指针，当左边==val，右边！=val时，交换两个元素，边界问题不太好处理，较麻烦。
class Solution &#123;public:    int removeElement(vector&lt;int&gt;&amp; nums, int val) &#123;        int l=0,r=nums.size()-1;        while(l&lt;=r)        &#123;            while(l&lt;=r &amp;&amp; nums[l]!=val) l++;            while(l&lt;=r &amp;&amp; nums[r]==val) r--;            if(l&lt;r)&#123; swap(nums[l],nums[r]);            l++;            r--;&#125;        &#125;        return r+1;    &#125;&#125;;
快慢指针法
思路：定义一个快指针，用于一直向前循环，定义一个慢指针，当快指针指到的元素！=val时，将这个元素加入到慢指针指向的位置。快指针不会慢于慢指针，所以慢指针元素的更改就是它最后输出的数组。
class Solution &#123;public:    int removeElement(vector&lt;int&gt;&amp; nums, int val) &#123;        int fast=0,slow=0,n=nums.size();        while(fast&lt;n)        &#123;            if(nums[fast]==val) fast++;            else nums[slow++]=nums[fast++];        &#125;        return slow;    &#125;&#125;;
相关题目
26.删除有序数组中的重复项：https://leetcode.cn/problems/remove-duplicates-from-sorted-array/description/
思路：快慢指针，题解中i为快指针，n为慢指针，当快慢指针指向的元素不相等时，更新慢指针，思路和例题中的差不多。
class Solution &#123;public:    int removeDuplicates(vector&lt;int&gt;&amp; nums) &#123;        int n=0;        for(int i=0;i&lt;nums.size();i++) if(nums[i]!=nums[n]) nums[++n]=nums[i];        return n+1;    &#125;&#125;;
283.移动零：https://leetcode.cn/problems/move-zeroes/solutions/2821184/san-chong-jie-fa-duo-yu-yan-you-pei-tu-b-1d3s/
思路：这题不太好想，前几天做过，这次看还是没思路。
class Solution &#123;public:    void moveZeroes(vector&lt;int&gt;&amp; nums) &#123;        int n=0,tem;        for(int i=0;i&lt;nums.size();i++)        &#123;            if(nums[i]!=0)            &#123;                tem=nums[i];                nums[i]=0;                nums[n++]=tem;                 &#125;        &#125;    &#125;&#125;;
977.有序数组的平方：https://leetcode.cn/problems/squares-of-a-sorted-array/
这题印象比较深刻，前几天做的时候一直想不明白我的做法的问题，后来问了学长，才知道，我因为没有定义一个新数组，导致在原数组上操作导致的问题。直接定义int数组也不行，得用vector定义一个动态数组，没接触过vector也是不太会用，一直想着看看呢，也总是不想看。当时一直以为是超出int范围了。
思路：左右指针法，两边的数的平方向中间是递减的，所以比较两端，大的那一个就是剩下元素中最大的那个。
class Solution &#123;public:    vector&lt;int&gt; sortedSquares(vector&lt;int&gt;&amp; nums) &#123;        int l = 0, r = nums.size() - 1, pos = nums.size() - 1;        vector&lt;int&gt; result(nums.size());  // 创建 int 类型的结果数组        while (l &lt;= r) &#123;            int ll = nums[l] * nums[l];              int rr = nums[r] * nums[r];              if (ll &gt;= rr) &#123;                result[pos] = ll;                l++;            &#125; else &#123;                result[pos] = rr;                r--;            &#125;            pos--;        &#125;        return result;  // 返回结果数组    &#125;&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>二分查找</tag>
        <tag>双指针</tag>
        <tag>数组</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--数组</title>
    <url>/2025/01/2day/</url>
    <content><![CDATA[滑动窗口
​	刚开始不太好想到滑动窗口这种方法，即使想到了也并没有办法证明滑动窗口方法的正确性，现在我也不会证明。只是会用，前几天做过一次，这是第二次做，记住了这个方法之后也是没有什么障碍。
例题
题目链接：209. 长度最小的子数组
题目描述：找出数组中满足其总和大于等于 target 的长度最小的子数组，并返回其长度**。**如果不存在符合条件的子数组，返回 0 。
class Solution &#123;public:    int minSubArrayLen(int target, vector&lt;int&gt;&amp; nums) &#123;      int n=nums.size();      int sum=0,m=100010,j=0;      for(int i=0;i&lt;n;i++)      &#123;        sum=sum+nums[i];        while(sum&gt;=target)&#123;            m=min(m,i-j+1);            sum-=nums[j++];        &#125;      &#125;      if(m==100010) return 0;      return m;    &#125;&#125;;
相关题目
904. 水果成篮
题目描述：找一个最长连续子数组，满足子数组中至多有两种数字。返回子数组的长度。
这题题目描述很抽象，没看懂啥意思，去评论区的解释。
76. 最小覆盖子串
不会做，没思路，目前水平不够，直接跳。
矩阵规律
题目链接：59. 螺旋矩阵 II
题目描述：给定一个正整数 n ，生成一个包含 1 到 n2 所有元素，且元素按顺时针顺序螺旋排列的 n x n 正方形矩阵 matrix 。
例题
贪吃蛇输出
题目思路：直接按顺序输出，定义上下左右四个边界，从左到右输出上边界加一，从上到下输出右边界减一，从右向左输出下边界减一，从下到上输出左边界加一，依次输出就可以，因为上边界加一，从上到下就少输出一个，右边界减一，从右到左输出就少输出一个。从下向上输出时，下边界减一，上边界加一，正好按顺序输出，完美！
class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; generateMatrix(int n) &#123;        vector&lt;vector&lt;int&gt;&gt; res(n, vector&lt;int&gt;(n, 0));        int l=0,r=n-1,t=0,b=n-1,count=1;        while(count&lt;=(n*n))        &#123;            for(int i=l;i&lt;=r;i++)            &#123;                res[t][i]=count;                count++;            &#125;            t++;            for(int j=t;j&lt;=b;j++)            &#123;                res[j][r]=count;                count++;            &#125;            r--;            for(int j=r;j&gt;=l;j--)            &#123;                res[b][j]=count;                count++;            &#125;            b--;            for(int j=b;j&gt;=t;j--)            &#123;                res[j][l]=count;                count++;            &#125;            l++;        &#125;        return res;    &#125;&#125;;
循环不变量原则
思路：每条边按左闭右开的输出，每圈输出四次，每次输出边长减一个，这里直接贴一下代码随想录的代码。
class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; generateMatrix(int n) &#123;        vector&lt;vector&lt;int&gt;&gt; res(n, vector&lt;int&gt;(n, 0)); // 使用vector定义一个二维数组        int startx = 0, starty = 0; // 定义每循环一个圈的起始位置        int loop = n / 2;         // 每个圈循环几次，例如n为奇数3，那么loop = 1 只是循环一圈，矩阵中间的值需要单独处理        int mid = n / 2;         // 矩阵中间的位置，例如：n为3， 中间的位置就是(1，1)，n为5，中间位置为(2, 2)        int count = 1; // 用来给矩阵中每一个空格赋值        int offset = 1; // 需要控制每一条边遍历的长度，每次循环右边界收缩一位        int i,j;        while (loop --) &#123;            i = startx;            j = starty;        // 下面开始的四个for就是模拟转了一圈        // 模拟填充上行从左到右(左闭右开)            for (j; j &lt; n - offset; j++) res[i][j] = count++;        // 模拟填充右列从上到下(左闭右开)            for (i; i &lt; n - offset; i++) res[i][j] = count++;        // 模拟填充下行从右到左(左闭右开)            for (; j &gt; starty; j--) res[i][j] = count++;        // 模拟填充左列从下到上(左闭右开)            for (; i &gt; startx; i--) res[i][j] = count++;        // 第二圈开始的时候，起始位置要各自加1， 例如：第一圈起始位置是(0, 0)，第二圈起始位置是(1, 1)            startx++;            starty++;        // offset 控制每一圈里每一条边遍历的长度            offset += 1;        &#125;        // 如果n为奇数的话，需要单独给矩阵最中间的位置赋值        if (n % 2) res[mid][mid] = count;        return res;    &#125;&#125;;
相关题目
54. 螺旋矩阵
进阶了一下，今天没时间了改天再做，这两天光建blog了。
LCR 146. 螺旋遍历二维数组
这题虽然是简单题，但是做起来比例题难，这题边界问题比较棘手。
class Solution &#123;public:    vector&lt;int&gt; spiralArray(vector&lt;vector&lt;int&gt;&gt;&amp; array) &#123;        if (array.empty() || array[0].empty()) &#123;            return &#123;&#125;; // 返回空 vector        &#125;        int t=0,l=0,r=array[0].size() -1,b=array.size()-1,n=array[0].size()*array.size();        vector&lt;int&gt; ans(n);        int j=0;        while(t &lt;= b &amp;&amp; l &lt;= r)&#123;            for(int i=l;i&lt;=r;i++) ans[j++]=array[t][i];            t++;            for(int i=t;i&lt;=b;i++) ans[j++]=array[i][r];            r--;            if (t &lt;= b) &#123; // 确保没有重复遍历                for (int i = r; i &gt;= l; i--) &#123;                    ans[j++] = array[b][i];                &#125;                b--;            &#125;            if (l &lt;= r) &#123; // 确保没有重复遍历                for (int i = b; i &gt;= t; i--) &#123;                    ans[j++] = array[i][l];                &#125;                l++;            &#125;        &#125;        return ans;    &#125;&#125;;
前缀和
前缀和 在涉及计算区间和的问题时非常有用！
刚开始使用的暴力解法，一直不行，知道看了题解才知道，故意卡暴力解。然后自己也想不出什么好方法，就问的chatgpt，这种方法刚开始我还以为时间复杂度差不多呢。
例题
题目链接：区间和
题目描述：给定一个整数数组 Array，请计算该数组在每个指定区间内元素的总和。
#include &lt;cstdio&gt;int main() &#123;    int n;    scanf(&quot;%d&quot;, &amp;n);    int a[n];    // 读取数组元素    for (int i = 0; i &lt; n; i++) &#123;        scanf(&quot;%d&quot;, &amp;a[i]);    &#125;    // 计算前缀和数组    int prefixSum[n + 1];  // prefixSum[0] = 0    prefixSum[0] = 0;    for (int i = 1; i &lt;= n; i++) &#123;        prefixSum[i] = prefixSum[i - 1] + a[i - 1];    &#125;    // 处理区间查询    int l, r;    while (scanf(&quot;%d %d&quot;, &amp;l, &amp;r) != EOF) &#123;        // 使用前缀和快速计算区间 [l, r] 的和        printf(&quot;%d\n&quot;, prefixSum[r + 1] - prefixSum[l]);    &#125;    return 0;&#125;
相关题目
开发商购买土地
看起来挺难的，没看懂题目意思，明天再研究。
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>数组</tag>
        <tag>滑动窗口</tag>
        <tag>矩阵规律</tag>
        <tag>前缀和</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--链表</title>
    <url>/2025/01/3day/</url>
    <content><![CDATA[链表基础
​	链表是一种通过指针串联在一起的线性结构，每一个节点由两部分组成，一个是数据域一个是指针域，最后一个节点的指针域指向null（空指针的意思）。
移除链表元素
题目链接：203. 移除链表元素
题目描述：一个链表的头节点 head 和一个整数 val ，删除链表中所有满足 Node.val == val 的节点，并返回新的头节点 。
虚拟头节点
时间复杂度：O(n)     空间复杂度：O(1)
题目思路：如果直接处理链表的话，需要考虑头节点，但是加入虚拟头节点就可以按照统一的方式去处理。
class Solution &#123;public:    ListNode* removeElements(ListNode* head, int val) &#123;        ListNode* dummy=new ListNode(0);        ListNode* pre=dummy;        pre-&gt;next=head;        while(head)        &#123;            if(head-&gt;val==val)            &#123;                pre-&gt;next=head-&gt;next;                ListNode* tem=head;                head=head-&gt;next;                delete tem;            &#125;            else            &#123;                pre=head;                head=head-&gt;next;            &#125;        &#125;        return dummy-&gt;next;    &#125;&#125;;
直接操作
时间复杂度：O(n)     空间复杂度：O(1)
class Solution &#123;public:    ListNode* removeElements(ListNode* head, int val) &#123;        // 删除头结点        while (head != NULL &amp;&amp; head-&gt;val == val) &#123; // 注意这里不是if            ListNode* tmp = head;            head = head-&gt;next;            delete tmp;        &#125;        // 删除非头结点        ListNode* cur = head;        while (cur != NULL &amp;&amp; cur-&gt;next!= NULL) &#123;            if (cur-&gt;next-&gt;val == val) &#123;                ListNode* tmp = cur-&gt;next;                cur-&gt;next = cur-&gt;next-&gt;next;                delete tmp;            &#125; else &#123;                cur = cur-&gt;next;            &#125;        &#125;        return head;    &#125;&#125;;
递归解法
时间复杂度：O(n)     空间复杂度：O(n)
题目思路：首先检查头节点的值是否为 val，如果是则移除头节点，答案即为在头节点的后续节点上递归的结果；如果头节点的值不为 val，则答案为头节点与在头节点的后续节点上递归得到的新链表拼接的结果。
class Solution &#123;public:    ListNode* removeElements(ListNode* head, int val) &#123;        // 基础情况：空链表        if (head == nullptr) &#123;            return nullptr;        &#125;        // 递归处理        if (head-&gt;val == val) &#123;            ListNode* newHead = removeElements(head-&gt;next, val);            delete head;            return newHead;        &#125; else &#123;            head-&gt;next = removeElements(head-&gt;next, val);            return head;        &#125;    &#125;&#125;;
反转链表
题目链接：206. 反转链表
题目描述：反转单链表，并返回反转后的链表。
双指针法
时间复杂度：O(n)     空间复杂度：O(1)
题目思路：定义cur和pre指针，pre初始化为NULL，cur指向head，然后反转链表，cur-&gt;next指向pre，按逻辑移动。
class Solution &#123;public:    ListNode* reverseList(ListNode* head) &#123;        ListNode* tem;        ListNode* cur=head;        ListNode* pre=NULL;        while(cur)        &#123;            tem=cur-&gt;next;            cur-&gt;next=pre;            pre=cur;            cur=tem;        &#125;        return pre;    &#125;&#125;;
递归法
思路和双指针差不多，明天研究一下。
时间复杂度：O(n)     空间复杂度：O(n)
class Solution &#123;public:    ListNode* reverse(ListNode* pre,ListNode* cur)&#123;        if(cur == NULL) return pre;        ListNode* temp = cur-&gt;next;        cur-&gt;next = pre;        // 可以和双指针法的代码进行对比，如下递归的写法，其实就是做了这两步        // pre = cur;        // cur = temp;        return reverse(cur,temp);    &#125;    ListNode* reverseList(ListNode* head) &#123;        // 和双指针法初始化是一样的逻辑        // ListNode* cur = head;        // ListNode* pre = NULL;        return reverse(NULL, head);    &#125;&#125;;
设计链表
题目链接：707. 设计链表
题目描述：获取第index个节点的值，添加头节点，添加尾节点，在第 index 个节点之前添加值为 val 的节点，删除链表中的第 index 个节点。
虚拟头节点
class MyLinkedList &#123;private:    struct LinkedNode &#123;          // 先定义 LinkedNode 结构体        int val;        LinkedNode* next;        LinkedNode(int val) : val(val), next(nullptr) &#123;&#125;    &#125;;    LinkedNode* dummyhead;       // 现在可以使用 LinkedNode 类型    int size;    public:    MyLinkedList() &#123;        dummyhead=new LinkedNode(0);        size=0;    &#125;       int get(int index) &#123;        if(index&gt;(size-1) || index&lt;0)&#123;            return -1;        &#125;        LinkedNode* cur=dummyhead-&gt;next;        while(index--)&#123;            cur=cur-&gt;next;        &#125;        return cur-&gt;val;    &#125;      void addAtHead(int val) &#123;        LinkedNode* newNode = new LinkedNode(val);        newNode-&gt;next=dummyhead-&gt;next;        dummyhead-&gt;next=newNode;        size++;    &#125;     void addAtTail(int val) &#123;        LinkedNode* newNode=new LinkedNode(val);        LinkedNode* cur=dummyhead;        while(cur-&gt;next != NULL)        &#123;            cur=cur-&gt;next;        &#125;        cur-&gt;next=newNode;        size++;    &#125;       void addAtIndex(int index, int val) &#123;        if(index&gt;size) return;        if(index&lt;0) index=0;        LinkedNode* newNode=new LinkedNode(val);        LinkedNode* cur=dummyhead;        while(index--)&#123;            cur=cur-&gt;next;        &#125;        newNode-&gt;next=cur-&gt;next;        cur-&gt;next=newNode;        size++;    &#125;    void deleteAtIndex(int index) &#123;        if(index&gt;(size-1) || index&lt;0)&#123;            return;        &#125;        LinkedNode* cur=dummyhead;        while(index--)        &#123;            cur=cur-&gt;next;        &#125;        LinkedNode* tem=cur-&gt;next;        cur-&gt;next=cur-&gt;next-&gt;next;        delete tem;        size--;    &#125;&#125;;
虚拟头节点（双链表）
还未看，直接copy的
//采用循环虚拟结点的双链表实现class MyLinkedList &#123;public:    // 定义双向链表节点结构体    struct DList &#123;        int elem; // 节点存储的元素        DList *next; // 指向下一个节点的指针        DList *prev; // 指向上一个节点的指针        // 构造函数，创建一个值为elem的新节点        DList(int elem) : elem(elem), next(nullptr), prev(nullptr) &#123;&#125;;    &#125;;    // 构造函数，初始化链表    MyLinkedList() &#123;        sentinelNode = new DList(0); // 创建哨兵节点，不存储有效数据        sentinelNode-&gt;next = sentinelNode; // 哨兵节点的下一个节点指向自身，形成循环        sentinelNode-&gt;prev = sentinelNode; // 哨兵节点的上一个节点指向自身，形成循环        size = 0; // 初始化链表大小为0    &#125;    // 获取链表中第index个节点的值    int get(int index) &#123;        if (index &gt; (size - 1) || index &lt; 0) &#123; // 检查索引是否超出范围            return -1; // 如果超出范围，返回-1        &#125;        int num;        int mid = size &gt;&gt; 1; // 计算链表中部位置        DList *curNode = sentinelNode; // 从哨兵节点开始        if (index &lt; mid) &#123; // 如果索引小于中部位置，从前往后遍历            for (int i = 0; i &lt; index + 1; i++) &#123;                curNode = curNode-&gt;next; // 移动到目标节点            &#125;        &#125; else &#123; // 如果索引大于等于中部位置，从后往前遍历            for (int i = 0; i &lt; size - index; i++) &#123;                curNode = curNode-&gt;prev; // 移动到目标节点            &#125;        &#125;        num = curNode-&gt;elem; // 获取目标节点的值        return num; // 返回节点的值    &#125;    // 在链表头部添加节点    void addAtHead(int val) &#123;        DList *newNode = new DList(val); // 创建新节点        DList *next = sentinelNode-&gt;next; // 获取当前头节点的下一个节点        newNode-&gt;prev = sentinelNode; // 新节点的上一个节点指向哨兵节点        newNode-&gt;next = next; // 新节点的下一个节点指向原来的头节点        size++; // 链表大小加1        sentinelNode-&gt;next = newNode; // 哨兵节点的下一个节点指向新节点        next-&gt;prev = newNode; // 原来的头节点的上一个节点指向新节点    &#125;    // 在链表尾部添加节点    void addAtTail(int val) &#123;        DList *newNode = new DList(val); // 创建新节点        DList *prev = sentinelNode-&gt;prev; // 获取当前尾节点的上一个节点        newNode-&gt;next = sentinelNode; // 新节点的下一个节点指向哨兵节点        newNode-&gt;prev = prev; // 新节点的上一个节点指向原来的尾节点        size++; // 链表大小加1        sentinelNode-&gt;prev = newNode; // 哨兵节点的上一个节点指向新节点        prev-&gt;next = newNode; // 原来的尾节点的下一个节点指向新节点    &#125;    // 在链表中的第index个节点之前添加值为val的节点    void addAtIndex(int index, int val) &#123;        if (index &gt; size) &#123; // 检查索引是否超出范围            return; // 如果超出范围，直接返回        &#125;        if (index &lt;= 0) &#123; // 如果索引为0或负数，在头部添加节点            addAtHead(val);            return;        &#125;        int num;        int mid = size &gt;&gt; 1; // 计算链表中部位置        DList *curNode = sentinelNode; // 从哨兵节点开始        if (index &lt; mid) &#123; // 如果索引小于中部位置，从前往后遍历            for (int i = 0; i &lt; index; i++) &#123;                curNode = curNode-&gt;next; // 移动到目标位置的前一个节点            &#125;            DList *temp = curNode-&gt;next; // 获取目标位置的节点            DList *newNode = new DList(val); // 创建新节点            curNode-&gt;next = newNode; // 在目标位置前添加新节点            temp-&gt;prev = newNode; // 目标位置的节点的前一个节点指向新节点            newNode-&gt;next = temp; // 新节点的下一个节点指向目标位置的结点            newNode-&gt;prev = curNode; // 新节点的上一个节点指向当前节点        &#125; else &#123; // 如果索引大于等于中部位置，从后往前遍历            for (int i = 0; i &lt; size - index; i++) &#123;                curNode = curNode-&gt;prev; // 移动到目标位置的后一个节点            &#125;            DList *temp = curNode-&gt;prev; // 获取目标位置的节点            DList *newNode = new DList(val); // 创建新节点            curNode-&gt;prev = newNode; // 在目标位置后添加新节点            temp-&gt;next = newNode; // 目标位置的节点的下一个节点指向新节点            newNode-&gt;prev = temp; // 新节点的上一个节点指向目标位置的节点            newNode-&gt;next = curNode; // 新节点的下一个节点指向当前节点        &#125;        size++; // 链表大小加1    &#125;    // 删除链表中的第index个节点    void deleteAtIndex(int index) &#123;        if (index &gt; (size - 1) || index &lt; 0) &#123; // 检查索引是否超出范围            return; // 如果超出范围，直接返回        &#125;        int num;        int mid = size &gt;&gt; 1; // 计算链表中部位置        DList *curNode = sentinelNode; // 从哨兵节点开始        if (index &lt; mid) &#123; // 如果索引小于中部位置，从前往后遍历            for (int i = 0; i &lt; index; i++) &#123;                curNode = curNode-&gt;next; // 移动到目标位置的前一个节点            &#125;            DList *next = curNode-&gt;next-&gt;next; // 获取目标位置的下一个节点            curNode-&gt;next = next; // 删除目标位置的节点            next-&gt;prev = curNode; // 目标位置的下一个节点的前一个节点指向当前节点        &#125; else &#123; // 如果索引大于等于中部位置，从后往前遍历            for (int i = 0; i &lt; size - index - 1; i++) &#123;                curNode = curNode-&gt;prev; // 移动到目标位置的后一个节点            &#125;            DList *prev = curNode-&gt;prev-&gt;prev; // 获取目标位置的下一个节点            curNode-&gt;prev = prev; // 删除目标位置的节点            prev-&gt;next = curNode; // 目标位置的下一个节点的下一个节点指向当前节点        &#125;        size--; // 链表大小减1    &#125;private:    int size; // 链表的大小    DList *sentinelNode; // 哨兵节点的指针&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>递归</tag>
        <tag>双指针</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--链表</title>
    <url>/2025/01/4day/</url>
    <content><![CDATA[链表操作
​	链表是一种通过指针串联在一起的线性结构，每一个节点由两部分组成，一个是数据域一个是指针域，最后一个节点的指针域指向null（空指针的意思）。
两两交换链表中的节点
题目链接：24. 两两交换链表中的节点
题目描述：两两交换链表中相邻的节点，并返回交换后链表的头节点
虚拟头节点
时间复杂度：O(n)     空间复杂度：O(1)
题目思路：直接对指针进行处理就行了。刚才随手写了一下，想着交一下看看哪里有bug呢，结果直接过了，也是挺顺的。
class Solution &#123;public:    ListNode* swapPairs(ListNode* head) &#123;        ListNode* dummy=new ListNode(0);        ListNode* pre=dummy;        dummy-&gt;next=head;        while(head &amp;&amp; head-&gt;next)        &#123;            ListNode* tmp=pre-&gt;next;            ListNode* tmp1=pre-&gt;next-&gt;next-&gt;next;            pre-&gt;next=head-&gt;next;            pre-&gt;next-&gt;next=tmp;            pre-&gt;next-&gt;next-&gt;next=tmp1;            pre=tmp;            head=tmp1;        &#125;        return dummy-&gt;next;    &#125;&#125;;
删除链表的倒数第 N 个结点
题目链接：9. 删除链表的倒数第 N 个结点
题目描述：删除链表的倒数第 n 个结点，并且返回链表的头结点。
快慢双指针法
时间复杂度：O(n)     空间复杂度：O(1)
题目思路：又给秒了，定义一个快指针，一个慢指针，快指针先移动到第n个位置，然后开始快慢指针开始同时移动，当快指针指向尾节点的时候，慢指针正好指向导数第n个位置的前一个结点，略过倒数第n个结点，就结束了。
class Solution &#123;public:    ListNode* removeNthFromEnd(ListNode* head, int n) &#123;        ListNode* dummy=new ListNode(0);        ListNode* fast=dummy;        ListNode* slow=dummy;        dummy-&gt;next=head;        for(int i=0;i&lt;=n;i++) fast=fast-&gt;next;        while(fast)        &#123;            fast=fast-&gt;next;            slow=slow-&gt;next;        &#125;        ListNode* tmp=slow-&gt;next;        slow-&gt;next=slow-&gt;next-&gt;next;        delete tmp;        return dummy-&gt;next;    &#125;&#125;;
链表相交
题目链接：面试题 02.07. 链表相交
题目描述：给定单链表的头节点 headA 和 headB ，找出并返回两个单链表相交的起始节点。如果两个链表没有交点，返回 null 。
思路1
题目思路：求两个链表交点节点的指针。题目我都看不懂！看题解秒了。
求出两个链表的长度，并求出两个链表长度的差值，然后让curA移动到，和curB 末尾对齐的位置。比较curA和curB是否相同，如果不相同，同时向后移动curA和curB，如果遇到curA == curB，则找到交点。否则循环退出返回空指针。
class Solution &#123;public:    ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) &#123;        ListNode* curA = headA;        ListNode* curB = headB;        int lenA = 0, lenB = 0;        while (curA != NULL) &#123; // 求链表A的长度            lenA++;            curA = curA-&gt;next;        &#125;        while (curB != NULL) &#123; // 求链表B的长度            lenB++;            curB = curB-&gt;next;        &#125;        curA = headA;        curB = headB;        // 让curA为最长链表的头，lenA为其长度        if (lenB &gt; lenA) &#123;            swap (lenA, lenB);            swap (curA, curB);        &#125;        // 求长度差        int gap = lenA - lenB;        // 让curA和curB在同一起点上（末尾位置对齐）        while (gap--) &#123;            curA = curA-&gt;next;        &#125;        // 遍历curA 和 curB，遇到相同则直接返回        while (curA != NULL) &#123;            if (curA == curB) &#123;                return curA;            &#125;            curA = curA-&gt;next;            curB = curB-&gt;next;        &#125;        return NULL;    &#125;&#125;;
思路二
再贴个牛逼代码。
class Solution &#123;public:    ListNode *getIntersectionNode(ListNode *headA, ListNode *headB) &#123;        ListNode *A = headA, *B = headB;        while (A != B) &#123;            A = A != nullptr ? A-&gt;next : headB;            B = B != nullptr ? B-&gt;next : headA;        &#125;        return A;    &#125;&#125;;
环形链表
题目链接：142. 环形链表 II
题目描述：给定一个链表，返回链表开始入环的第一个节点。 如果链表无环，则返回 null。
题目思路：很有生活的题，不太好想，看题解才明白怎么才能找到环的入口，也是挺有思维量的。想明白了就好了，记下来就行了。
class Solution &#123;public:    ListNode *detectCycle(ListNode *head) &#123;        ListNode* fast=head;        ListNode* slow=head;        while(fast &amp;&amp; fast-&gt;next)&#123;            fast=fast-&gt;next-&gt;next;            slow=slow-&gt;next;            if(fast==slow)&#123;                ListNode* f=fast;                ListNode* s=head;                while(f!=s)&#123;                    f=f-&gt;next;                    s=s-&gt;next;                &#125;                return s;            &#125;        &#125;        return 0;    &#125;&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>递归</tag>
        <tag>双指针</tag>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--哈希表</title>
    <url>/2025/02/5day/</url>
    <content><![CDATA[哈希表
​	查询一个元素是否出现过，或者一个元素是否在集合里的时候，就要第一时间想到哈希法。一种以关键码的值**「key-value」而直接进行访问的数据结构**。
有效的字母异位词
题目链接：242. 有效的字母异位词
题目描述：给定两个字符串 s 和 t ，编写一个函数来判断 t 是否是 s 的 字母异位词。
题目思路：创建一个哈希表，表长为26，哈希函数采用直接定址法，都不用处理冲突，还是比较简单的。直接排序，看是否两个数组相等应该也可以吧。
class Solution &#123;public:    bool isAnagram(string s, string t) &#123;        int n=s.size(),m=t.size(),q[26]=&#123;0&#125;;        if(m!=n) return false;        for(int i=0;i&lt;n;i++) q[s[i]-&#x27;a&#x27;]++;        for(int i=0;i&lt;m;i++) q[t[i]-&#x27;a&#x27;]--;        for(int i=0;i&lt;26;i++) if(q[i]!=0) return false;        return true;    &#125;&#125;;
两个数组的交集
题目链接：349. 两个数组的交集
题目描述：给定两个数组 nums1 和 nums2 ，返回它们的交集。输出结果中的每个元素一定是 唯一 的。
我的思路：感觉自己写的这个代码和屎一样，又臭又长，一点也不优雅。首先循环nums1数组，将出现的元素在s[]的位置变为1，然后再遍历第二个数组，如果出现和第一个数组相同的元素，则t[]对应位置变为1，再将这些位置存到一个新数组中，记录数组长度，然后构建一个正好长度的新数组，返回这个数组。
class Solution &#123;public:    vector&lt;int&gt; intersection(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123;        int n=nums1.size(),m=nums2.size();        int s[1001]=&#123;0&#125;,t[1001]=&#123;-1&#125;,num=0,u=1001;        for(int i=0;i&lt;n;i++) s[nums1[i]]=1;        for(int i=0;i&lt;m;i++) if(s[nums2[i]]==1) t[nums2[i]]=1;        vector&lt;int&gt; r(u);        for(int i=0;i&lt;1001;i++)        &#123;            if(t[i]&gt;0)&#123;r[num]=i;            num++;            &#125;        &#125;        vector&lt;int&gt; v(num);        for(int i=0;i&lt;num;i++) v[i]=r[i];        return v;    &#125;&#125;;
代码随想录题解：太高级了，看都看不懂，特意搜了一下这几个函数的用法。
​	使用 unordered_set&lt;int&gt; result 来存储交集，这样可以自动去重，只保留一个 nums2 中与 nums1 相同的元素。
set1.find(num)：

find 是 unordered_set 提供的一个成员函数，用于查找一个元素。如果元素存在，它会返回指向该元素的迭代器；如果元素不存在，它会返回指向 set1.end() 的迭代器。

set1.end()：

set1.end() 返回的是一个指向 set1 容器最后一个元素之后的位置的迭代器。它并不是容器中的一个有效元素，表示容器的末尾。

set1.find(num) != set1.end()：

如果 find(num) 返回的迭代器与 set1.end() 不同，说明 num 存在于 set1 中。
如果 find(num) 返回的迭代器等于 set1.end()，说明 num 不存在于 set1 中。

class Solution &#123;public:    vector&lt;int&gt; intersection(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123;        unordered_set&lt;int&gt; result_set;         unordered_set&lt;int&gt; nums_set(nums1.begin(), nums1.end());        for (int num : nums2) &#123;            if (nums_set.find(num) != nums_set.end()) &#123;                result_set.insert(num);            &#125;        &#125;        return vector&lt;int&gt;(result_set.begin(), result_set.end());    &#125;&#125;;
class Solution &#123;public:    vector&lt;int&gt; intersection(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123;        unordered_set&lt;int&gt; result_set;         int hash[1005] = &#123;0&#125;;         for (int num : nums1) &#123;             hash[num] = 1;        &#125;        for (int num : nums2) &#123;             if (hash[num] == 1) &#123;                result_set.insert(num);            &#125;        &#125;        return vector&lt;int&gt;(result_set.begin(), result_set.end());    &#125;&#125;;
快乐数
题目链接：202. 快乐数
我的思路：我就随便试一下，就直接过了，因为不知道停止条件，所以直接设了个100次，性能还很高。
class Solution &#123;public:    bool isHappy(int n) &#123;        for(int j=0;j&lt;100;j++)        &#123;            int num=0,t;            while(n&gt;0)            &#123;t=n%10;            n=n/10;            num=num+t*t;            &#125;            n=num;            if(n==1) return true;        &#125;        return false;    &#125;&#125;;
代码随想录：题目中说了会 无限循环，那么也就是说求和的过程中，sum会重复出现，这对解题很重要！
class Solution &#123;public:    // 取数值各个位上的单数之和    int getSum(int n) &#123;        int sum = 0;        while (n) &#123;            sum += (n % 10) * (n % 10);            n /= 10;        &#125;        return sum;    &#125;    bool isHappy(int n) &#123;        unordered_set&lt;int&gt; set;        while(1) &#123;            int sum = getSum(n);            if (sum == 1) &#123;                return true;            &#125;            // 如果这个sum曾经出现过，说明已经陷入了无限循环了，立刻return false            if (set.find(sum) != set.end()) &#123;                return false;            &#125; else &#123;                set.insert(sum);            &#125;            n = sum;        &#125;    &#125;&#125;;
两数之和
题目链接：1. 两数之和
暴力解法：我直接先用暴力解写了一下,比较简单。
class Solution &#123;public:    vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123;         int n=nums.size();        for(int i=0;i&lt;n;i++)        &#123;            for(int j=i+1;j&lt;n;j++)            &#123;                if((nums[i]+nums[j])==target)                 &#123;                    return &#123;i,j&#125;;                &#125;            &#125;        &#125;        return &#123;&#125;;    &#125;&#125;;
哈希解法：思路还是挺好想的，但是代码不太会实现，不太熟练，自己写了一半，发现很多操作不会表达。直接贴一份代码随想录的代码。

数组的大小是受限制的，而且如果元素很少，而哈希值太大会造成内存空间的浪费。
set是一个集合，里面放的元素只能是一个key，而两数之和这道题目，不仅要判断y是否存在而且还要记录y的下标位置，因为要返回x 和 y的下标。所以set 也不能用。

​	此时就要选择另一种数据结构：map ，map是一种key value的存储结构，可以用key保存数值，用value再保存数值所在的下标。
map中的存储结构为 {key：数据元素，value：数组元素对应的下标}。
auto 是 C++11 引入的 类型自动推导（Type Inference） 关键字，编译器会根据变量的 初始化值 自动推导出其数据类型，而无需手动声明类型。
class Solution &#123;public:    vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; nums, int target) &#123;        std::unordered_map &lt;int,int&gt; map;        for(int i = 0; i &lt; nums.size(); i++) &#123;            // 遍历当前元素，并在map中寻找是否有匹配的key            auto iter = map.find(target - nums[i]);             if(iter != map.end()) &#123;                return &#123;iter-&gt;second, i&#125;;            &#125;            // 如果没找到匹配对，就把访问过的元素和下标加入到map中            map.insert(pair&lt;int, int&gt;(nums[i], i));         &#125;        return &#123;&#125;;    &#125;&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>哈希表</tag>
        <tag>查找</tag>
        <tag>set</tag>
        <tag>map</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--哈希表</title>
    <url>/2025/02/6day/</url>
    <content><![CDATA[哈希表
​	查询一个元素是否出现过，或者一个元素是否在集合里的时候，就要第一时间想到哈希法。一种以关键码的值**「key-value」而直接进行访问的数据结构**。总结
四数相加Ⅱ
题目链接：454. 四数相加 II
题目思路：我刚开始的思路是for四次，但是算了一下，可能有点超时，然后就直接看题解了。将四个数组两两分成一组进行处理，时间复杂度就是O(n*n)。

首先定义 一个unordered_map，key放a和b两数之和，value 放a和b两数之和出现的次数。
遍历大A和大B数组，统计两个数组元素之和，和出现的次数，放到map中。
定义int变量count，用来统计 a+b+c+d = 0 出现的次数。
再遍历大C和大D数组，找到如果 0-(c+d) 在map中出现过的话，就用count把map中key对应的value也就是出现次数统计出来。
最后返回统计值 count 就可以了

class Solution &#123;public:    int fourSumCount(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2, vector&lt;int&gt;&amp; nums3, vector&lt;int&gt;&amp; nums4) &#123;        unordered_map&lt;int,int&gt; umap;        for(int a : nums1) for(int b:nums2) umap[a+b]++;        int count=0;        for(int c:nums3) for(int d:nums4) if(umap.find(0-(c+d))!=umap.end()) count+=umap[0-(c+d)];        return count;    &#125;&#125;;
救赎金
题目链接：383. 赎金信
题目思路：秒了，这和 242. 有效的字母异位词 几乎差不多。
class Solution &#123;public:    bool canConstruct(string ransomNote, string magazine) &#123;        int n=magazine.size(),m=ransomNote.size();        int j[26]=&#123;0&#125;;        for(int i=0;i&lt;n;i++) j[magazine[i]-&#x27;a&#x27;]++;        for(int i=0;i&lt;m;i++) j[ransomNote[i]-&#x27;a&#x27;]--;        for(int i=0;i&lt;26;i++) if(j[i]&lt;0) return false;         return true;    &#125;&#125;;
三数之和
题目链接：15. 三数之和
题目思路1：感觉这题最不好处理的地方就是去重。三次循环，意料之中的超时了，当锻炼一下代码熟练度了。
class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123;        vector&lt;vector&lt;int&gt;&gt; result;        sort(nums.begin(),nums.end());        for(int i=0;i&lt;nums.size();i++)        &#123;            for(int j=i+1;j&lt;nums.size();j++)            &#123;                for(int k=j+1;k&lt;nums.size();k++)                &#123;                    if((nums[i]+nums[j]+nums[k])==0)                     result.push_back(&#123;nums[i], nums[j], nums[k]&#125;);                &#125;            &#125;        &#125;        set&lt;vector&lt;int&gt;&gt; unique_nums(result.begin(), result.end());        vector&lt;vector&lt;int&gt;&gt; result_vector(unique_nums.begin(), unique_nums.end());        return result_vector;    &#125;&#125;;
题目思路2：改了一下上一种方法，用哈希表进行处理。虽然可以通过，但是还是很慢。
class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123;        vector&lt;vector&lt;int&gt;&gt; result;        sort(nums.begin(),nums.end());        for(int i=0;i&lt;nums.size();i++)        &#123;            if (nums[i] &gt; 0) break;            if (i &gt; 0 &amp;&amp; nums[i] == nums[i - 1]) continue;            unordered_set&lt;int&gt; set;            for(int j=i+1;j&lt;nums.size();j++)            &#123;                int target = 0 - (nums[i] + nums[j]);                if (set.find(target) != set.end()) &#123;                    result.push_back(&#123;nums[i], target, nums[j]&#125;);                       set.erase(target);                &#125;                else &#123;                    set.insert(nums[j]);                &#125;            &#125;        &#125;        set&lt;vector&lt;int&gt;&gt; unique_nums(result.begin(), result.end());        vector&lt;vector&lt;int&gt;&gt; result_vector(unique_nums.begin(), unique_nums.end());        return result_vector;    &#125;&#125;;
双指针：代码随想录的那个代码，感觉很多地方可以优化，所以就去找了一个优化完的代码。首先先将数组排序，我们只需要输出加和等于0的元素就可以，不用管次序。排序之后就可以从两端开始操作了，先创造一个大循环，用来固定住第一个数，然后再用双指针取操作另外两个数。
优化一：当最小的三个数的和大于0时，就可以直接退出循环了。
优化二：当最大的两个数加最小的那个数，还是小于0，就可以向前移动到再大的数了。
class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; threeSum(vector&lt;int&gt;&amp; nums) &#123;        ranges::sort(nums);        vector&lt;vector&lt;int&gt;&gt; ans;        int n = nums.size();        for (int i = 0; i &lt; n - 2; i++) &#123;            int x = nums[i];            if (i &amp;&amp; x == nums[i - 1]) continue; // 跳过重复数字            if (x + nums[i + 1] + nums[i + 2] &gt; 0) break; // 优化一            if (x + nums[n - 2] + nums[n - 1] &lt; 0) continue; // 优化二            int j = i + 1, k = n - 1;            while (j &lt; k) &#123;                int s = x + nums[j] + nums[k];                if (s &gt; 0) &#123;                    k--;                &#125; else if (s &lt; 0) &#123;                    j++;                &#125; else &#123; // 三数之和为 0                    ans.push_back(&#123;x, nums[j], nums[k]&#125;);                    for (j++; j &lt; k &amp;&amp; nums[j] == nums[j - 1]; j++); // 跳过重复数字                    for (k--; k &gt; j &amp;&amp; nums[k] == nums[k + 1]; k--); // 跳过重复数字                &#125;            &#125;        &#125;        return ans;    &#125;&#125;;
四数之和
题目链接：18. 四数之和
我的思路：做了半个小时，好几个小问题，思路和上一题一样，用同样的方法，只不过多了一层循环，需要多判断一下重复条件，那几个相加超范围不太会如何处理，chatgpt让它给的方案。看了一下代码随想录的思路，差不多，它加了两行剪枝代码，但是它的代码性能有点慢，加了也不如我的这个性能高，我也在代码中加上了那两行剪枝代码。
class Solution &#123;public:    vector&lt;vector&lt;int&gt;&gt; fourSum(vector&lt;int&gt;&amp; nums, int target) &#123;        int n=nums.size();        sort(nums.begin(),nums.end());        vector&lt;vector&lt;int&gt;&gt; ans;        for(int i=0;i&lt;n-3;i++)            if(i&gt;0 &amp;&amp; nums[i]==nums[i-1]) continue;            if (nums[i] &gt; target &amp;&amp; nums[i] &gt;= 0) break; //             for(int j=i+1;j&lt;n-2;j++)            &#123;                if(j&gt;i+1 &amp;&amp; nums[j]==nums[j-1]) continue;                if(nums[i]+nums[j] &gt; target &amp;&amp; nums[i]+nums[j] &gt;= 0) break; //                int c=j+1,d=n-1;                if((long long)nums[i]+nums[j]+nums[j+1]+nums[j+2]&gt;target) break;                if((long long)nums[i]+nums[j]+nums[n-1]+nums[n-2]&lt;target) continue;                while(c&lt;d)&#123;                    long long sum=(long long)nums[i]+nums[j]+nums[c]+nums[d];                    if(sum&gt;target) d--;                    else if(sum&lt;target) c++;                    else&#123;                        ans.push_back(vector&lt;int&gt; &#123;nums[i],nums[j],nums[c],nums[d]&#125;);                        while(c&lt;d &amp;&amp; nums[c]==nums[c+1]) c++;                        while(c&lt;d &amp;&amp; nums[d]==nums[d-1]) d--;                        c++;                        d--;                    &#125;                &#125;            &#125;        &#125;        return ans;    &#125;&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>双指针</tag>
        <tag>哈希表</tag>
        <tag>map</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--字符串</title>
    <url>/2025/02/7day/</url>
    <content><![CDATA[字符串
​	字符串，就是由字符连接而成的序列。常见的字符串问题包括字符串匹配问题、子串相关问题、前缀/后缀相关问题、回文串相关问题、子序列相关问题等。
反转字符串
题目链接：344. 反转字符串
class Solution &#123;public:    void reverseString(vector&lt;char&gt;&amp; s) &#123;        for(int i=0,j=s.size()-1;i&lt;j;i++,j--)        &#123;            char a=s[i];            s[i]=s[j];            s[j]=a;        &#125;    &#125;&#125;;
反转字符串
题目链接：541. 反转字符串 II
注意一下reverse函数的用法。
class Solution &#123;public:    string reverseStr(string s, int k) &#123;        for (int i = 0; i &lt; s.size(); i += (2 * k)) &#123;            if (i + k &lt;= s.size()) &#123;                reverse(s.begin()  i, s.begin() + i + k );            &#125; else &#123;                reverse(s.begin() + i, s.end());            &#125;        &#125;        return s;    &#125;&#125;;
替换数字
题目链接：替换数字（第八期模拟笔试）
题目思路：看似简单，实则不好操作，gpt给的这个思路很好啊，重新弄一个新字符串然后拼接。代码随想录的那个太麻烦了，直接pass掉了。
#include &lt;iostream&gt;#include &lt;cctype&gt;  // 需要 isdigit()using namespace std;string replaceDigitsWithNumber(const string&amp; s) &#123;    string result;    for (char c : s) &#123;        if (isdigit(c)) &#123;            result += &quot;number&quot;;  // 仅替换数字        &#125; else &#123;            result += c;  // 直接添加非数字字符        &#125;    &#125;    return result;&#125;int main() &#123;    string s;    cin &gt;&gt; s;  // 读取输入    cout &lt;&lt; replaceDigitsWithNumber(s) &lt;&lt; endl;      return 0;&#125;
主要难点在于如何去掉空格，使用快慢指针。
class Solution &#123;public:    void reverse(string&amp; s, int start, int end)&#123; //翻转，区间写法：左闭右闭 []        for (int i = start, j = end; i &lt; j; i++, j--) &#123;            swap(s[i], s[j]);        &#125;    &#125;    void removeExtraSpaces(string&amp; s) &#123;//去除所有空格并在相邻单词之间添加空格, 快慢指针。        int slow = 0;   //整体思想参考https://programmercarl.com/0027.移除元素.html        for (int i = 0; i &lt; s.size(); ++i) &#123; //            if (s[i] != &#x27; &#x27;) &#123; //遇到非空格就处理，即删除所有空格。                if (slow != 0) s[slow++] = &#x27; &#x27;; //手动控制空格，给单词之间添加空格。slow != 0说明不是第一个单词，需要在单词前添加空格。                while (i &lt; s.size() &amp;&amp; s[i] != &#x27; &#x27;) &#123; //补上该单词，遇到空格说明单词结束。                    s[slow++] = s[i++];                &#125;            &#125;        &#125;        s.resize(slow); //slow的大小即为去除多余空格后的大小。    &#125;    string reverseWords(string s) &#123;        removeExtraSpaces(s); //去除多余空格，保证单词之间之只有一个空格，且字符串首尾没空格。        reverse(s, 0, s.size() - 1);        int start = 0; //removeExtraSpaces后保证第一个单词的开始下标一定是0。        for (int i = 0; i &lt;= s.size(); ++i) &#123;            if (i == s.size() || s[i] == &#x27; &#x27;) &#123; //到达空格或者串尾，说明一个单词结束。进行翻转。                reverse(s, start, i - 1); //翻转，注意是左闭右闭 []的翻转。                start = i + 1; //更新下一个单词的开始下标start            &#125;        &#125;        return s;    &#125;&#125;;
右旋字符串
题目链接：右旋字符串
题目思路：和前边有一题很类似，都是申请了一个额外的空间往上加，这题是先把后n个加上，再把前m-n个加上。
#include&lt;iostream&gt;using namespace std;int main()&#123;    int n;    string s,ans;    cin&gt;&gt;n&gt;&gt;s;    int m=s.size();    for(int i=(m-n);i&lt;m;i++) ans+=s[i];    for(int i=0;i&lt;(m-n);i++) ans+=s[i];    cout&lt;&lt;ans;    return 0;&#125;
代码随想录：它要求不申请额外的空间，这个就直接reverse两次，和上一题差不多，先全局再局部。
#include&lt;iostream&gt;#include&lt;algorithm&gt;using namespace std;int main() &#123;    int n;    string s;    cin &gt;&gt; n;    cin &gt;&gt; s;    int len = s.size(); //获取长度    reverse(s.begin(), s.end()); // 整体反转    reverse(s.begin(), s.begin() + n); // 先反转前一段，长度n    reverse(s.begin() + n, s.end()); // 再反转后一段    cout &lt;&lt; s &lt;&lt; endl;&#125; 
找出字符串中第一个匹配项的下标
题目链接：28. 找出字符串中第一个匹配项的下标
暴力解法：思路正确，但是我写的代码写的太麻烦了，下边贴一份优雅的代码。时间复杂度O(m*n)。
class Solution &#123;public:    int strStr(string haystack, string needle) &#123;        int s[26]=&#123;0&#125;;        if(needle.size()&gt;haystack.size()) return -1;        for(int i:needle) s[i-&#x27;a&#x27;]++;        for(int i=0;i&lt;haystack.size();i++)        &#123;            int t;            if(s[haystack[i]-&#x27;a&#x27;]==0) continue;            else&#123;                t=i;                int a=t;                for(int j=0;j&lt;needle.size();j++) if(haystack.size()-a&gt;=needle.size() &amp;&amp; haystack[a+j]==needle[j]) t++;            &#125;            if((t-i)==needle.size()) return i;        &#125;        return -1;    &#125;&#125;;
class Solution &#123;public:    int strStr(string s, string p) &#123;        int n = s.size(), m = p.size();        for(int i = 0; i &lt;= n - m; i++)&#123;            int j = i, k = 0;             while(k &lt; m and s[j] == p[k])&#123;                j++;                k++;            &#125;            if(k == m) return i;        &#125;        return -1;    &#125;&#125;;
**KMP解法：**当出现字符串不匹配时，可以记录一部分之前已经匹配的文本内容，利用这些信息避免从头再去做匹配。
前缀表是用来回退的，它记录了模式串与主串(文本串)不匹配的时候，模式串应该从哪里开始重新匹配。代码随想录写的这个就很通俗易懂。
Nex数组构造：

初始化
处理前后缀不相同的情况
处理前后缀相同的情况


class Solution &#123;public:    void getNext(int* next, const string&amp; s) &#123;        int j = -1;        next[0] = j;        for(int i = 1; i &lt; s.size(); i++) &#123; // 注意i从1开始            while (j &gt;= 0 &amp;&amp; s[i] != s[j + 1]) &#123; // 前后缀不相同了                j = next[j]; // 向前回退            &#125;            if (s[i] == s[j + 1]) &#123; // 找到相同的前后缀                j++;            &#125;            next[i] = j; // 将j（前缀的长度）赋给next[i]        &#125;    &#125;    int strStr(string haystack, string needle) &#123;        if (needle.size() == 0) &#123;            return 0;        &#125;		vector&lt;int&gt; next(needle.size());		getNext(&amp;next[0], needle);        int j = -1; // // 因为next数组里记录的起始位置为-1        for (int i = 0; i &lt; haystack.size(); i++) &#123; // 注意i就从0开始            while(j &gt;= 0 &amp;&amp; haystack[i] != needle[j + 1]) &#123; // 不匹配                j = next[j]; // j 寻找之前匹配的位置            &#125;            if (haystack[i] == needle[j + 1]) &#123; // 匹配，j和i同时向后移动                j++; // i的增加在for循环里            &#125;            if (j == (needle.size() - 1) ) &#123; // 文本串s里出现了模式串t                return (i - needle.size() + 1);            &#125;        &#125;        return -1;    &#125;&#125;;
重复的子字符串
题目链接：459. 重复的子字符串
暴力解法：想用暴力法写一下，结果写了两个小时，还是看了题解写出来的，钻牛角尖了。我写的代码性能不如官方代码高，贴一下官方代码。
class Solution &#123;public:    bool repeatedSubstringPattern(string s) &#123;        int n = s.size();        for (int i = 1; i * 2 &lt;= n; ++i) &#123;            if (n % i == 0) &#123;                bool match = true;                for (int j = i; j &lt; n; ++j) &#123;                    if (s[j] != s[j - i]) &#123;                        match = false;                        break;                    &#125;                &#125;                if (match) &#123;                    return true;                &#125;            &#125;        &#125;        return false;    &#125;&#125;;
移动匹配：将两个 s 连在一起，并移除第一个和最后一个字符。如果 s 是该字符串的子串，那么 s 就满足题目要求。
class Solution &#123;public:    bool repeatedSubstringPattern(string s) &#123;        string t = s + s;        t.erase(t.begin()); t.erase(t.end() - 1); // 掐头去尾        if (t.find(s) != std::string::npos) return true; // r        return false;    &#125;&#125;;
KMP实现：
class Solution &#123;public:    void getNext (int* next, const string&amp; s)&#123;        next[0] = -1;        int j = -1;        for(int i = 1;i &lt; s.size(); i++)&#123;            while(j &gt;= 0 &amp;&amp; s[i] != s[j + 1]) &#123;                j = next[j];            &#125;            if(s[i] == s[j + 1]) &#123;                j++;            &#125;            next[i] = j;        &#125;    &#125;    bool repeatedSubstringPattern (string s) &#123;        if (s.size() == 0) &#123;            return false;        &#125;        int next[s.size()];        getNext(next, s);        int len = s.size();        if (next[len - 1] != -1 &amp;&amp; len % (len - (next[len - 1] + 1)) == 0) &#123;            return true;        &#125;        return false;    &#125;&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>双指针</tag>
        <tag>字符串</tag>
        <tag>KMP</tag>
        <tag>reverse</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--栈·队列</title>
    <url>/2025/02/8day/</url>
    <content><![CDATA[栈·队列
​                                                                                    
stack
STL 中的 stack 容器提供了一众成员函数以供调用，其中较为常用的有：

元素访问

st.top() 返回栈顶


修改

st.push() 插入传入的参数到栈顶
st.pop() 弹出栈顶


容量

st.empty() 返回是否为空
st.size() 返回元素数量



queue
STL 中的 queue 容器提供了一众成员函数以供调用。其中较为常用的有：

元素访问

q.front() 返回队首元素
q.back() 返回队尾元素


修改

q.push() 在队尾插入元素
q.pop() 弹出队首元素


容量

q.empty() 队列是否为空
q.size() 返回队列中元素的数量



deque
STL 中的 deque 容器提供了一众成员函数以供调用。其中较为常用的有：

元素访问

q.front() 返回队首元素
q.back() 返回队尾元素


修改

q.push_back() 在队尾插入元素
q.pop_back() 弹出队尾元素
q.push_front() 在队首插入元素
q.pop_front() 弹出队首元素
q.insert() 在指定位置前插入元素（传入迭代器和元素）
q.erase() 删除指定位置的元素（传入迭代器）


容量

q.empty() 队列是否为空
q.size() 返回队列中元素的数量



此外，deque 还提供了一些运算符。其中较为常用的有：


使用赋值运算符 = 为 deque 赋值，类似 queue。


使用 [] 访问元素，类似 vector。


用栈实现队列
题目链接：232. 用栈实现队列
class MyQueue &#123;private:    // 如果 B 栈为空，将 A 栈中的元素倒入 B 栈    void moveToB() &#123;        if (B.empty()) &#123;            while (!A.empty()) &#123;                B.push(A.top());                A.pop();            &#125;        &#125;    &#125;public:    stack&lt;int&gt; A, B;    MyQueue() &#123;    &#125;    void push(int x) &#123;        A.push(x);    &#125;    int pop() &#123;        moveToB(); // 移动元素到 B 栈        int val = B.top();        B.pop();        return val;    &#125;    int peek() &#123;        moveToB(); // 移动元素到 B 栈        return B.top();    &#125;    bool empty() &#123;        return A.empty() &amp;&amp; B.empty();    &#125;&#125;;
用队列实现栈
题目链接：225. 用队列实现栈
方法一：使用 一个队列

push(x)：

首先，将元素 x 入队到队列末尾。
然后，将队列中前面已有的元素依次出队，再重新入队到队列末尾。
这样，队列的前端就始终是最新压入的元素，相当于实现了栈的“后进先出（LIFO）”顺序。


pop()：

直接将队首元素出队即可。因为在上一步的处理里，队首元素就是栈顶。


top()：

返回队首元素（不弹出）。


empty()：

判断队列是否为空。



class MyStack &#123;public:    queue&lt;int&gt; q;    MyStack() &#123;    &#125;        // 每次 push 后，把前面的 (size - 1) 个元素依次出队并重新入队，确保新元素在队首    void push(int x) &#123;        // 1. 新元素先入队        q.push(x);        // 2. 将前面的元素依次移到末尾        int n = q.size();        // 只需要将前面的 (n - 1) 个元素移动到末尾        for(int i = 0; i &lt; n - 1; i++) &#123;            q.push(q.front());            q.pop();        &#125;    &#125;        int pop() &#123;        int val = q.front();  // 由于 push 中的旋转操作，队首就是栈顶        q.pop();        return val;    &#125;        int top() &#123;        return q.front();     // 队首即为栈顶    &#125;        bool empty() &#123;        return q.empty();    &#125;&#125;;
方法二：使用 两个队列

队列 A 和 队列 B 协同工作，保证其中一个队列始终存放当前所有元素，另一个队列用来做辅助操作。
push(x)：

把新元素直接入队到空队列中（或者你可以总是把它放到 A，然后把 A 里旧的元素转移到 B，具体实现略有差异）。


pop()：

在 pop() 之前，我们需要把除最后一个元素外的所有元素，从一个队列（有数据的队列）依次出队并入队到另一个空队列，让最后一个元素留在原队列，然后弹出这个元素，这相当于栈顶元素。


top()：

类似 pop()，只是查看最后一个元素而不把它真正弹出。


empty()：

两个队列都为空即为真。



#include &lt;queue&gt;using namespace std;class MyStack &#123;public:    queue&lt;int&gt; q1, q2;  // 两个队列    MyStack() &#123;    &#125;        void push(int x) &#123;        // 1. 新元素先入空的队列 q2        q2.push(x);        // 2. 把 q1 中所有元素依次移到 q2 中        while (!q1.empty()) &#123;            q2.push(q1.front());            q1.pop();        &#125;        // 3. 交换 q1 和 q2，保证所有元素又回到 q1，q2 变空        swap(q1, q2);    &#125;        int pop() &#123;        // 队首就是栈顶        int val = q1.front();        q1.pop();        return val;    &#125;        int top() &#123;        return q1.front();    &#125;        bool empty() &#123;        return q1.empty() &amp;&amp; q2.empty();    &#125;&#125;;
有效的括号
题目链接：20. 有效的括号
题目思路：先判断一下s的长度是否为偶数，如果不是就返回false，再将全部的左符号压入栈中，然后开始判断剩余的符号是否可以匹配，如果不能就返回false，将s循环结束，如果全部匹配成功，最后应该栈是空的，如果不是返回false。
class Solution &#123;public:    bool isValid(string s) &#123;        int n=s.size();        if(n%2!=0) return false;        stack&lt;char&gt; t;        for(int i=0;i&lt;n;i++)        &#123;            if(s[i]==&#x27;(&#x27;) t.push(&#x27;)&#x27;);            else if(s[i]==&#x27;&#123;&#x27;) t.push(&#x27;&#125;&#x27;);            else if(s[i]==&#x27;[&#x27;) t.push(&#x27;]&#x27;);            else if(t.empty() || t.top()!=s[i]) return false;            else t.pop();        &#125;        return t.empty();    &#125;&#125;;
删除字符串中的所有相邻重复项
题目链接：1047. 删除字符串中的所有相邻重复项
建栈的写法，性能太差了。
class Solution &#123;public:    string removeDuplicates(string s) &#123;        stack&lt;char&gt; t;        int n=s.size();        for(int i=0;i&lt;n;i++)        &#123;            if(!t.empty() &amp;&amp; s[i]==t.top()) t.pop();            else t.push(s[i]);         &#125;         string result;        while(!t.empty())        &#123;            result=t.top()+result;            t.pop();        &#125;        return result;    &#125;&#125;;
string自己就可以做栈，string有pop和push接口，性能很高。
class Solution &#123;public:    string removeDuplicates(string s) &#123;        string stk;        for (char ch : s) &#123;            if (!stk.empty() &amp;&amp; stk.back() == ch) &#123;                stk.pop_back();            &#125; else &#123;                stk.push_back(ch);            &#125;        &#125;        return stk;    &#125;&#125;;
逆波兰表达式求值
题目链接：150. 逆波兰表达式求值
题目挺简单的，就是一个点需要注意：
stoi()：

stoi 是一个将 std::string 类型转换为 int 的函数。如果 tokens[i] 是一个有效的整数表示，stoi(tokens[i]) 将返回对应的整数值。

class Solution &#123;public:    int evalRPN(vector&lt;string&gt;&amp; tokens) &#123;        stack&lt;int&gt; t;        int n=tokens.size(),re;        for(int i=0;i&lt;n;i++)        &#123;            if(tokens[i]==&quot;+&quot;)             &#123;                int a=t.top();t.pop();                int b=t.top();t.pop();                re=a+b;                t.push(re);            &#125;            else if(tokens[i]==&quot;-&quot;)            &#123;                int a=t.top();t.pop();                int b=t.top();t.pop();                re=b-a;                t.push(re);            &#125;            else if(tokens[i]==&quot;*&quot;)            &#123;                int a=t.top();t.pop();                int b=t.top();t.pop();                re=b*a;                t.push(re);            &#125;            else if(tokens[i]==&quot;/&quot;)            &#123;                int a=t.top();t.pop();                int b=t.top();t.pop();                re=b/a;                t.push(re);            &#125;            else t.push(stoi(tokens[i]));        &#125;        return t.top();    &#125;&#125;;
滑动窗口最大值
题目链接：239. 滑动窗口最大值
双端队列：队列中元素个数大于k，就删除队首元素，若入队元素大于队列中的元素，则把队列中的元素弹出。
class Solution &#123;public:    vector&lt;int&gt; maxSlidingWindow(vector&lt;int&gt;&amp; nums, int k) &#123;        vector&lt;int&gt; ans;        deque&lt;int&gt; q; // 双端队列        for (int i = 0; i &lt; nums.size(); i++) &#123;            // 1. 入            while (!q.empty() &amp;&amp; nums[q.back()] &lt;= nums[i]) &#123;                q.pop_back(); // 维护 q 的单调性            &#125;            q.push_back(i); // 入队            // 2. 出            if (i - q.front() &gt;= k) &#123; // 队首已经离开窗口了                q.pop_front();            &#125;            // 3. 记录答案            if (i &gt;= k - 1) &#123;                // 由于队首到队尾单调递减，所以窗口最大值就是队首                ans.push_back(nums[q.front()]);            &#125;        &#125;        return ans;    &#125;&#125;;
前 K 个高频元素
题目链接：347. 前 K 个高频元素
堆是一棵完全二叉树，树中每个结点的值都不小于（或不大于）其左右孩子的值。 如果父亲结点是大于等于左右孩子就是大顶堆，小于等于左右孩子就是小顶堆。小顶堆每次将最小的元素弹出，最后小顶堆里积累的才是前k个最大元素。

class Solution &#123;public:    // 小顶堆    class mycomparison &#123;    public:        bool operator()(const pair&lt;int, int&gt;&amp; lhs, const pair&lt;int, int&gt;&amp; rhs) &#123;            return lhs.second &gt; rhs.second;        &#125;    &#125;;    vector&lt;int&gt; topKFrequent(vector&lt;int&gt;&amp; nums, int k) &#123;        // 要统计元素出现频率        unordered_map&lt;int, int&gt; map; // map&lt;nums[i],对应出现的次数&gt;        for (int i = 0; i &lt; nums.size(); i++) &#123;            map[nums[i]]++;        &#125;        // 对频率排序        // 定义一个小顶堆，大小为k        priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, mycomparison&gt; pri_que;        // 用固定大小为k的小顶堆，扫面所有频率的数值        for (unordered_map&lt;int, int&gt;::iterator it = map.begin(); it != map.end(); it++) &#123;            pri_que.push(*it);            if (pri_que.size() &gt; k) &#123; // 如果堆的大小大于了K，则队列弹出，保证堆的大小一直为k                pri_que.pop();            &#125;        &#125;        // 找出前K个高频元素，因为小顶堆先弹出的是最小的，所以倒序来输出到数组        vector&lt;int&gt; result(k);        for (int i = k - 1; i &gt;= 0; i--) &#123;            result[i] = pri_que.top().first;            pri_que.pop();        &#125;        return result;    &#125;&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>栈</tag>
        <tag>队列</tag>
        <tag>双端队列</tag>
        <tag>堆</tag>
        <tag>queue</tag>
        <tag>stack</tag>
        <tag>deque</tag>
      </tags>
  </entry>
  <entry>
    <title>代码随想录--二叉树</title>
    <url>/2025/02/9day/</url>
    <content><![CDATA[二叉树前中后序遍历
二叉树定义
struct TreeNode &#123;    int val;    TreeNode *left;    TreeNode *right;    TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;&#125;;
二叉树的前序遍历
题目链接：144. 二叉树的前序遍历
递归遍历
class Solution &#123;public:    void traversal(TreeNode* cur, vector&lt;int&gt;&amp; vec) &#123;        if (cur == NULL) return;        vec.push_back(cur-&gt;val);    // 中        traversal(cur-&gt;left, vec);  // 左        traversal(cur-&gt;right, vec); // 右    &#125;    vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123;        vector&lt;int&gt; result;        traversal(root, result);        return result;    &#125;&#125;;
迭代遍历

class Solution &#123;public:    vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123;        vector&lt;int&gt; res;        stack&lt;TreeNode*&gt; s;        if(root==NULL) return res;        s.push(root);        while(!s.empty())&#123;            TreeNode* node= s.top();            s.pop();            res.push_back(node-&gt;val);            if(node-&gt;right) s.push(node-&gt;right);            if(node-&gt;left) s.push(node-&gt;left);        &#125;        return res;    &#125;&#125;;
统一迭代法
每次加入一个右中左，接着将中全部输出，最后再按顺序输出栈里的内容，思路很直观，另外两种遍历也是如此。
class Solution &#123;public:    vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123;        vector&lt;int&gt; result;        stack&lt;TreeNode*&gt; st;        if (root != NULL) st.push(root);        while (!st.empty()) &#123;            TreeNode* node = st.top();            if (node != NULL) &#123;                st.pop();                if (node-&gt;right) st.push(node-&gt;right);  // 右                if (node-&gt;left) st.push(node-&gt;left);    // 左                st.push(node);                          // 中                st.push(NULL);            &#125; else &#123;                st.pop();                node = st.top();                st.pop();                result.push_back(node-&gt;val);            &#125;        &#125;        return result;    &#125;&#125;;
二叉树的中序遍历
题目链接：94. 二叉树的中序遍历
递归遍历
class Solution &#123;public:    void traversal(TreeNode* cur, vector&lt;int&gt;&amp; vec) &#123;        if (cur == NULL) return;        traversal(cur-&gt;left, vec);  // 左        vec.push_back(cur-&gt;val);    // 中        traversal(cur-&gt;right, vec); // 右    &#125;    vector&lt;int&gt; preorderTraversal(TreeNode* root) &#123;        vector&lt;int&gt; result;        traversal(root, result);        return result;    &#125;&#125;;
迭代遍历

class Solution &#123;public:    vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123;        vector&lt;int&gt; res;        stack&lt;TreeNode*&gt; s;        TreeNode* cur = root;                while (cur != nullptr || !s.empty()) &#123;            // 将当前节点及其左子树压入栈            while (cur != nullptr) &#123;                s.push(cur);                cur = cur-&gt;left;            &#125;            cur = s.top();            s.pop();            res.push_back(cur-&gt;val);            cur = cur-&gt;right;        &#125;         return res;    &#125;&#125;;
统一迭代法

class Solution &#123;public:    vector&lt;int&gt; inorderTraversal(TreeNode* root) &#123;        vector&lt;int&gt; result;        stack&lt;TreeNode*&gt; st;        if (root != NULL) st.push (root);        while (!st.empty()) &#123;            TreeNode* node = st.top();            if (node != NULL) &#123;                st.pop(); // 将该节点弹出，避免重复操作，下面再将右中左节点添加到栈中                if (node-&gt;right) st.push(node-&gt;right);  // 添加右节点（空节点不入栈）                st.push(node);                          // 添加中节点                st.push(NULL); // 中节点访问过，但是还没有处理，加入空节点做为标记。                if (node-&gt;left) st.push(node-&gt;left);    // 添加左节点（空节点不入栈）            &#125; else &#123; // 只有遇到空节点的时候，才将下一个节点放进结果集                st.pop();           // 将空节点弹出                node = st.top();    // 重新取出栈中元素                st.pop();                result.push_back(node-&gt;val); // 加入到结果集            &#125;        &#125;        return result;    &#125;&#125;;
二叉树的后序遍历
题目链接：145. 二叉树的后序遍历
递归遍历
class Solution &#123;public:    void traversal(TreeNode *root,vector&lt;int&gt;&amp; res)&#123;        if(root==NULL) return;        traversal(root-&gt;left,res);        traversal(root-&gt;right,res);        res.push_back(root-&gt;val);    &#125;    vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123;        vector&lt;int&gt; re;        traversal(root,re);        return re;    &#125;&#125;;
迭代遍历
class Solution &#123;public:    vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123;        vector&lt;int&gt; res;        stack&lt;TreeNode*&gt; s;        if(root==NULL) return res;        s.push(root);        while(!s.empty())&#123;            TreeNode* node=s.top();            s.pop();            res.push_back(node-&gt;val);            if(node-&gt;left) s.push(node-&gt;left);            if(node-&gt;right) s.push(node-&gt;right);        &#125;        reverse(res.begin(),res.end());        return res;    &#125;&#125;;
统一迭代法
class Solution &#123;public:    vector&lt;int&gt; postorderTraversal(TreeNode* root) &#123;        stack&lt;TreeNode*&gt; s;        vector&lt;int&gt; res;        if(root==NULL) return res;        s.push(root);        while(!s.empty())        &#123;            TreeNode* node =s.top();            if(node!=NULL)            &#123;                s.pop();                s.push(node);                s.push(NULL);                if(node-&gt;right) s.push(node-&gt;right);                if(node-&gt;left) s.push(node-&gt;left);            &#125;            else&#123;                s.pop();                node =s.top();                s.pop();                res.push_back(node-&gt;val);            &#125;        &#125;        return res;    &#125;&#125;;
]]></content>
      <categories>
        <category>算法刷题</category>
        <category>代码随想录</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>二叉树</tag>
        <tag>二叉树遍历</tag>
        <tag>递归</tag>
        <tag>迭代</tag>
      </tags>
  </entry>
  <entry>
    <title>BERT详解 - 双向编码器表示模型精读</title>
    <url>/2025/11/BERT/</url>
    <content><![CDATA[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding
引言
BERT (Bidirectional Encoder Representations from Transformers) 是Google在2018年提出的革命性自然语言处理模型，它通过在无标注文本上进行预训练，学习深层的双向语言表示，在下游任务上取得了突破性的成果。
BERT的核心创新在于双向上下文编码，与之前的ELMo（浅层双向）和GPT（单向）不同，BERT使用Transformer编码器同时利用上下文信息，彻底改变了NLP领域的预训练范式。
背景知识
预训练语言模型的发展
在BERT之前，主流的预训练方法存在以下局限性：

单向语言模型（如GPT）：只能从左到右或从右到左进行编码，无法同时利用双向上下文
浅层双向模型（如ELMo）：虽然考虑了双向信息，但只是简单拼接左右向表示，而非深度双向，网络架构比较老，使用的RNN

为什么需要双向编码？
语言的理解往往需要同时考虑前后文信息。例如：

“银行” 这个词在 “我去银行存钱” 和 “河边的银行” 中含义完全不同
只有同时看到前后文，才能准确理解词义

论文核心思想
主要贡献

双向预训练：通过Masked Language Model (MLM) 实现真正的双向编码
统一的预训练框架：一个模型可以适应多种下游任务
迁移学习的成功：证明了大规模预训练+微调的有效性

核心架构
BERT基于Transformer的编码器部分，主要包含：
BERT = Transformer Encoder × N层

BERT-Base: 12层Transformer，768维隐藏层，12个注意力头，110M参数
BERT-Large: 24层Transformer，1024维隐藏层，16个注意力头，340M参数

预训练方法
1. Masked Language Model (MLM)
目标：预测被掩码的词汇
方法：

随机选择15%的token进行掩码
其中：

80%替换为 [MASK]
10%替换为随机token
10%保持不变



为什么不完全用[MASK]？

预训练时用[MASK]，但微调时没有[MASK]，会造成不匹配
通过随机替换，模型学会在缺少明确信号时也能预测

数学表示：
P(w_i | w_&#123;context&#125;) = softmax(W_h_i)
其中，h_i是第i个token的上下文表示
2. Next Sentence Prediction (NSP)
目标：判断两个句子是否是连续的
方法：

输入格式：[CLS] 句子A [SEP] 句子B [SEP]
50%的概率是连续句子（IsNext）
50%的概率是随机句子（NotNext）

为什么需要NSP？

许多下游任务（如问答、自然语言推理）需要理解句子间关系
MLM主要学习词级表示，NSP帮助学习句子级表示

输入表示
BERT的输入由三个embedding相加：
Input = Token Embedding + Segment Embedding + Position Embedding
Token Embedding

使用WordPiece分词
特殊token：

[CLS]：分类任务的表示
[SEP]：句子分隔符
[MASK]：掩码token
[UNK]：未知词



Segment Embedding

区分句子A和句子B
E_A = 0，E_B = 1

Position Embedding

学习的位置编码（而非Transformer的固定位置编码）
最大序列长度：512

模型架构详解
Transformer Encoder层
每个Transformer Encoder包含：


多头自注意力机制 (Multi-Head Self-Attention)
Attention(Q, K, V) = softmax(QK^T / √d_k)VMultiHead = Concat(head_1, ..., head_h)W^O


前馈神经网络 (Feed-Forward Network)
FFN(x) = max(0, xW_1 + b_1)W_2 + b_2


残差连接和层归一化
output = LayerNorm(x + Sublayer(x))


BERT的输出

最后一层的输出：每个token的上下文表示
[CLS] token的输出：用于分类任务的句子级表示

微调策略
下游任务适配
BERT可以通过简单的修改适应各种任务：


单句分类（如情感分析）
[CLS] 句子 [SEP] → 分类层


句子对分类（如自然语言推理）
[CLS] 句子A [SEP] 句子B [SEP] → 分类层


问答任务（如SQuAD）
[CLS] 问题 [SEP] 段落 [SEP] → 起始位置 + 结束位置


序列标注（如命名实体识别）
[CLS] token1 token2 ... [SEP] → 每个token的标签


微调技巧

学习率：预训练的学习率通常较小（如2e-5）
Batch size：16或32通常效果较好
Epochs：2-4个epoch通常足够
学习率调度：线性衰减或warmup

实验结果
GLUE基准测试
BERT在11个NLP任务上取得了state-of-the-art的结果：

MNLI: 84.6% (4.6%提升)
QQP: 71.2% F1 (4.2%提升)
QNLI: 90.5% (5.1%提升)
SST-2: 93.5% (2.0%提升)
CoLA: 52.1% (5.6%提升)

SQuAD v1.1

F1: 93.2%
EM: 87.4%

消融实验

MLM的影响：移除MLM导致显著性能下降
NSP的影响：对某些任务有帮助，但不是必需的
模型大小的影响：更大的模型带来更好的性能
训练步数的影响：更多训练步数持续提升性能

代码实现
使用Hugging Face Transformers
from transformers import BertTokenizer, BertModelimport torch# 加载预训练模型和分词器tokenizer = BertTokenizer.from_pretrained(&#x27;bert-base-uncased&#x27;)model = BertModel.from_pretrained(&#x27;bert-base-uncased&#x27;)# 输入文本text = &quot;Hello, how are you?&quot;inputs = tokenizer(text, return_tensors=&#x27;pt&#x27;)# 获取模型输出with torch.no_grad():    outputs = model(**inputs)# outputs包含：# - last_hidden_state: 最后一层的隐藏状态# - pooler_output: [CLS] token的池化输出print(outputs.last_hidden_state.shape)  # [batch_size, seq_len, hidden_size]print(outputs.pooler_output.shape)      # [batch_size, hidden_size]
文本分类示例
from transformers import BertForSequenceClassificationfrom transformers import Trainer, TrainingArguments# 加载分类模型model = BertForSequenceClassification.from_pretrained(    &#x27;bert-base-uncased&#x27;,    num_labels=2  # 二分类)# 准备数据train_texts = [&quot;I love this movie&quot;, &quot;This movie is terrible&quot;]train_labels = [1, 0]# 训练参数training_args = TrainingArguments(    output_dir=&#x27;./results&#x27;,    num_train_epochs=3,    per_device_train_batch_size=16,    learning_rate=2e-5,)# 训练trainer = Trainer(    model=model,    args=training_args,    train_dataset=train_dataset,)trainer.train()
自定义BERT模型（简化版）
import torchimport torch.nn as nnfrom torch.nn import TransformerEncoder, TransformerEncoderLayerclass SimpleBERT(nn.Module):    def __init__(self, vocab_size, d_model=768, nhead=12, num_layers=12):        super().__init__()        self.embedding = nn.Embedding(vocab_size, d_model)        self.pos_encoding = nn.Parameter(torch.randn(512, d_model))                encoder_layers = TransformerEncoderLayer(            d_model=d_model,            nhead=nhead,            dim_feedforward=3072,            dropout=0.1        )        self.transformer = TransformerEncoder(encoder_layers, num_layers)            def forward(self, x, mask=None):        # x: [batch_size, seq_len]        x = self.embedding(x) + self.pos_encoding[:x.size(1)]        x = x.transpose(0, 1)  # [seq_len, batch_size, d_model]        output = self.transformer(x, src_key_padding_mask=mask)        return output.transpose(0, 1)  # [batch_size, seq_len, d_model]
技术细节与优化
注意力机制计算
def scaled_dot_product_attention(Q, K, V, mask=None):    &quot;&quot;&quot;    Q: [batch_size, num_heads, seq_len, d_k]    K: [batch_size, num_heads, seq_len, d_k]    V: [batch_size, num_heads, seq_len, d_v]    &quot;&quot;&quot;    d_k = Q.size(-1)    scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(d_k)        if mask is not None:        scores = scores.masked_fill(mask == 0, -1e9)        attention_weights = torch.softmax(scores, dim=-1)    output = torch.matmul(attention_weights, V)    return output, attention_weights
预训练损失函数
def compute_bert_loss(mlm_logits, nsp_logits, mlm_labels, nsp_labels, mlm_mask):    # MLM损失    mlm_loss = nn.CrossEntropyLoss(ignore_index=-100)(        mlm_logits.view(-1, mlm_logits.size(-1)),        mlm_labels.view(-1)    )        # NSP损失    nsp_loss = nn.CrossEntropyLoss()(        nsp_logits,        nsp_labels    )        # 总损失    total_loss = mlm_loss + nsp_loss    return total_loss, mlm_loss, nsp_loss
BERT的优缺点
优点

强大的表示能力：双向编码捕获丰富的上下文信息
通用性强：一个模型适应多种任务
迁移学习效果好：预训练+微调范式非常有效
开源可用：提供了多种规模的预训练模型

缺点

计算成本高：参数量大，推理速度慢
最大长度限制：只能处理512个token
预训练任务局限：MLM和NSP可能不是最优的预训练目标
单向生成困难：由于双向特性，不适合生成任务

BERT的后续发展
改进方向


模型压缩：

DistilBERT：知识蒸馏减小模型
ALBERT：参数共享降低参数量



效率提升：

ELECTRA：更高效的预训练任务
RoBERTa：去除NSP，优化训练策略



长文本处理：

Longformer：处理更长序列
BigBird：稀疏注意力机制



多语言扩展：

mBERT：多语言BERT
XLM：跨语言预训练



总结
BERT通过双向Transformer编码器和创新的预训练任务（MLM + NSP），为NLP领域带来了革命性的变化。其核心思想是：

双向编码：同时利用前后文信息
预训练+微调：大规模无监督预训练 + 任务特定微调
统一架构：一个模型适应多种下游任务

BERT的成功证明了大规模预训练语言模型的有效性，为后续的GPT、T5等模型奠定了基础。
参考文献


Devlin, J., Chang, M. W., Lee, K., &amp; Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv preprint arXiv:1810.04805.


Vaswani, A., et al. (2017). Attention is all you need. Advances in neural information processing systems, 30.


Radford, A., et al. (2018). Improving language understanding by generative pre-training.


Howard, J., &amp; Ruder, S. (2018). Universal language model fine-tuning for text classification. arXiv preprint arXiv:1801.06146.


思考题

为什么BERT使用15%的mask比例？这个比例是否可以调整？
BERT的MLM任务中，为什么要用80% [MASK]、10% 随机、10% 不变的方式？
NSP任务对BERT的性能有多大影响？为什么RoBERTa去掉了NSP？
BERT为什么不适合生成任务？如果要用于生成，应该怎么改进？
如何理解BERT的双向编码？它与ELMo的双向有什么本质区别？

思考题答案
1. 为什么BERT使用15%的mask比例？这个比例是否可以调整？
15% mask比例的原因：

平衡学习效率与难度：如果mask比例太低（如5%），模型看到的有效训练信号太少，学习效率低；如果太高（如50%），输入信息损失过多，模型难以学习有效的语言表示。
经验最优值：15%是经过实验验证的平衡点，既能提供足够的训练信号，又不会过度破坏句子的完整性。
计算效率：只预测15%的token，相比预测所有token，计算成本更低。

是否可以调整？
可以调整，但需要权衡：

更低的mask比例（5-10%）：训练更稳定，但可能需要更多训练步数
更高的mask比例（20-30%）：可能学到更强的表示，但训练难度增加，可能影响性能

实验发现：

RoBERTa的实验表明，15%仍然是一个较好的选择
对于特定领域或任务，可能需要微调这个比例

2. BERT的MLM任务中，为什么要用80% [MASK]、10% 随机、10% 不变的方式？
这是BERT设计中的一个关键创新，主要解决预训练与微调的不匹配问题：
问题背景：

预训练时：模型看到大量[MASK] token
微调时：模型看不到[MASK] token，只有真实词汇
如果只使用[MASK]，模型会过度依赖这个特殊token，导致微调时性能下降

三种策略的作用：


80% [MASK]：

主要学习目标：让模型学会从上下文预测被掩盖的词
这是MLM的核心任务



10% 随机替换：

引入噪声：让模型学会在&quot;错误&quot;信息下也能正确预测
提高鲁棒性：模拟真实场景中可能出现的错误或噪声
防止过拟合：避免模型只记住[MASK]的模式



10% 保持不变：

关键设计：让模型在微调时能够利用真实词汇的信息
缓解不匹配：预训练时也看到真实词汇，与微调场景更一致
保持语言理解：确保模型不仅学习预测，还学习理解真实词汇



数学直觉：
如果只使用[MASK]：  P(预测|看到[MASK]) ≠ P(预测|看到真实词)  ❌ 不匹配使用混合策略：  P(预测|看到[MASK]) ≈ P(预测|看到真实词)  ✅ 更匹配
实验验证：

如果100%使用[MASK]，在微调任务上性能会下降约2-3%
混合策略使得预训练和微调更加一致

3. NSP任务对BERT的性能有多大影响？为什么RoBERTa去掉了NSP？
NSP的影响分析：
正面影响：

对需要理解句子关系的任务有帮助：如自然语言推理（MNLI）、问答（QNLI）
帮助模型学习句子级表示，而不仅仅是词级表示

负面影响：

任务过于简单：模型可能只关注句子边界信息，而非深层语义关系
训练信号弱：相比MLM，NSP提供的学习信号较弱
可能引入噪声：随机选择的负样本可能包含一些有用的信息，但被标记为&quot;不相关&quot;

RoBERTa去掉NSP的原因：


实验发现NSP效果有限：

在某些任务上，去掉NSP反而性能更好
NSP带来的提升主要来自更长的训练，而非任务本身



NSP任务设计有问题：

负样本（随机句子对）可能包含有用的信息
模型可能学到&quot;只要不是连续句子就是负样本&quot;的简单模式



MLM已经足够强大：

MLM本身就能学习到句子间的关系
通过跨句子的上下文，模型自然能理解句子关系



简化训练流程：

去掉NSP后，训练更简单，只需要MLM任务
可以专注于优化MLM的训练策略



实验结果：

RoBERTa去掉NSP后，在大多数任务上性能持平或略有提升
证明了NSP并非必需，MLM已经足够学习句子级表示

4. BERT为什么不适合生成任务？如果要用于生成，应该怎么改进？
BERT不适合生成任务的原因：


双向编码的本质：

BERT在编码时同时看到整个序列（包括&quot;未来&quot;的信息）
生成任务需要自回归（从左到右），不能看到未来信息
这违反了生成任务的基本要求



架构限制：

BERT只有编码器，没有解码器
无法进行自回归生成



预训练目标不匹配：

MLM是&quot;填空&quot;任务，不是&quot;续写&quot;任务
模型没有学习到生成下一个token的能力



改进方案：


使用BERT作为编码器 + 独立解码器：
BERT Encoder + Transformer Decoder

编码器：用BERT理解输入
解码器：用Transformer解码器进行自回归生成
应用：机器翻译、摘要生成



单向BERT变体：

训练时使用因果掩码（只能看到左侧信息）
类似GPT，但可以保留BERT的其他优势



序列到序列BERT（BART）：

使用BERT的编码器 + GPT的解码器
预训练任务：文本去噪（删除、打乱、填充等）
既保留BERT的理解能力，又具备生成能力



T5（Text-to-Text Transfer Transformer）：

统一的编码器-解码器架构
所有任务都转换为文本生成任务
更强的生成能力



实际应用：

BART：专门为生成任务设计的BERT变体
T5：统一的文本到文本模型
GPT系列：更适合纯生成任务

5. 如何理解BERT的双向编码？它与ELMo的双向有什么本质区别？
BERT的双向编码：


同时编码：

在单次前向传播中，每个token都能同时看到左侧和右侧的所有信息
通过自注意力机制，所有位置的信息同时参与计算



深度双向：

多层Transformer编码器，每一层都是双向的
信息在多层间双向流动和融合



数学表示：
h_i^l = Transformer_Encoder([h_1^&#123;l-1&#125;, ..., h_n^&#123;l-1&#125;])
其中，h_i^l 同时依赖于所有位置的 h_j^{l-1}


ELMo的双向：


分别编码：

使用两个独立的LSTM：前向LSTM和后向LSTM
前向LSTM：从左到右编码，h_i^forward 只看到左侧信息
后向LSTM：从右到左编码，h_i^backward 只看到右侧信息



浅层拼接：

最终表示 = [h_i^forward; h_i^backward]
只是简单拼接，没有深度融合



数学表示：
h_i^forward = LSTM_forward(x_1, ..., x_i)h_i^backward = LSTM_backward(x_i, ..., x_n)h_i = [h_i^forward; h_i^backward]


本质区别：



特性
ELMo
BERT




编码方式
两个独立的单向编码器
一个双向编码器


信息融合
浅层拼接
深度融合（多层）


同时性
分别处理，后拼接
同时处理所有位置


架构
RNN（LSTM）
Transformer


表示质量
词级表示为主
上下文相关表示


计算效率
顺序计算，较慢
并行计算，较快



关键差异示例：
假设要理解句子 “The bank is closed” 中的 “bank”：


ELMo：

前向LSTM看到 “The bank”，可能理解为&quot;银行&quot;
后向LSTM看到 “bank is closed”，也可能理解为&quot;银行&quot;
拼接后得到表示，但两个方向的信息是独立计算的



BERT：

自注意力机制同时考虑 “The”、“bank”、“is”、“closed”
所有位置的信息在每一层都相互影响
最终表示融合了完整的上下文信息



为什么BERT的双向更好？

信息融合更充分：不是简单拼接，而是深度交互
并行计算：Transformer可以并行处理，效率更高
长距离依赖：自注意力机制能更好地捕捉长距离依赖
表示能力更强：多层双向编码产生更丰富的表示

总结：

ELMo是&quot;伪双向&quot;：两个单向模型的拼接
BERT是&quot;真双向&quot;：真正的双向同时编码和融合

]]></content>
      <categories>
        <category>论文精读</category>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>BERT</tag>
        <tag>Transformer</tag>
        <tag>自然语言处理</tag>
        <tag>论文精读</tag>
      </tags>
  </entry>
  <entry>
    <title>CSRMS</title>
    <url>/2025/04/CSRMS/</url>
    <content><![CDATA[CSRMS
用于视觉表征学习的类级结构化关系建模与平滑 (MM2023)
论文地址：https://ercdm.sdu.edu.cn/__local/7/AC/70/7E4948C4761839F62E3958CE772_043AE854_2B459A.pdf
代码地址：https://github.com/czt117/CSRMS
个人理解这个像是一个知识总结的过程。首先通过特征提取获得特征图，这个过程可以类比我从书本上学习知识的过程，提取出有用的知识，然后通过聚类算法对特征图进行分簇，就相当于把学到的知识进行总结的过程，但是总会有一些比较相近的知识容易被搞混，这个就是类间相似性和类内多样性，再着重对这一块进行处理，使得对知识的掌握更加透彻。
名词解释：
课程构建（Curriculum Construction）：是一种渐进式学习方法，通过根据任务或样本的难度或复杂性来设计学习顺序，让模型从简单的内容逐步过渡到复杂的内容，从而更高效地掌握知识。它通过评估样本难度、调整学习权重并动态控制训练过程，帮助模型更高效地学习，最终提高收敛速度和泛化能力。
实例级别的图像（Instance-level images）：指的是针对单个具体图像样本的研究和处理。每一张图像被视为一个独立的实例，拥有其独特的特征和属性，而不是仅仅代表某个类别或群体的共性。与类别级别（Class-level）的研究不同，实例级别更关注图像的个体差异和细节。
对比学习（Contrastive Learning）：是一种机器学习技术，特别在无监督学习和自监督学习中应用广泛。它的核心思想是通过对比不同样本之间的相似性和差异性，让模型自动学习数据的特征表示
研究目的
缓解类内多样性和类间相似性问题

整体架构
CSRMS 框架的三个核心模块：类级关系建模、类感知图采样 和 关系图引导的表示学习
在离线学习阶段，根据表征视觉分布挖掘类级关系，构建数据集级关系图；在训练阶段，根据类级关系构建多样化类感知采样策略，结合课程构建，获得Batch级别关系子图；在类级关系的引导下，利用特征平滑、类原型对齐和类级约束显式正则化视觉表征，有效缓解视觉表征分布复杂性。

离线学习阶段
类级关系建模
类级关系定义
(a) 类内视觉模式的多样性（Intra-Class Diversity of Visual Patterns）：同一类别的样本分布在不同主导簇，说明类内样本视觉差异大。
$$
R_{ID} = \{ (I_a, I_b) \mid y_a = y_b, P_{C_a} \neq P_{C_b} \}
$$
(b) 视觉模式的类间相似性 （Inter-Class Similarity of Visual Patterns）：不同类别的样本分布在同一主导簇，说明类间样本视觉上相似。
$$
R_{IS} = \{(I_a, I_b) \mid y_a \neq y_b, P_{C_a} = P_{C_b} \}
$$
© 视觉模式的混类簇 (Mix-class Cluster of Visual Patterns)：不同类别的样本分布在同一混类簇，说明聚类结果复杂，缺乏主导类别。
$$
R_{MC} = \{(I_a, I_b) \mid y_a \neq y_b, M_{C_a} = M_{C_b} \}
$$
主导簇（Dominant Clusters）：指聚类中主要由某个类别样本构成的簇，通常通过聚类算法基于特征分布确定。
混类簇（Mix-class Clusters）：指聚类中没有明显主导类别的簇，包含多个类别的样本，增加了建模难度。
ART聚类
自适应聚类算法 ART：能够根据数据分布动态调整簇数量，适合处理视觉特征空间中的复杂分布。对视觉特征进行聚类，得到视觉模式。$ C={c1,…,cJ}$
$$
C = ART(M_v(I))
$$
得到三个级别：类级别、模式级别、实例级别。然后构建关系图 $G_t$ 。这是一个多层图结构，实例级别连接到模式级别（通过聚类），模式级别连接到类级别（通过标签），这种结构有助于捕捉样本间的复杂关系。
训练阶段
类感知图采样
正样本采样
使用主导模式采样器$ S_{dp} $，从类别 $ y_i $ 主导的最大簇 $c_j $ 中选择与 $ I_i $ 距离最大的前 $ n $个正样本。为每个批次样本选择正样本集合 $ \Omega_{posi} $，以解决类内多样性。
选择距离最远的正样本，增加类内样本的多样性，增强表征学习的鲁棒性。
$$
\Omega_{posi} = S_{dp}(I_i, \varphi(I_i, I_{i_j}), n)
$$
负样本采样
视觉相似模式采样器 $ S_{ap} $，从类别 $ y_i $ 主导的最大簇 $c_i $ 中选择与 $ I_i $ 距离最大的前 $m$个正样本。为每个批次样本选择负样本集合$\Omega_{nega} $，以解决类间相似性和混类簇。
选择视觉相似的负样本，增强类间区分度，缓解类间相似性问题。
$$
\Omega_{nega} = S_{ap}(I_i, \varphi(I_i, I_{i_j}), m)
$$
课程学习
基于易难估计，为批次样本分配难度级别。
$$
f(I_i) = \begin{cases}
\Omega_{\text{easy}} &amp; \text{if } \frac{N_k^j}{N_k} &gt; \rho_1 \\
\Omega_{\text{medium}} &amp; \text{if } \frac{N_k^j}{N_k} &lt; \rho_1 \\
\Omega_{\text{hard}} &amp; \text{if } \frac{N_k^h}{N_k} &gt; \rho_1 \text{ and } j \neq h
\end{cases}
$$
调整学习权重
使用“衰减方法”，设置惩罚系数，并通过参数调节。
$$
α_i⋅λ_e+(1−α_i)⋅(α_f⋅λ_m+(1−α_f)⋅λ_h)=1
$$
初期：$\alpha_i $、$ \alpha_f $接近 1，优先学习简单样本。
后期：当损失收敛（例如损失 &lt; 0.01 且连续两轮损失差 &lt; 0.0001）时，逐步减小 $ \alpha_i $、$ \alpha_f $，引入更多困难样本。
构建批次子图
$G_b$ 是 $ G_t $的一个子图，针对每个训练批次（batch）生成，包含批次中的样本及其正负样本对，用于后续表征学习。过采样策略，从 $ G_t $中选择与批次样本相关的子图结构，保留类级别、模式级别和实例级别的关系，同时引入正样本和负样本以增强表征学习。
关系图引导的表示学习
簇感知表征平滑
图形平滑
使用图卷积网络（GCN）$ \mathcal{G}(\cdot) $，基于子图 $ G_b $ 和正样本 $ \Omega_{posi} $，聚合同一类别图像的信息。
$$
F_g=\mathcal{G}(\hat{A},I_i,Ω_{posi})=softmax(\hat{A}⋅ReLU(\hat{A}⋅X⋅W^{(1)})⋅W^{(0)})
$$
簇级特征平滑
将表征 $ F_g $ 与簇原型  $ w_{cu} $ 对齐，其中$w_{cu} $是类别 $ y_i $主导的最大簇 $c_j $的原型。
$$
F_u=α_u⊙F_g+β_u⊙w_{cu}
$$
类级分布正则化
类级表征对齐
表征 $ F_u$ 与类原型 $ p_{cu} $ 对齐，其中 $ p_{cu} $ 是类别 $ y_i $ 在所有主导簇中的表征聚合。
$$
F_a=α_a⊙F_u+β_a⊙p_{cu}
$$
负样本约束
构建负样本损失$\mathcal L_{neg}$，推远不同类别表征：
$$
\mathcal L_{neg} = \sum_{i=1}^{N} -\log \left( \mu_{i} \frac{\theta}{\sum_{q=1}^{m}|M_v(I_i) - M_v(\Omega_{nega}^q)|_2 + \theta} \right)
$$
类间约束
构建类间分散损失$\mathcal L_{inter}$，进一步推远不同类别表征：
$$
\mathcal L_{inter} = \sum_{i,j} { i = j } |0| + { i \ne j } -\log \left( \mu\frac{\theta}{|F_v^i - F_v^j|_2 + \theta} \right)
$$
分类器训练
使用分类器 $ C(\cdot) $预测类别：
$$
F_a →P
$$
使用交叉熵损失 $\mathcal L_{ce}$优化：
$$
\mathcal L_{ce} = \frac{1}{N} \sum_{i} \mathcal L_i = -\frac{1}{N} \sum_{i}\sum_{c=1}^{C} y_{ic} \log(P_{ic})
$$
]]></content>
      <categories>
        <category>论文精读</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>论文精读</tag>
        <tag>视觉表征</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode 两个变量 - 2025.11.13</title>
    <url>/2025/11/LeetCode%E5%88%B7%E9%A2%98%E6%97%A5%E5%BF%97%E6%A8%A1%E6%9D%BF/</url>
    <content><![CDATA[今日概览

日期：&#123;2025-11-13&#125;
题目数量：&#123;共 2 题&#125;
难度分布：简单 2 
主要收获：自己的方法就是屎山，灵神的方法高端又通透
心情/状态：太久没刷了，已经把基本的语法忘记了，以后尝试用python刷题，学习一些比较好用的函数


题目列表与详解
1. Two Sum


题号 / 链接：#1 / 题目链接


难度：简单


题型标签：哈希表，数组


题目描述（简要）：

就是查找一下哪两个数相加等于target，返回下标。



思路分析

两个方法，不同的时间复杂度

方法一：暴力写法。
复杂度

时间：O(*n*2)
空间：O(1)

class Solution:    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:        for i, x in enumerate(nums):              for j in range(i + 1, len(nums)):                  if x + nums[j] == target:                     return [i, j]  
​	这里主要是enumerate( )函数，忘记是干啥用的了，enumerate( ) 是 Python 提供的内置函数，用来在遍历可迭代对象（如列表、元组、字符串等）时，同时获得元素的索引和值。它的常见用法如下：
words = [&quot;apple&quot;, &quot;banana&quot;, &quot;cherry&quot;]for index, item in enumerate(words):    print(index, item)
输出结果：
0 apple1 banana2 cherry
方法二：哈希。
class Solution:    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:        seen = &#123;&#125;        for idx, num in enumerate(nums):            complement = target - num            if complement in seen:                return [seen[complement], idx]            seen[num] = idx        return []
复杂度

时间：O(n)
空间：O(n)

2025.11.17 二刷
出去开会几天，把enumerate函数忘记了
class Solution:    def twoSum(self, nums: List[int], target: int) -&gt; List[int]:        s=&#123;&#125;        for i in range(len(nums)):            if target-nums[i] in s:                return [i,s[target-nums[i]]]            s[nums[i]]=i
反思与总结

可以按照题目要求找符合两数相加的值，也可以换一种思路直接去查找符合要求的值，枚举其中一个变量，把它当成常量看待，从而转化成「一个变量」的问题


2. 好数对的数目

题号 / 链接：#2 / 题目链接
难度：简单
题型标签：哈希表，数组
题目描述（简要）：

就是统计每个数出现了多少次，然后用排列组合算出来相加。



思路分析
我的垃圾写法，后续有可以进行改进，学习的新函数，还是贴了一下。
复杂度
class Solution:    def numIdenticalPairs(self, nums: List[int]) -&gt; int:        n=[0 for i in range(101)]        m=0        for index,num in enumerate(nums):            n[num]+=1        for i in range(101):            t=0            while n[i]&gt;=1:                n[i]=n[i]-1                t=t+n[i]            m+=t        return m
如果换一个数据范围可能就不行了，更通用的写法可以使用 collections.Counter 或 defaultdict(int) 自动统计。还有可以直接使用排列组合公式cnt * (cnt - 1) // 2 就能得到该值的所有好数对数量。
改进方法一：使用 Counter
from typing import Listfrom collections import Counterclass Solution:    def numIdenticalPairs(self, nums: List[int]) -&gt; int:        counter = Counter(nums)        ans = 0        for cnt in counter.values():            ans += cnt * (cnt - 1) // 2        return ans
改进方法二：一边遍历一边累加
from typing import Listfrom collections import defaultdictclass Solution:    def numIdenticalPairs(self, nums: List[int]) -&gt; int:        freq = defaultdict(int)        ans = 0        for num in nums:            ans += freq[num]      # 之前出现了 freq[num] 个 num，与当前 num 都能构成好数对            freq[num] += 1        return ans
复杂度

时间：O(n)
空间：O(n)

反思与总结

我的方法毫无通用性可言

]]></content>
      <categories>
        <category>算法刷题</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>刷题记录</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>MAE详解 - Masked Autoencoders精读</title>
    <url>/2025/11/MAE/</url>
    <content><![CDATA[Masked Autoencoders Are Scalable Vision Learners
引言
MAE (Masked Autoencoders) 由He Kaiming团队在2021年提出，为视觉自监督学习带来了新的范式。论文标题“Masked Autoencoders Are Scalable Vision Learners”凸显了其两大特性：一是基于掩码的自重构任务；二是能在大规模数据和模型上稳定扩展。和SimCLR、MoCo等对比学习方法相比，MAE丢弃了昂贵的负样本构造环节，通过简单的遮挡-重建目标即可学习高质量的视觉特征。
在图像理解任务中，过去的自监督方法往往依赖对比学习或生成式建模。MAE将NLP中成熟的Masked Language Modeling理念迁移到视觉领域，将图片切分为patch token，然后随机遮挡大部分token，让模型仅凭剩余少量可见token推断出被遮挡的像素，从而学到上下文结构。
背景知识
自监督视觉预训练的演进

预文本任务 (Pretext Task)：如旋转预测、拼图恢复等，但任务与下游语义差距较大。
对比学习时代：SimCLR、MoCo、BYOL通过实例判别与数据增强获得强特征，但需要大batch或额外队列。
生成式方法回潮：iGPT、VQ-VAE尝试像素重建，但计算成本高、收敛慢。
Vision Transformer普及：ViT把图像转成patch序列，为视觉领域引入“token”概念，使得掩码预测成为可能。

MAE正是在ViT基础上发展的生成式自监督方法。
自动编码器 vs. 对比学习



特性
自动编码器
对比学习




目标
自重构输入
拉近正样本、推远负样本


数据增强依赖
低
高


训练稳定性
较稳定
依赖大batch/动量队列


计算需求
可低（MAE只编码可见token）
往往高


表征性质
偏向局部+全局
偏向判别特征



MAE融合了自动编码器的补全思想与Transformer的全局建模能力。
论文核心思想
主要贡献

高掩码率：高达75%~90%的随机遮挡仍能有效预训练，极大降低计算量。
轻量解码器：编码器专注表示学习，解码器仅用于预训练阶段重建。
非对称架构：编码器处理少量可见token，解码器负责重建全部token，简化了训练。
可扩展性：在ImageNet上与有监督预训练相当甚至更优，对下游检测、分割任务具备竞争力。

整体流程
输入图像 → Patch划分 → 随机掩码 → 编码器处理可见patch → 嵌入掩码token → 轻量解码器重建像素 → 计算重建损失
模型架构
Patch Embedding 与 ViT兼容性

使用ViT相同的patchify方式：将图像划分为16×16的patch，拼接成序列。
对每个patch做线性投影得到D维token，并加上位置编码。
由于MAE后续要还原像素，额外保存patch形状信息用于unpatchify。

随机掩码策略

均匀随机：从所有patch中随机采样保留25%，掩码75%。
可见token排序：保留patch在顺序上也会随机打乱，增加任务难度。
原因：视觉信息冗余高，遮挡大部分区域仍能推断结构，训练效率也随掩码率提高而提高。

编码器（Encoder）

直接使用标准ViT Backbone（如ViT-B/16）。
输入仅限可见token，大幅减少自注意力计算量。
由于只处理25%的token，训练速度提高约3~4倍。

解码器（Decoder）

结构比编码器浅（如8层Transformer），隐藏维度更小（如512）。
输入由“编码器输出的可见token + 掩码token嵌入”组成。
仅在预训练阶段存在，下游微调时丢弃，避免增加推理成本。

重建目标

对所有patch输出预测像素，常用均方误差(MSE)。
论文采用归一化的pixel值（对每个patch做均值方差归一），提升稳定性。
也可以替换为DCT系数、特征空间等，扩展空间很大。

训练策略
预训练设置



配置
常用取值




数据集
ImageNet-1K无标签


掩码率
75%


Patch size
16


训练时长
400 epoch


优化器
AdamW (lr=1.5e-4, weight decay=0.05)


学习率策略
Cosine + warmup


数据增强
仅RandomResizeCrop + 随机水平翻转



微调策略

使用预训练好的编码器权重初始化ViT Backbone。
替换为任务特定头（分类、检测、分割）。
学习率通常更小（如5e-4），训练epoch也减少（如100 epoch）。
对分类任务，还会加入Mixup、CutMix等常规增强。

Linear Probe &amp; KNN

冻结编码器，仅训练线性分类头，可评估特征线性可分性。
5-NN评估也常用来衡量无监督表示质量。

实验结果
ImageNet分类



模型
预训练方式
Top-1 Acc




ViT-B/16 (监督)
有标签
81.8%


ViT-B/16 (MAE)
400 epoch
83.7%


ViT-L/16 (MAE)
400 epoch
85.9%



MAE在有限标注下游训练（如少量epoch）同样保持优势。
下游任务

目标检测 (COCO)：与有监督预训练持平甚至略优。
语义分割 (ADE20K)：微调后比监督预训练高1~2 mIoU。
鲁棒性：对遮挡和噪声具有更强适应性。

消融实验

掩码率：75%最佳，过低浪费计算，过高训练不稳定。
解码器深度：浅层即可，过深收益有限。
重建目标：直接像素即可，无需复杂loss。
位置编码：无需额外改动，使用ViT默认编码即可。

表征分析

MAE倾向关注全局结构，对局部纹理不过拟合。
可视化显示模型能推断出缺失的主体轮廓，说明捕捉到高层语义。
线性探针结果表明特征具备良好的线性可分性。

代码实现要点
基础组件
import torchimport torch.nn as nnclass PatchEmbed(nn.Module):    def __init__(self, img_size=224, patch_size=16, in_chans=3, embed_dim=768):        super().__init__()        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)    def forward(self, x):        # x: [B, C, H, W]        x = self.proj(x)                               # [B, embed_dim, H/patch, W/patch]        x = x.flatten(2).transpose(1, 2)               # [B, N, embed_dim]        return x
随机掩码函数
def random_masking(x, mask_ratio=0.75):    B, N, _ = x.shape    len_keep = int(N * (1 - mask_ratio))    noise = torch.rand(B, N, device=x.device)    ids_shuffle = torch.argsort(noise, dim=1)    ids_restore = torch.argsort(ids_shuffle, dim=1)    ids_keep = ids_shuffle[:, :len_keep]    x_masked = torch.gather(x, dim=1, index=ids_keep.unsqueeze(-1).repeat(1, 1, x.size(-1)))    return x_masked, ids_restore, ids_keep
训练循环示例
def mae_forward(model, imgs, mask_ratio=0.75):    tokens = model.patch_embed(imgs)    tokens = tokens + model.pos_embed[:, 1:, :]    tokens, ids_restore, _ = random_masking(tokens, mask_ratio)    latent = model.encoder(tokens)    # prepare decoder input    mask_tokens = model.mask_token.repeat(latent.size(0), ids_restore.size(1) - latent.size(1), 1)    latent_full = torch.cat([latent, mask_tokens], dim=1)    latent_full = torch.gather(latent_full, dim=1, index=ids_restore.unsqueeze(-1).repeat(1, 1, latent.size(2)))    rec = model.decoder(latent_full)    target = model.patchify(imgs)    loss = ((rec - target) ** 2).mean()    return loss
PyTorch Lightning/Timm 的现成实现

timm.models.mae 提供官方实现，可直接加载mae_vit_base_patch16等模型。
Hugging Face Transformers也提供Mask2Former等派生实现。

工程实践建议

Mixed Precision：配合高掩码率，训练非常高效。
数据增强：预训练阶段增强较轻，避免破坏像素重建难度；微调阶段再加重。
学习率调试：预训练用较大学习率，微调用较小的学习率。
梯度累计：若显存受限，可结合梯度累计保持批量大小。

与其他方法的比较



模型
训练范式
计算需求
表征特点




MAE
掩码重建
低 (编码少量token)
全局语义强


BEiT
Token重建
中 (需tokenizer)
依赖dVAE词表


SimMIM
像素重建
中等
无解码器分离


MaskFeat
HOG特征重建
中
更注重低级特征



MAE以简单高效著称，成为后续大量工作（如MaskFeat、iBOT）的基础。
优缺点总结
优点

训练高效：编码器只处理可见token，显著降低计算。
鲁棒性强：对遮挡与噪声有更好表现。
迁移能力好：分类、检测、分割任务均有优势。
实现简单：无须复杂的数据增强或对比对。

缺点

重建目标限制：重建像素可能关注低级细节，对高层语义关注不足。
遮挡策略固定：随机掩码未利用场景先验，对结构化遮挡可能欠佳。
不适合生成：目标是补全而非生成高质量图像。
超参数敏感：掩码率、解码器宽度等需要调优。

相关与后续工作

MAE v2：引入多尺度特征、更强的数据增强。
SimMIM / MaskFeat：探索不同重建目标（直接像素、HOG等）。
MaskCLIP：结合跨模态信息，用文本引导掩码学习。
Masked Siamese Networks：将掩码与对比学习结合。
VideoMAE：扩展到视频，随机掩码时空patch。

总结
MAE通过高掩码率的自重构任务，在不依赖负样本对的情况下实现了高质量的视觉自监督学习。其关键在于：

非对称架构：编码器轻量输入，解码器仅用于训练。
高掩码率：降低计算同时保持学习难度。
贴近NLP的设计：借鉴MLM理念，实现跨模态迁移。

MAE证明了生成式自监督在视觉任务中的可行性，为后续的Mask-based预训练方法奠定了基础。
参考文献

He, K., Chen, X., Xie, S., Li, Y., Dollár, P., &amp; Girshick, R. (2021). Masked autoencoders are scalable vision learners. arXiv:2111.06377.
Dosovitskiy, A., et al. (2020). An image is worth 16x16 words: Transformers for image recognition at scale.
Bao, H., Dong, L., &amp; Wei, F. (2021). BEiT: BERT Pre-Training of Image Transformers.
Xie, Z., et al. (2022). SimMIM: A Simple Framework for Masked Image Modeling.

思考题

为什么MAE可以使用75%的高掩码率？是否存在场景需要降低掩码率？
解码器仅用于预训练阶段，是否意味着我们可以用更复杂的解码器来提升效果？
MAE的像素重建目标会不会让模型学到过多低级特征？如果是，该如何改进？
与对比学习相比，MAE缺少显式的判别约束，如何弥补这一点？
如果要把MAE扩展到视频或多模态任务，需要额外注意哪些设计？

思考题答案
1. 为什么MAE可以使用75%的高掩码率？是否需要调整？

图像存在大量冗余，局部区域通常可由上下文推断。
Transformer具备全局建模能力，即便仅看到25%的patch也能捕捉结构。
高掩码率减少计算成本；在纹理细节极其丰富的任务（如医学影像）可以适当调低（如50%）以保证信息量。

2. 解码器能否更复杂？

理论上可以，但实验表明解码器过深收益有限，且增加训练成本。
解码器主要提供学习信号，过强的解码器会掩盖编码器能力。
若要改进，不如让解码器重建更高层次表征（如语义分割mask）。

3. 像素重建是否导致偏向低级细节？

像素Loss会促使模型拟合纹理，但高掩码率迫使模型理解结构。
可通过重建特征空间（如DINO特征）、频域信息或多任务损失提升语义理解。

4. 如何引入判别约束？

在MAE基础上叠加对比学习头（如MAE+MoCo）。
结合监督信号（半监督设置）或知识蒸馏。
在线性探针阶段引入额外的判别任务。

5. 拓展到视频或多模态的注意点

视频：需要处理时序维度，可随机掩码时空patch，并采用时序位置编码。
多模态（图文）：需联合掩码不同模态，并设计跨模态对齐目标，如重建文本描述。
计算资源：视频/多模态数据更大，掩码率、模型尺寸需兼顾效率。

]]></content>
      <categories>
        <category>论文精读</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>论文精读</tag>
        <tag>MAE</tag>
        <tag>自监督学习</tag>
        <tag>Vision Transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>MoE</title>
    <url>/2025/04/MOE/</url>
    <content><![CDATA[Mixtures of Experts
《Adaptive Mixture of Local Experts》

论文链接：https://www.cs.toronto.edu/~hinton/absps/jjnh91.pdf
1991年，由 Hinton和 Jordan提出，这是最早的MoE架构。
核心思想：通过多个独立专家网络处理输入数据不同子集，并由门控网络动态选择专家。每个专家接受相同的输入数据，但通过门控网络的动态分配，专家会专注于处理输入空间的特定区域。
基础架构
如图，一个由专家网络和门控网络组成的系统。每个专家是一个前馈网络，所有专家接收相同的输入，并具有相同数量的输出。门控网络也是一个前馈网络，通常接收与专家网络相同的输入。它的输出是归一化的 $ p_j = \exp(r_j) / \sum_i \exp(r_i) $，其中 $ r_j $是门控网络输出单元 $j$ 接收的总加权输入。选择器（selector）类似于一个多输入单输出的随机开关；开关选择来自专家 $ j $ 的输出的概率为 $p_j$ 。每个专家通常只会被分配到可能输入向量空间的一个小区域内。
系统由多个专家网络和一个门控网络组成。每个专家是一个前馈网络，处理特定子任务；门控网络根据输入决定每个专家的混合比例（概率）。

通过重新定义误差函数，鼓励专家竞争而非协作，确保每个专家专注于特定子任务。传统误差函数（如均方误差）会导致专家协作，增加耦合；论文提出优比损失（基于高斯混合模型的负对数概率），使专家独立学习，减少干扰。改进后的误差函数使门控网络倾向于选择最适合的专家，加快收敛。
性能比较
元音辨别：区分多说话者元音区分（识别元音 [i], [I], [a], [A]）。
数据集：来自 75 个说话者的共振峰数据（Peterson 和 Barney, 1952），前 50 个用于训练，后 25 个用于测试。

模型能自动分解任务，专注于不同类别对（如 [i]/[I] 和 [a]/[A]），仅 2-3 个专家在最终混合中活跃。
混合专家模型达到误差标准明显快于反向传播网络，平均只需要大约一半的周期数。混合模型的学习时间也随着专家数量的增加而很好地扩展。混合专家模型具有较小但统计上显著的平均周期数优势。
总结
这篇论文针对的问题是在不同场合执行不同任务会产生干扰，导致训练速度慢和泛化性能差。MoE 的核心思想是让专家专注于适合的子任务。这意味着某些专家的利用率较低（论文中提到最终只有 2-3 个专家活跃），后续的论文大多都是在解决这个问题。
论文展示了 MoE 模型的任务分解过程：初始阶段，门控网络给所有专家分配相等的混合比例，导致每个专家处理的案例数量大致相等，决策线趋向于处理所有案例的平均最优解。随着训练进行，竞争机制使专家分化，专注于特定子任务，从而形成更符合数据分布的最优决策面。这种机制显著减少了干扰，训练速度比反向传播网络快约 50%，体现了 MoE 架构在训练时间上的优势。
《Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer》
超大型神经网络：稀疏门控混合专家层
论文链接：https://arxiv.org/abs/1701.06538
2017年，合作作者中还有Hinton和 Jordan，在LSTM层之间应用MoE卷积。仅以微小的计算效率损失就取得了超过 1000 倍的模型容量提升，并在公共语言建模和翻译数据集上显著提升了最先进的结果。
上一篇强调的是减小时间成本，这一篇是减小计算成本。

基础架构
稀疏门控专家混合层（MoE）
MoE 由很多专家组成，每个专家相当于一个前馈神经网络。以及一个可训练的门控网络，该网络选择专家的稀疏组合来处理每个输入。网络的所有部分都通过反向传播进行联合训练。

设 $ G(x) $和 $ E_i(x) $ 分别为给定输入 $ x $ 的门控网络输出和第 $ i $ 个专家网络的输出。MoE 模块的输出 $ y $ 可表示为：
$$
y = \sum_{i=1}^{n} G(x)_i E_i(x)
$$

均衡负载
门控网络总是倾向于收敛到一种状态，在这种状态下，它总是对同一批专家产生较大的权重，使得被偏好的专家训练得更快，更容易被门控网络选中。希望在训练和推理过程中，专家的重要性相等，称之为负载平衡 。某种程度上，这是为了防止对同一个专家过度拟合。
Keep Top-K
Noisy Top-K Gating
添加了两个组件：稀疏性和噪音。在应用 Softmax 函数之前，添加可调的高斯噪声，然后仅保留前 $ k $ 个值，将其余值设为 $-\infty$（这会导致对应的门控值为 0）。每部分的噪声量由可训练权重矩阵 $ W_{\text{noise}} $ 控制。通过简单的反向传播训练门控网络。稀疏性用于节省计算，噪声项有助于负载均衡。

Noise
使用Noisy Top-K Gating方法改进MoE层，引入可训练的 Gaussian 噪声防止总是选择相同的专家。

$$
H(x)_i = (x \cdot W_g)_i + \text{StandardNormal}() \cdot \text{Softplus}((x \cdot W_{\text{noise}})_i)
$$
Sparse
除了想要激活的前 k 名专家之外，其他所有专家的权重都将设置为 $-\infty$ 。

$$
\text{KeepTopK}(v, k)_i =
\begin{cases}
v_i & \text{if } v_i \text{ is in the top } k \text{ elements of } v, \\\
-\infty & \text{otherwise}.
\end{cases}
$$
通过将这些权重设置为 $-\infty$ ，SoftMax 在这些权重上的输出将产生概率 0 ：

$$
G(x) = \text{Softmax}(\text{KeepTopK}(H(x), k))
$$
KeepTopK 策略将每个 token 路由给几个选定的专家。

Auxiliary Loss
为了在训练过程中获得更均匀的专家分布，辅助损失（也称为负载平衡损失 ）被添加到网络的常规损失中。它增加了一个约束，迫使专家具有同等重要性。
该辅助损失的第一个组成部分是将整个批次中每个专家的门控值相加。

$$
\text{Importance}(X) = \sum_{x \in X} G(x) 
$$
这为我们提供了每个专家的重要性分数 ，该分数表示无论输入如何，选择特定专家的可能性。可以用它来计算变异系数 （ CV ），它告诉我们专家之间重要性得分的差异有多大。利用这个 CV 分数，我们可以在训练期间更新辅助损失 ，以尽可能降低 CV 分数（ 从而给予每个专家同等的重要性 ）。

如果重要性分数存在很大差异，则 CV 会很高，相反，如果所有专家的重要性得分都相似，那么 CV 就会较低

$$
L_{\text{importance}}(X) = w_{\text{importance}} \cdot CV(\text{Importance}(X))^2
$$
最后，将辅助损失作为单独的损失添加，以便在训练期间进行优化。
虽然这种损失函数可以确保平衡的重要性，但专家仍然可能收到数量非常不同的样本。为了解决这一问题，论文引入了 $ L_{\text{load}} $ 损失，专门用于平衡专家接收的样本数量（即负载均衡），与 $ L_{\text{importance}} $ 损失（平衡门控权重总和）配合使用。
Load-Balancing Loss
专家接收的样本数量是一个离散值，无法用于反向传播。所以这里定义了一个平滑估计器 $Load(X)$，用于估计每个专家在输入批次 $X$ 中分配到的示例数量，通过概率计算来近似样本分配。平滑性使得可以通过估计器反向传播梯度。这是门控函数中噪声项的目的。
对于一个输入批次 $ X $，第 $ i $ 个专家的负载定义为：
$$ 
{Load}(X)_i = \sum_{x \in X} P(x, i)
$$ 
其中 $ P(x, i) $ 是给定输入 $ x $ 时第 $ i $ 个专家被选中的概率，它描述了第 $ i$ 个专家的“带噪声得分”大于某个阈值的概率。论文通过噪声 Top-K 门控的特性计算 $ P(x, i) $：
$$ 
P(x, i) = \Pr\left( (x \cdot W_g)_i + \text{StandardNormal}() \cdot \text{Softplus}((x \cdot W_{\text{noise}})_i) > k{th\_excluding}(H(x), k, i) \right)
$$ 
$ (x \cdot W_g)_i $：

$x $ 是输入向量（例如来自上一层的 LSTM 输出）。
$ W_g $ 是门控网络的可训练权重矩阵。
$ (x \cdot W_g)_i $ 是第 $ i $ 个专家的原始得分（未添加噪声），表示门控网络对第 $ i $ 个专家的“偏好”。

$ StandardNormal()⋅Softplus((x⋅Wnoise)i) $：

$ \text{StandardNormal}() $：表示从均值为 0、标准差为 1 的标准正态分布中采样一个随机数。
$ (x \cdot W_{\text{noise}})_i $：通过另一个可训练权重矩阵$ W_{\text{noise}} $ 计算的噪声控制项。
$ \text{Softplus}((x \cdot W_{\text{noise}})_i) $：这部分计算噪声的标准差。它通过将输入 $x$ 与另一个可训练的权重矩阵 $W_{noise}$ 相乘，然后应用 Softplus 函数 $ \text{Softplus}(z) = \log(1 + e^z) $ 来确保标准差为正值。这个标准差是可调节的，并且依赖于输入 $x$ 。
这部分是加到原始得分上的高斯噪声，表示一个高斯噪声项，均值为 0，方差由 $ \text{Softplus}((x \cdot W_{\text{noise}})_i) $决定。噪声的引入有助于负载均衡，避免门控网络总是选择固定的专家。

$$ 
H(x)_ i = (x \cdot W_g)_i + \text{StandardNormal}() \cdot \text{Softplus}((x \cdot W_{\text{noise}})_i
$$ 
$H(x)_i$代表了第$ i $个专家的最终“带噪声得分”。
$k\text{th_excluding}(H(x), k, i)$: 这是决定专家 i 是否被选中的阈值。它的含义是：在向量 $H(x)$（包含了所有专家的带噪声得分）中，排除掉第 i 个专家自身的分数后，找到剩下 n−1 个分数中第 k 大的分数 。
$Pr(⋯&gt;…): $ 公式计算  $ H(x)_ i $（重新采样噪声后）大于  $k\text{th_excluding}(H(x), k, i)$ 的概率。在噪声 Top-K 门控中，第 $𝑖$ 个专家被选中当且仅当 $ H(x)_ i$ 是 $𝐻 ( 𝑥 )$ 中前 $𝑘$ 大的值。
$$ 
P(x, i) = \Phi\left( \frac{(x \cdot W_g)_i - k{th\_ excluding}(H(x), k, i)}{\text{Softplus}((x \cdot W_{\text{noise}})_i)} \right)
$$ 
Φ 表示标准正态分布的累积分布函数（CDF）。利用正态分布的 CDF 给出了计算这个概率的具体数学表达式，方便进行计算和反向传播（因为 Φ 是可微的）。这整个机制是为了在选择专家时引入随机性（有助于负载均衡 ）并估算每个专家被选中的概率，进而定义$L_{load}$损失。
$$ 
L_{\text{load}}(X) = w_{\text{load}} \cdot CV(\text{Load}(X))^2
$$ 
初始负载不平衡：为了避免内存溢出错误，需要在近似相等的专家负载状态下初始化网络（因为软约束需要一些时间才能发挥作用）。为了实现这一点，将矩阵 $W_g$ 和 $W_{noise}$ 初始化为全零，这样就不会产生信号，而只有一些噪声。
Hierarchical Mixture-of-Experts
层次 MoE 是一种分层结构的 MoE，如果专家数量非常庞大，可以使用两层分层MoE来降低分支因子。在一个分层MoE中，一个主门控网络选择一个稀疏加权组合的“专家”，每个“专家”本身就是一个具有自己门控网络的二级混合专家。
第一级（主门控网络）：主门控网络 $ G_{\text{primary}} $ 负责选择一组“专家组”（groups of experts）。
第二级（次级门控网络）：每个专家组内有一个次级门控网络 $G_i $，负责在该组内选择具体的专家。
专家网络：最终的专家网络 $E_{i,j} $，其中 $ i $ 表示组索引，$j $ 表示组内的专家索引。
$$ 
y_H = \sum_{i=1}^{a} \sum_{j=1}^{b} G_{\text{primary}}(x)_i \cdot G_i(x)_j \cdot E_{i,j}(x)
$$ 
$Gprimary(x)i$：主门控网络对第 $ i $ 个组的权重。
$G_i(x)_j $：第 $ i $ 个组的次级门控网络对组内第 $j $ 个专家的权重。
$ E_{i,j}(x) $：第 $ i $ 个组中第 $j $ 个专家的输出。
对专家利用率的衡量指标将更改为以下内容：
$$ 
\text{Importance}_H(X)_{i,j} = \sum_{x \in X} G_{\text{primary}}(x)_i \cdot G_i(x)_j
$$ 
$$ 
\text{Load}_H(X)_{i,j} = \frac{\text{Load}_{\text{primary}}(X)_i \cdot \text{Load}_i(X^{(i)})_j}{|X^{(i)}|}
$$ 
$Load_{primary}$   和 $Load_i$ 分别表示主门控网络和 $i^{th}$ 次级门控网络的加载函数。 $ X^{(i)}$表示 X 中满足 $ G_{primary}(x)_i &gt; 0 $ 的子集。
《GShard: Scaling Giant Models with Conditional Computation and Automatic Sharding》
基于条件计算和自动分片的巨型模型扩展。
论文链接：https://arxiv.org/abs/2006.16668

创新点
Expert Capacity
专家容量
不平衡不仅存在于所选专家中，还存在于发送给专家的token分配中。如果输入 token 不成比例地发送给一个专家而不是另一个专家，那么也可能导致训练不足。

解决这个问题的一个方法是限制每个专家可以处理的 token 数量，即专家容量 。当专家达到容量上限时，产生的 token 将被发送给下一个专家：

如果两个专家都已达到其容量上限，则 token 将不会被任何专家处理，而是被发送到下一层。这称为 token 溢出 。这些token的表示通过残差连接传递到下一层。

Auxiliary loss
门控函数不应总是选择相同的一小部分专家，因为这会导致一小部分专家容量溢出，而其余专家则被闲置。定义了一个辅助损失项 ℓaux 来强制执行此约束。 它被添加到模型的总损失函数中 L = ℓnll + k ∗ ℓaux，其中 k 是一个常数乘数。
Random routing
随机路由机制
在 top-2 设计中，始终选择表现最优的专家，但第二选择的专家则根据其权重以一定概率被选中。
《Switch Transformers: Scaling to Trillion Parameter Models with Simple and Eﬃcient Sparsity》
论文链接：https://arxiv.org/abs/2101.03961

简化了MoE路由算法，并设计了直观的改进模型，从而降低了通信和计算成本。提出的训练技术减轻了不稳定性，并且证明了可以使用较低精度（bfloat16）格式首次训练大型稀疏模型。将 Switch 层添加到 Transformer 的自注意力层中。
Switch Routing
（1）仅将token路由到单个专家，因此减少了路由器计算。
（2）由于每个token仅被路由到单个专家，因此每个专家的批次大小（专家容量）可以至少减半。
（3）路由实现得到简化，并且通信成本降低。
《DeepSeekMoE: Towards Ultimate Expert Specialization in Mixture-of-Experts Language Models》
现有MoE架构问题
（1）知识混合性：现有的MoE实践通常采用数量有限的专家（例如，8个或16个），因此分配给特定专家的token可能涵盖各种知识。因此，指定的专家将倾向于在其参数中组合截然不同的知识类型，而这些知识很难同时利用。
（2）知识冗余：分配给不同专家的token可能需要共同的知识。因此，多个专家可能会收敛于在其各自的参数中获取共享知识，从而导致专家参数的冗余。
这些问题共同阻碍了现有MoE实践中的专家专业化，使其无法达到MoE模型的理论性能上限。
我个人感觉第一个问题和第一篇论文提出的目的应该是一致的，一个模型在不同场合执行不同任务会产生干扰，然后这里的专家又出现了这个问题，使得专家的专业化程度较低。
解决问题的主要策略
（1）细粒度专家分割：在保持参数数量不变的同时，我们通过分割 FFN 中间隐藏维度将专家分割成更细的粒度。相应地，在保持恒定计算成本的同时，我们也激活更多细粒度的专家，以实现激活专家的更灵活和适应性更强的组合。细粒度的专家分割使得不同的知识能够被更精细地分解，并被更精确地学习到不同的专家中，其中每个专家将保持更高的专业化水平。此外，激活专家组合的灵活性增加也有助于更准确和有针对性的知识获取。
（2）共享专家隔离：我们隔离某些专家作为始终激活的共享专家，旨在捕获和巩固不同上下文中的通用知识。通过将通用知识压缩到这些共享专家中，其他路由专家之间的冗余将被减轻。这可以提高参数效率，并确保每个路由专家通过专注于独特的方面来保持专业性。
DeepSeekMoE 中的这些架构创新为训练参数高效的 MoE 语言模型提供了机会，其中每个专家都高度专业化。

DeepSeekMoE 的示意图。子图 (a) 展示了具有传统 top-2 路由策略的 MoE 层。子图 (b) 说明了细粒度专家分割策略。子图 © 展示了共享专家隔离策略的集成，构成了完整的 DeepSeekMoE 架构。值得注意的是，在这三种架构中，专家参数的数量和计算成本保持不变。

DeepSeekMoE 架构
细粒度专家分割
通过将FFN中间隐藏维度降低到原始大小的𝑚分之一，将每个专家FFN分割成𝑚个更小的专家。由于每个专家变得更小，作为回应，还将激活专家的数量增加到𝑚倍，以保持相同的计算成本。通过细粒度的专家分割，MoE层的输出可以表示为：
$$ 
\mathbf{h}_t^l = \sum_{i=1}^{mN} (g_{i,t} \cdot \text{FFN}_i(\mathbf{u}_t^l)) + \mathbf{u}_t^l
$$ 
$$
g_{i,t} = \begin{cases}
s_{i,t}, &amp; s_{i,t} \in \text{Topk}({s_{j,t}} \mid 1 \leq j \leq mN), mK), \
0, &amp; \text{otherwise}
\end{cases}
$$
$$
s_{i,t} = \text{Softmax}_i(\mathbf{u}_t^{l^T} \mathbf{e}_i^l)
$$
其中，专家参数的总数等于 𝑁 乘以标准 FFN 中的参数数量，mN 表示细粒度专家的总数。采用细粒度专家分割策略后，非零门控的数量也将增加到 mK。
组合灵活性的激增增强了实现更准确和更有针对性的知识获取的潜力。
共享专家隔离
采用传统的路由策略，分配给不同专家的令牌可能需要一些共同的知识或信息。因此，多个专家可能会趋同于在其各自的参数中获取共享知识，从而导致专家参数的冗余。然而，如果存在专门用于捕获和整合不同上下文中的共同知识的共享专家，则可以减轻其他路由专家之间的参数冗余。这种冗余的减轻将有助于构建一个参数效率更高、专家更专业的模型。
隔离𝐾𝑠个专家作为共享专家。无论路由器模块如何，每个token都将被确定性地分配给这些共享专家。为了保持恒定的计算成本，其他路由专家中激活的专家数量将减少𝐾𝑠。通过集成共享专家隔离策略，完整DeepSeekMoE架构中的MoE层可以表述如下：
$$ 
\mathbf{h}_t^l = \sum_{i=1}^{K_s} \text{FFN}_i(\mathbf{u}_t^l) + \sum_{i=K_s+1}^{mN} (g_{i,t} \cdot \text{FFN}_i(\mathbf{u}_t^l)) + \mathbf{u}_t^l
$$ 
$$
g_{i,t} = \begin{cases}
s_{i,t}, &amp; s_{i,t} \in \text{Topk}({s_{j,t} \mid K_s + 1 \leq j \leq mN }), mK - K_s), \
0, &amp; \text{otherwise}
\end{cases}
$$
$$
s_{i,t} = \text{Softmax}_i(\mathbf{u}_t^{l^T} \mathbf{e}_i)
$$
最后，在 DeepSeekMoE 中，共享专家的数量为 𝐾𝑠，路由专家的总数为 𝑚𝑁 − 𝐾𝑠，非零门的数量为 𝑚𝐾 − 𝐾𝑠。
负载均衡问题
自动学习的路由策略可能会遇到负载不均衡的问题，这表现出两个显著的缺陷。首先，存在路由崩溃的风险，即模型总是只选择少数几个专家，导致其他专家无法得到充分的训练。其次，如果专家分布在多个设备上，负载不均衡会加剧计算瓶颈。
Expert-Level Balance Loss
专家级平衡损失。为了降低路由崩溃的风险，平衡损失的计算如下：
$$ 
\mathcal{L}_{\text{ExpBal}} = \alpha_1 \sum_{i=1}^{N'} f_i p_i
$$ 
$$
f_i = \frac{N’}{K’ T} \sum_{t=1}^{T} \mathbb{1}(\text{Token } t \text{ selects Expert } i)
$$
$$
p_i = \frac{1}{T} \sum_{t=1}^{T} s_{i,t}
$$
其中𝛼1是一个被称为专家级别平衡因子的超参数，为了简洁起见，𝑁′等于(𝑚𝑁 − 𝐾𝑠)，𝐾′等于(𝑚𝐾 − 𝐾𝑠)。1(·)表示指示函数。
Device-Level Balance Loss
将所有路由的专家划分为 𝐷 组 {E1, E2, . . ., E𝐷}，并将每组部署在单个设备上，则设备级别平衡损失的计算方式如下：
$$ 
\mathcal{L}_{\text{DevBal}} = \alpha_2 \sum_{i=1}^{D} f'_i p'_i
$$ 
$$ 
f'_i = \frac{1}{|\mathcal{E}_i|} \sum_{j \in \mathcal{E}_i} f_j
$$ 
$$ 
p'_i = \sum_{j \in \mathcal{E}_i} p_j
$$ 
其中𝛼2是一个被称为设备级别平衡因子的超参数。设置一个较小的专家级别平衡因子以降低路由崩溃的风险，同时设置一个较大的设备级别平衡因子以促进设备间的均衡计算。
]]></content>
      <categories>
        <category>论文精读</category>
        <category>大模型</category>
      </categories>
      <tags>
        <tag>论文精读</tag>
        <tag>混合专家系统</tag>
      </tags>
  </entry>
  <entry>
    <title>Mamba详解 - 选择性状态空间模型精读</title>
    <url>/2025/11/Mamba/</url>
    <content><![CDATA[Mamba: Linear-Time Sequence Modeling with Selective SSMs
论文地址：https://arxiv.org/pdf/2312.00752
代码地址：https://github.com/state-spaces/mamba
引言
Mamba 是一种基于状态空间模型（State Space Model, SSM）的高效序列建模框架，旨在在保持强表达能力的同时，将计算与内存复杂度降至与序列长度线性相关。与Transformer的二次复杂度相比，Mamba在超长序列、低时延和内存受限场景中具有显著优势。
Mamba的核心在于“选择性扫描（Selective Scan）”与“输入依赖的状态转移”，通过对经典S4（Structured State Space Sequence Model）的工程化与理论改进，实现端到端可训练、GPU友好、且具有SOTA性能的线性时间序列模型。
背景知识：状态空间模型（SSM）与S4
连续与离散SSM
连续时间SSM：
$$
\dot x(t) = A x(t) + B u(t), \quad y(t) = C x(t) + D u(t)
$$
离散化后：
$$
x_{k+1} = \bar A x_k + \bar B u_k, \quad y_k = C x_k + D u_k
$$
其中 $x$ 为隐状态，$u$ 为输入，$y$ 为输出。
S4的关键思想

通过特定结构（HiPPO 等）构造稳定的 $A$ 矩阵，捕捉长程依赖；
使用高效卷积实现序列到序列的映射（状态演化可转换为一维卷积核）；
优点：理论稳定、长依赖强；
局限：实现复杂、某些硬件/场景下吞吐有限，且与输入的自适应性不足。

Mamba的核心创新


选择性扫描（Selective Scan）：

令状态转移与输入耦合，通过门控/选择性机制动态调节信息流；
避免固定核卷积的刚性，增强对非稳态、稀疏事件的响应能力。



输入条件化的SSM参数化：

将 $B, C$ 等参数设为输入依赖（conditioning on input），提升表达力；
结合高效实现，使其仍保持线性复杂度。



GPU友好的实现与块并行：

通过分块扫描（block scan）与前缀-后缀合并，实现可并行化的线性时间推理；
内存访问模式优化，显著提升吞吐。



端到端可训练的稳定性：

对状态矩阵参数施加稳定性约束（如谱半径控制、隐式参数化），保证数值稳定。



模型架构
典型的 Mamba Block 包含：

输入投影与门控（选择性）
选择性SSM扫描（线性复杂度）
前馈网络（MLP/GEGLU）
残差连接与归一化

流程示意：
X → InputProj → Selective SSM (scan) → OutputProj → MLP → Residual/Norm
相较Transformer：不使用全局自注意力，而以“可学习的一维核 + 选择性门控”的形式进行token混合；相较S4：对输入进行条件化，提升适配性与表达力。
选择性扫描（Selective Scan）要点

将序列划分为若干块（blocks），每块内部执行线性递推扫描；
记录块末端的状态作为“前缀状态”，在合并阶段向后续块传递；
通过选择性/门控，抑制无用状态更新，突出关键位置的信息流；
与并行卷积不同，选择性扫描可随输入动态调整有效感受野。

复杂度与性能

时间复杂度：$O(N)$ 随序列长度线性；
空间复杂度：$O(N)$（可通过流水线/检查点进一步降内存峰值）；
对超长序列（&gt;4K、&gt;16K tokens）训练与推理更加高效；
在语言建模、语音、时间序列等任务上与或优于同级别Transformer。

训练与实践

优化器：AdamW；学习率余弦退火；warmup数千步；
正则：Dropout/Stochastic Depth 按深度线性增长；
初始化：对状态矩阵采用稳定化参数化（如对角+低秩）；
长序列技巧：梯度检查点、混合精度、分块扫描大小调优。

与Transformer/Conv的比较



方向
Transformer
ConvNet
Mamba（SSM）




复杂度
O(N^2)
O(N)
O(N)


长距离依赖
强（显式全连接）
弱-中
强（稳定递推核）


并行性
训练强/推理弱（自回归）
强
强（块并行扫描）


归纳偏置
弱
强（局部）
中（递推+选择性）


适用场景
通用
局部模式
超长序列/低时延



代码片段（概念化示例）
import torchimport torch.nn as nnclass SelectiveSSM(nn.Module):    def __init__(self, d_model, state_size):        super().__init__()        self.d_model = d_model        self.state_size = state_size        # 输入依赖的门控/参数化（示意）        self.in_proj = nn.Linear(d_model, 3 * state_size)        self.out_proj = nn.Linear(state_size, d_model)    def forward(self, x):        # x: [B, N, D]        B, N, D = x.shape        a, b, g = self.in_proj(x).chunk(3, dim=-1)  # 输入条件化参数（示意）        state = torch.zeros(B, self.state_size, device=x.device)        outputs = []        for t in range(N):  # 实际实现会使用块并行，这里仅示意            state = torch.tanh(a[:, t, :] * state + b[:, t, :])            state = g[:, t, :].sigmoid() * state  # 选择性门控            outputs.append(state)        y = torch.stack(outputs, dim=1)  # [B, N, S]        return self.out_proj(y)class MambaBlock(nn.Module):    def __init__(self, d_model, state_size, mlp_ratio=4.0, p=0.1):        super().__init__()        self.norm1 = nn.LayerNorm(d_model)        self.ssm = SelectiveSSM(d_model, state_size)        self.drop1 = nn.Dropout(p)        self.norm2 = nn.LayerNorm(d_model)        hidden = int(d_model * mlp_ratio)        self.mlp = nn.Sequential(            nn.Linear(d_model, hidden), nn.GELU(), nn.Dropout(p),            nn.Linear(hidden, d_model), nn.Dropout(p)        )    def forward(self, x):        x = x + self.drop1(self.ssm(self.norm1(x)))        x = x + self.mlp(self.norm2(x))        return x

注：上例为思想演示，真实Mamba使用更优化的扫描与参数化，且为高效CUDA/Flash实现；请参考官方实现。

实验要点与经验

序列长度：尽量使用长序列预训练以发挥线性复杂度优势；
批量与块大小：根据显存调优块扫描长度，保持吞吐与稳定；
任务迁移：语言→语音/时间序列时，适当调整状态规模与门控强度；
可解释性：通过可视化门控开启位置与核响应，分析模型关注点。

优缺点
优点

线性复杂度，适合超长序列与端侧低时延应用；
选择性门控使得对稀疏/非稳态事件更敏感；
GPU友好实现，训练/推理吞吐高；
理论上可与注意力/卷积并行或互补，形成混合结构。

缺点

对全局两两交互的显式建模不如注意力直观；
超参数（状态规模、门控强度、离散化方式）对稳定性敏感；
在某些视觉任务（如密集预测）上需额外结构适配（见MambaOut）。

相关与后续工作

S4/S5：结构化SSM与其后续改进；
MambaOut：面向视觉分类的实用化改造；
Hyena/RetNet/WSI：其他线性/次线性序列混合范式；
混合架构：SSM + Attention/Conv的多路并行。

参考文献


Gu, A., &amp; Dao, T. (2023). Mamba: Linear-Time Sequence Modeling with Selective State Spaces. arXiv preprint arXiv:2312.00752. https://arxiv.org/pdf/2312.00752


Gu, A., Goel, K., &amp; Ré, C. (2022). Efficiently Modeling Long Sequences with Structured State Spaces. ICML 2022.


Sun, Y., et al. (2023). RetNet: Retentive Network: A Successor to Transformer for Large Language Models. NeurIPS 2023.


Poli, M., et al. (2023). Hyena Hierarchy: Towards Larger Convolutional Language Models. ICML 2023.


思考题

为什么选择性扫描能在保持线性复杂度的同时提升表达力？
如何在保持稳定性的同时引入更强的输入条件化（例如多尺度门控）？
在语言建模中，Mamba与Transformer是否适合分工合作？如何设计混合路由？
针对超长上下文（&gt;64K tokens），Mamba的块并行与跨块信息传递应如何权衡？

思考题答案

选择性扫描通过输入依赖的门控让状态更新“稀疏化/聚焦化”，避免固定核对非稳态信号的欠拟合，同时保持线性递推形式；因此表达力↑、复杂度仍为O(N)。
采用分层门控（通道/时间/块级多粒度）、稳定化参数化（对角+低秩）、以及正则（门控L1/温度限制）可提升条件化同时维持稳定；
可用“前段SSM提取远距记忆 + 中段注意力做细粒度交互”的混合体，或MoE式路由将易于局部建模的片段交给Conv/SSM，需在延迟与精度之间折中；
提高块大小、增加跨块汇总通道（summary tokens）、或在块边界引入轻量全局模块（如稀疏注意力）以减小信息切换损失；同时用检查点与流水线降低内存峰值。

]]></content>
      <categories>
        <category>论文精读</category>
        <category>序列建模</category>
      </categories>
      <tags>
        <tag>论文精读</tag>
        <tag>Mamba</tag>
        <tag>SSM</tag>
        <tag>序列建模</tag>
      </tags>
  </entry>
  <entry>
    <title>MambaOut</title>
    <url>/2025/09/MambaOut/</url>
    <content><![CDATA[MambaOut
MambaOut: Do We Really Need Mamba for Vision?  (CVPR 2025)
论文地址：https://arxiv.org/pdf/2405.07992
代码地址：https://github.com/yuweihao/MambaOut
概述
Mamba最初为解决注意力的二次复杂度提出（线性时空复杂度、长序列友好），但在视觉分类等任务上往往不如卷积或Transformer稳定。MambaOut系统性分析了&quot;何时以及为何Mamba在视觉上不占优&quot;，并提出一种在视觉分类上更实用的简化设计：保留有益的序列建模特性，同时移除对视觉任务不友好的模块（如SSM核心token混合器），通过堆叠精简的Mamba块，获得在ImageNet上的强竞争力。
研究动机深度分析
Mamba在NLP中的成功要素：

因果自回归特性：文本生成天然需要单向建模
超长序列处理：文档级任务需要处理数万token
时序依赖建模：语言具有明确的前后文关系
状态演化机制：SSM能有效编码历史信息

为什么这些优势在视觉中不明显？

双向语义理解：图像理解需要全局信息，不适合单向扫描
序列长度有限：即使是高分辨率图像，patch数量通常在千级别
空间结构敏感：图像的2D空间结构被强制展平会损失信息
局部性优先：视觉特征的局部性比全局依赖更重要

核心洞察
本文的核心洞察在于：视觉任务的成功不需要复杂的序列建模机制。通过系统的消融实验，作者发现：

移除SSM后，模型性能不降反升
简单的token混合（如深度可分离卷积）效果更好
训练稳定性显著改善，不再需要复杂的初始化策略

主要结论与贡献

视觉分类不具备&quot;长序列+自回归&quot;的天然优势场景，原生Mamba的强项难以发挥。
去除SSM等不利于图像表征的混合器，保留高效的序列建模后，分类性能显著提升。
提出MambaOut：在相似FLOPs下，ImageNet上优于现有视觉Mamba变体；训练更稳定、收敛更容易。

关键发现与洞察
1. SSM在视觉中的问题
通过系统的消融实验，论文发现了几个关键问题：

单向扫描不适合2D图像：图像的空间关系是双向的，不像文本的因果关系
状态演化增加复杂性：SSM的状态更新机制在视觉任务中带来额外计算负担，收益有限
选择性机制效果有限：Mamba的选择性扫描在图像patch序列上没有明显优势

2. 简化带来的改进
移除SSM组件后的改进：

训练更稳定：梯度流更简单，不再有复杂的状态更新
收敛更快：150 epochs vs 200 epochs达到相同性能
性能更好：在ImageNet上提升1-2%准确率

3. 关键设计选择
MambaOut保留的关键组件：

Gated MLP：提供必要的非线性变换
层归一化：稳定训练过程
残差连接：保证梯度流通
简单的token混合：使用深度可分离卷积替代SSM

实验设计的巧妙之处
渐进式消融策略：

首先移除选择性扫描 → 性能略有提升
然后移除状态空间模型 → 性能继续提升
最后用简单混合器替代 → 达到最佳性能

这种渐进式方法清晰地展示了每个组件的贡献（或负贡献）。
公平比较的设置：

保持参数量相近（误差&lt;5%）
保持FLOPs相近（误差&lt;10%）
使用相同的训练配置（optimizer、schedule、augmentation）

这确保了性能提升来自架构改进，而非其他因素。
方法与架构
基本思想

图像分类核心在于“空间结构与语义的高效建模”，无需严格自回归；
简化Mamba的状态空间混合，将其作为高效token混合器使用；
通过多层堆叠，利用线性复杂度优势扩展模型深度与序列长度。

模块结构（示意）

Patch Embedding：将图像划分为patch并投影为token序列；
MambaOut Block：

轻量token混合（保留线性高效特性）
前馈网络（FFN）
残差连接与归一化


分类头：全局池化/CLS + 线性分类器

相较ViT，MambaOut在token交互上更偏线性序列建模，复杂度更低；相较原生Mamba，MambaOut去掉不利视觉任务的SSM，强调稳定性与判别性。
与相关方法对比

ViT（注意力）

优点：全局建模强、表现稳定
缺点：注意力复杂度二次、长序列成本高


原生Mamba（SSM）

优点：线性复杂度，长序列/自回归强
缺点：在图像分类上表现不稳定/欠鲁棒


MambaOut（本文）

优点：保留线性高效的优点，去除不利视觉模块，分类更强
缺点：对密集预测（检测/分割）的泛化仍需更多验证



实验结果
ImageNet-1K分类性能
主要结果对比（ImageNet-1K validation set）：



Model
Params
FLOPs
Top-1 Acc




DeiT-S
22M
4.6G
79.8%


Swin-T
29M
4.5G
81.3%


Vim-S
26M
5.1G
80.5%


VMamba-S
26M
5.1G
81.5%


MambaOut-S
24M
4.5G
82.0%


DeiT-B
86M
17.5G
81.8%


Swin-B
88M
15.4G
83.3%


Vim-B
98M
18.2G
81.8%


VMamba-B
89M
18.0G
82.8%


MambaOut-B
85M
15.8G
83.6%



关键发现：

性能优势：MambaOut在各个模型规模上均超越视觉Mamba变体
计算效率：在相似或更少的FLOPs下实现更高精度
参数效率：参数量略少但性能更优

训练稳定性分析
收敛速度对比：

MambaOut-S：150 epochs即可达到80%准确率
Vim-S：需要200 epochs才能达到相同性能
训练损失下降更平滑，无明显震荡

超参数鲁棒性：

学习率范围：MambaOut在1e-4到5e-3范围内都能稳定训练
Warmup需求：仅需5 epochs warmup（vs. Vim需要20 epochs）
数据增强：对各种增强策略（RandAugment、Mixup、CutMix）响应良好

消融实验详细分析
SSM组件消融：



Component
Top-1 Acc
Training Time




Full Mamba
79.8%
1.0x


w/o selective scan
80.5%
0.85x


w/o state space
81.2%
0.75x


MambaOut (all removed)
82.0%
0.70x



Token混合器对比：



Mixer Type
Top-1 Acc
FLOPs




SSM
79.8%
4.8G


Self-Attention
81.0%
5.2G


Depthwise Conv
81.5%
4.3G


Gated Conv
82.0%
4.5G



消融与分析

去除SSM的影响：显著提升稳定性与最终精度；
深度/宽度扩展：线性复杂度便于堆叠更多层，收益更稳定；
数据增强/正则：与ViT常规配置兼容（Mixup/CutMix/Label Smoothing等）。

工程实践建议

预处理：标准的ImageNet增强流程足够（RandAug/RandomResizedCrop/HFlip）。
优化器：AdamW + Cosine LR + Warmup；
批大小：和ViT训练设置一致即可，梯度累积可平衡显存；
初始化：可复用ViT/Conv stem进行更稳定的早期训练。

代码片段（概念化示例）
import torchimport torch.nn as nnclass MambaOutBlock(nn.Module):    def __init__(self, dim, mlp_ratio=4.0, p=0.0):        super().__init__()        self.norm1 = nn.LayerNorm(dim)        # 轻量token混合：可替换为线性时序混合或深度可分离卷积等高效混合器        self.token_mixer = nn.Sequential(            nn.Conv1d(dim, dim, kernel_size=3, padding=1, groups=dim),            nn.Conv1d(dim, dim, kernel_size=1)        )        self.drop1 = nn.Dropout(p)        self.norm2 = nn.LayerNorm(dim)        hidden = int(dim * mlp_ratio)        self.mlp = nn.Sequential(            nn.Linear(dim, hidden), nn.GELU(), nn.Dropout(p),            nn.Linear(hidden, dim), nn.Dropout(p)        )    def forward(self, x):        # x: [B, N, C]        y = self.norm1(x)        y = y.transpose(1, 2)              # [B, C, N]        y = self.token_mixer(y).transpose(1, 2)        x = x + self.drop1(y)        x = x + self.mlp(self.norm2(x))        return x

注：上面用深度可分离卷积近似“线性复杂度的token混合”思想，便于理解；实际论文实现请以官方代码为准。

优缺点
优点

训练与收敛更稳定，相比视觉Mamba变体更易用；
线性复杂度便于扩展深度与序列长度；
与ViT训练技巧兼容，工程门槛低。

缺点

对检测、分割等密集预测任务的系统性评估仍有限；
理论解释仍在发展中，对何种视觉任务最适合有待进一步量化。

总结
MambaOut的核心在于：针对视觉分类的需求，对Mamba做“有保留的简化”。它保留线性复杂度与高效序列建模优势，去除对视觉不友好的SSM，最终在ImageNet上超过其他视觉Mamba模型，并接近/超越同级ViT。对希望探索Transformer之外高效结构的研究者与工程师而言，MambaOut提供了一条可行、稳健的路线。
参考

MambaOut: Do We Really Need Mamba for Vision? (CVPR 2025)
Mamba: Linear-Time Sequence Modeling with Selective SSMs (2023)
ViT: An Image is Worth 16x16 Words (ICLR 2021)

思考题

为什么移除SSM会提升分类稳定性？是否可以保留部分SSM结构以兼顾泛化？
线性复杂度混合在极高分辨率或长序列输入下的收益与瓶颈是什么？
在检测/分割等任务上，MambaOut需要哪些针对性的修改？
与ViT的多头注意力相比，MambaOut的token混合在哪些场景更具优势？

思考题答案
1. 为什么移除SSM会提升分类稳定性？是否可以保留部分SSM结构以兼顾泛化？

分类不需要严格自回归，SSM的选择性状态更新在图像场景中可能引入不必要的时序归纳偏置，导致优化目标与任务不匹配；
移除后，token混合更“判别化”且梯度传播路径更稳定；
可尝试“部分保留”：仅在深层或低分辨率阶段加入简化SSM，或以门控/残差旁路的形式弱耦合，避免主干表征被SSM主导。

2. 线性复杂度混合在极高分辨率或长序列输入下的收益与瓶颈是什么？

收益：复杂度O(N)便于扩展到超长序列/高分辨率，显存和速度更友好；
瓶颈：缺乏显式全局交互的建模能力，远程依赖捕获可能弱于注意力；
实践：可叠加稀疏/分层全局模块（如跨块聚合、低频通道注意力）补足长距关系。

3. 在检测/分割等任务上，MambaOut需要哪些针对性的修改？

多尺度特征：引入FPN/HRNet式多尺度分支，适配密集预测；
局部-全局结合：在高分辨率阶段加入局部卷积/窗口注意力以提升细节；
解码头适配：与常见检测/分割头（Mask R-CNN、UPerNet、Deeplab）对齐接口与特征尺度；
训练策略：更强的数据增强（大尺度抖动、copy-paste）与正负样本平衡。

4. 与ViT的多头注意力相比，MambaOut的token混合在哪些场景更具优势？

超长序列与资源受限训练：线性复杂度在显存与时间上更占优；
分类/检索等判别任务：无需强全局两两交互即可取得良好表现；
端侧/实时场景：更低的计算开销带来更稳定的延迟与能耗。

]]></content>
      <categories>
        <category>论文精读</category>
        <category>序列建模</category>
      </categories>
      <tags>
        <tag>论文精读</tag>
        <tag>Mamba</tag>
      </tags>
  </entry>
  <entry>
    <title>MoCo</title>
    <url>/2025/04/MoCo/</url>
    <content><![CDATA[MoCo
Momentum Contrast for Unsupervised Visual Representation Learning  (cvpr2020)
论文地址：https://arxiv.org/pdf/1911.05722
代码地址：https://github.com/facebookresearch/moco
概述

MoCo 将对比学习看作是一个字典查找任务 ：一个编码后的查询（query）应该与其匹配的键（正样本）相似，而与其他所有的键（负样本）不相似 。
对比学习的核心思想是训练一个编码器，使其能够区分相似（正样本）和不相似（负样本）的样本 。
传统方法 VS MoCo

端到端（End-to-end）方法（SimCLR，Inva Spread）：将当前 mini-batch 内的样本作为字典 。这种方法的优点是字典中的键编码是一致的（由同一个编码器生成），但缺点是字典的大小受限于 mini-batch 的大小，而 mini-batch 大小又受限于 GPU 内存 。过大的 mini-batch 也会带来优化难题 。
Memory Bank 方法（Inst Disc）：Memory Bank包含数据集所有数据的特征表示，从Memory Bank中采样数据不需要进行反向传播，所以能支持比较大的字典，然而一个样本的特征表示只在它出现时才在Memory Bank更新，所以一个epoch只会更新一次，但模型在训练过程中不断迭代，这个特征就会“过时”，因此具有更少的一致性，而且它的更新只是进行特征表示的更新，不涉及encoder。
MoCo跟Inst Disc是非常相似的，比如它用队列取代了原来的memory bank作为一个额外的数据结构去存储负样本，用动量编码器去取代了原来loss里的约束项，这样就可以动量的更新编码器，而不是动量的去更新特征，从而能得到更好的结果。其整体的出发点以及一些实现的细节（比如backbone和lr、batch_size，dim、τ等等超参数都是一样的）和Inst Disc都是非常类似的，所以可以说MoCo是Inst Disc的改进工作。
创新点
MoCo 通过两个创新点解决了这一问题：基于队列的动态字典和动量编码器，给无监督的对比学习构造了一个又大又一致的字典。
基于队列的动态字典
MoCo 使用一个队列来存储图像表征（称为键），作为动态字典。通过这种“先进先出”的更新方式，队列始终保持固定的大小，并且包含的是相对较新的样本表示，有助于维持字典的一致性。队列可以容纳 65,536 个键，为对比学习提供了丰富的负样本集合。
f_k.params = f_q.params # 初始化for x in loader: # 输入一个图像序列x，包含N张图，没有标签    x_q = aug(x) # 用于查询的图（数据增强得到）    x_k = aug(x) # 模板图（数据增强得到），自监督就体现在这里，只有图x和x的数据增强才被归为一类    q = f_q.forward(x_q) # 提取查询特征，输出NxC    k = f_k.forward(x_k) # 提取模板特征，输出NxC    # 不使用梯度更新f_k的参数，这是因为文章假设用于提取模板的表示应该是稳定的，不应立即更新    k = k.detach()     # 这里bmm是分批矩阵乘法    l_pos = bmm(q.view(N,1,C), k.view(N,C,1)) # 输出Nx1，也就是自己与自己的增强图的特征的匹配度    l_neg = mm(q.view(N,C), queue.view(C,K)) # 输出Nxk，自己与上一批次所有图的匹配度（全不匹配）    logits = cat([l_pos, l_neg], dim=1) # 输出Nx(1+k)    labels = zeros(N)    # NCE损失函数，就是为了保证自己与自己衍生的匹配度输出越大越好，否则越小越好    loss = CrossEntropyLoss(logits/t, labels)     loss.backward()    update(f_q.params) # f_q使用梯度立即更新    # 由于假设模板特征的表示方法是稳定的，因此它更新得更慢，这里使用动量法更新，相当于做了个滤波。    f_k.params = m*f_k.params+(1-m)*f_q.params     enqueue(queue, k) # 为了生成反例，所以引入了队列    dequeue(queue)
动量编码器
MoCo 使用两个编码器：查询编码器（query encoder）和键编码器（key encoder）。查询编码器通过反向传播正常更新，而键编码器是查询编码器的缓慢更新版本，其参数通过动量机制更新。具体来说，键编码器的参数是其之前参数与查询编码器参数的加权平均，动量系数（momentum coefficient）通常设为 0.999，使得键编码器变化非常缓慢。这种稳定性保证了队列中键的表征不会因编码器快速变化而失去一致性。
$$
\theta_k \leftarrow m \theta_k + (1-m) \theta_q
$$
query的编码器和key的编码器既可以是相同的（模型的架构一样，参数完全共享，比如Inva Spread），或者说它们的参数是部分共享的，也可以是彻底不一样的两个网络（CMC，多视角多编码器）。
Pretext Task（代理任务）
论文中主要采用了一个简单的实例判别任务（Instance Discrimination）：如果一个查询和一个键来源于同一张图片的不同随机增强视图（例如，不同的裁剪、颜色抖动等），则它们构成一个正样本对；否则构成负样本对 。编码器（如 ResNet ）将这些视图编码为特征向量，然后通过 InfoNCE 损失函数进行优化 。
损失函数
在对比学习中，最常用的目标函数是 InfoNCE 损失（Noise-Contrastive Estimation 的信息理论扩展）。InfoNCE 损失基于互信息最大化的思想，鼓励模型区分正样本对和负样本对。
$$
\mathcal L_{q} = - \log \frac{\exp(q \cdot k_{+} / \tau)}{\sum_{i=0}^{K} \exp(q \cdot k_{i} / \tau)}
$$
$ q $ 是查询的编码表示。
$ k_{+} $ 是正样本键的编码表示。
$ k_i $ 是字典中所有的键（包括一个正样本 $ k_{+} $ 和 K 个负样本）。
$ \tau $ 是超参数，用来控制分布的形状 ，去掉后整个式子其实就是交叉熵损失函数。
$ q \cdot k $ 表示点积相似度。
NCE loss（noise contrastive estimation ）：将超级多分类转为二分类——数据类别data sample和噪声类别noisy sample。这样解决了类别多的问题。
]]></content>
      <categories>
        <category>论文精读</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>论文精读</tag>
        <tag>对比学习</tag>
      </tags>
  </entry>
  <entry>
    <title>基础知识--STL</title>
    <url>/2025/02/STL/</url>
    <content><![CDATA[标准模板库（STL）
STL 即标准模板库（Standard Template Library），是 C++  标准库的一部分，里面包含了一些模板化的通用的数据结构和算法。由于其模板化的特点，它能够兼容自定义的数据类型，避免大量的造轮子工作。NOI 和  ICPC 赛事都支持 STL 库的使用，因此合理利用 STL 可以避免编写无用算法，并且充分利用编译器对模板库优化提高效率。
STL容器

迭代器
​	在 STL 中，迭代器（Iterator）用来访问和检查 STL 容器中元素的对象，它的行为模式和指针类似，但是它封装了一些有效性检查，并且提供了统一的访问格式。
​	迭代器听起来比较晦涩，其实迭代器本身可以看作一个数据指针。迭代器主要支持两个运算符：自增 (++) 和解引用（单目 * 运算符），其中自增用来移动迭代器，解引用可以获取或修改它指向的元素。
vector&lt;int&gt; data(10);//下面两个 for 循环的效果是一样的for (int i = 0; i &lt; data.size(); i++)  cout &lt;&lt; data[i] &lt;&lt; endl;  // 使用下标访问元素for (vector&lt;int&gt;::iterator iter = data.begin(); iter != data.end(); iter++)  cout &lt;&lt; *iter &lt;&lt; endl;  // 使用迭代器访问元素// 在C++11后可以使用 auto iter = data.begin() 来简化上述代码
​	STL 容器 一般支持从一端或两端开始的访问，以及对 const 修饰符 的支持。例如容器的 begin() 函数可以获得指向容器第一个元素的迭代器，rbegin() 函数可以获得指向容器最后一个元素的反向迭代器，cbegin() 函数可以获得指向容器第一个元素的 const 迭代器，end() 函数可以获得指向容器尾端（「尾端」并不是最后一个元素，可以看作是最后一个元素的后继；「尾端」的前驱是容器里的最后一个元素，其本身不指向任何一个元素）的迭代器。
序列式容器

向量(vector) 后端可高效增加元素的顺序表。
双端队列(deque) 双端都可高效增加元素的顺序表。
列表(list) 可以沿双向遍历的链表。
单向列表(forward_list) 只能沿一个方向遍历的链表。

vector
std::vector 是 STL 提供的 内存连续的、可变长度 的数组（亦称列表）数据结构。能够提供线性复杂度的插入和删除，以及常数复杂度的随机访问。
vector定义
#include&lt;vector&gt;                       //头文件vector&lt;typename&gt; name;                 //相当于长度可以变化的一维数组vector&lt;vector&lt;typename&gt; &gt; name;        //相当于长度可以变化的一维数组vector&lt;typename&gt; Arrayname[arraySize]; //一维长度固定为arraySize，Arrayname[0]~Arrayname[arraySize-1]中每一个都是一个vector容器//typename可以是任何基本类型，例如int,double,char,结构体等，也可以是STL标准容器，例如vector,set,queue等
// 1. 创建空vector; 常数复杂度vector&lt;int&gt; v0;// 1+. 这句代码可以使得向vector中插入前3个元素时，保证常数时间复杂度v0.reserve(3);// 2. 创建一个初始空间为3的vector，其元素的默认值是0; 线性复杂度vector&lt;int&gt; v1(3);// 3. 创建一个初始空间为3的vector，其元素的默认值是2; 线性复杂度vector&lt;int&gt; v2(3, 2);// 4. 创建一个初始空间为3的vector，其元素的默认值是1，// 并且使用v2的空间配置器; 线性复杂度vector&lt;int&gt; v3(3, 1, v2.get_allocator());// 5. 创建一个v2的拷贝vector v4， 其内容元素和v2一样; 线性复杂度vector&lt;int&gt; v4(v2);// 6. 创建一个v4的拷贝vector v5，其内容是&#123;v4[1], v4[2]&#125;; 线性复杂度vector&lt;int&gt; v5(v4.begin() + 1, v4.begin() + 3);// 7. 移动v2到新创建的vector v6，不发生拷贝; 常数复杂度; 需要 C++11vector&lt;int&gt; v6(std::move(v2));  // 或者 v6 = std::move(v2);
vector容器内元素的访问
//1.通过下标访问vector&lt;int&gt; m;//直接访问m[index],index从0到m.size()-1//2.通过迭代器访问vector&lt;int&gt;::iterator it;//迭代器就像STL容器的“指针”，可以用*it访问vector中的元素//m[i]和*(m.begin()+i)等价
#include&lt;stdio.h&gt;#include&lt;vector&gt;using namespace std;int main()&#123;    vector&lt;int&gt; vi;    for(int i=1;i&lt;=5;i++) vi.push_back(i);    //1    vector&lt;int&gt;::iterator it = vi.begin();    for(int i=0;i&lt;5;i++)    &#123;        printf(&quot;%d&quot;,*(it+i)); //输出 1 2 3 4 5    &#125;    //2    for(vector&lt;int&gt;::iterator it = vi.begin();it!=vi.end();it++)    &#123;        printf(&quot;%d&quot;,*it);    //输出 1 2 3 4 5    &#125;    return 0;&#125;
vector常用函数


push_back() 在末尾插入一个元素，均摊复杂度为 常数，最坏为线性复杂度。


pop_back() 删除末尾元素，常数复杂度。


front()返回vector的第一个元素，等价于*a.begin() 和 a[0]。


back()返回vector的最后一个元素，等价于*==a.end() 和 a[a.size() – 1]。


size() 返回容器长度（元素数量），即 std::distance(v.begin(), v.end())。


v.data() 返回指向数组第一个元素的指针。


insert() 支持在某个迭代器位置插入元素、可以插入多个。insert(it,x)在it处插入x。


clear() 清除所有元素。


erase() 删除某个迭代器或者区间的元素，返回最后被删除的迭代器。


erase(it)删除迭代器为it处的元素，erase(first，last)即删除[first，last)内所有元素。
deque
std::deque（双端队列）支持在头部和尾部进行高效插入删除的序列容器，与vector相比：

头尾插入/删除时间复杂度为O(1)
支持随机访问（通过下标）
存储空间分块管理，迭代器比vector复杂
中间插入删除效率较低

deque定义
#include &lt;deque&gt;std::deque&lt;int&gt; dq1;              // 空双端队列std::deque&lt;char&gt; dq2(5, &#x27;A&#x27;);     // 包含5个&#x27;A&#x27;std::deque&lt;int&gt; dq3 = &#123;1,2,3&#125;;    // 列表初始化（C++11）
deque容器内元素的访问



方式
示例
说明




下标访问
dq[0]
无越界检查


at() 方法
dq.at(0)
有越界检查，越界抛出异常


首元素
dq.front()
等价于 dq[0]


末尾元素
dq.back()
等价于 dq[dq.size()-1]



deque常用函数



函数
功能说明




push_front(x)
在头部插入元素x


pop_front()
删除头部元素


push_back(x)
在尾部插入元素x


pop_back()
删除尾部元素


insert(pos, x)
在迭代器pos前插入元素x


erase(pos)
删除迭代器pos指向的元素


resize(n)
调整容器大小为n


shrink_to_fit()
请求移除未使用的容量（C++11）



特殊说明
// 头尾操作示例std::deque&lt;int&gt; dq;dq.push_front(2);    // 头部插入：dq = [2]dq.push_back(3);     // 尾部插入：dq = [2,3]dq.pop_front();      // 删除头部：dq = [3]// 随机访问示例dq[0] = 5;          // 修改第一个元素
综合对比



特性\容器
vector
deque




头插效率
O(n)
O(1)


尾插效率
均摊O(1)
O(1)


中间插入
O(n)
O(n)


内存布局
单块连续内存
多块连续内存


迭代器失效
容易失效
部分操作不失效


缓存友好性
高
较低



关联式容器

集合(set) 用以有序地存储 互异 元素的容器，其实现是由节点组成的红黑树。
多重集合(multiset) 用以有序地存储元素的容器。允许存在相等的元素。

​	头文件set，主要包括set和multiset两个容器，分别是“有序集合”和“有序多重集合”，即前者的元素不能重复，而后者可以包含若干个相等的元素。set和multiset的内部实现是一棵红黑树，它们支持的函数基本相同。
set
set 是关联容器，含有键值类型对象的已排序集，搜索、移除和插入拥有对数复杂度。set 内部通常采用 红黑树 实现。平衡二叉树 的特性使得 set 非常适合处理需要同时兼顾查找、插入与删除的情况。
set定义
#include&lt;set&gt;set&lt;typename&gt; name;    //set数组的定义和vector相同set&lt;typename&gt; Arrayname[arraySize];
set容器内元素的访问
set只能通过迭代器访问
set和multiset的迭代器称为“双向访问迭代器”，不支持“随机访问”，支持星号(*)解除引用，仅支持”++”和–“两个与算术相关的操作。
若把it++，则it会指向“下一个”元素。这里的“下一个”元素是指在元素从小到大排序的结果中，排在it下一名的元素。同理，若把it–，则it将会指向排在“上一个”的元素。
set&lt;typename&gt;::iterator it;   //这样就得到了迭代器，可以通过*it来访问set
#include &lt;stdio.h&gt;#include &lt;set&gt;using namespace std;int main()&#123;    set&lt;int&gt; st;    st.insert(1);    st.insert(5);    st.insert(3);    st.insert(3);    for(set&lt;int&gt;::iterator it = st.begin();it != st.end();it++)    &#123;        printf(&quot;%d&quot;,*it);    &#125;    return 0;&#125;//输出结果：1 3 5
set常用函数


insert(x) 当容器中没有等价元素的时候，将元素 x 插入到 set 中。


find(x) 在 set 内存在键为 x 的元素时会返回该元素的迭代器，否则返回 end()。


erase(x) 删除值为 x 的 所有 元素，返回删除元素的个数。


​      erase(pos) 删除迭代器为 pos 的元素，要求迭代器必须合法。
​      erase(first,last) 删除迭代器在 [first,last) 范围内的所有元素。


clear() 清空 set。


count(x) 返回 set 内键为 x 的元素数量。


lower_bound(x) 返回指向首个不小于给定键的元素的迭代器。如果不存在这样的元素，返回 end()。


upper_bound(x) 返回指向首个大于给定键的元素的迭代器。如果不存在这样的元素，返回 end()。


empty() 返回容器是否为空。


size() 返回容器内元素个数。


// 现存可用的元素set&lt;int&gt; available;// 需要大于等于的值int x;// 查找最小的大于等于x的元素set&lt;int&gt;::iterator it = available.lower_bound(x);if (it == available.end()) &#123;  // 不存在这样的元素，则进行相应操作……&#125; else &#123;  // 找到了这样的元素，将其从现存可用元素中移除  available.erase(it);  // 进行相应操作……&#125;

映射(map) 由 {键，值} 对组成的集合，以某种比较键大小关系的谓词进行排列。
多重映射(multimap) 由 {键，值} 对组成的多重集合，亦即允许键有相等情况的映射。

map
map 是有序键值对容器，它的元素的键是唯一的。搜索、移除和插入操作拥有对数复杂度。map 通常实现为 红黑树。
map定义
map&lt;key,value&gt; mp;//字符串映射到整型，必须使用string而不能用char数组map&lt;string,int&gt; mp;//将set容器映射到字符串map&lt;set&lt;int&gt;, string&gt; mp;
map容器内元素的访问
//1.通过下标访问map&lt;char,int&gt; mp;//直接使用mp[&#x27;c&#x27;]来访问对应的整数，map中的键是唯一的。#include &lt;stdio.h&gt;#include &lt;map&gt;using namespace std;int main()&#123;    map&lt;char,int&gt; mp;    mp[&#x27;c&#x27;]=20;    mp[&#x27;c&#x27;]=30;    printf(&quot;%d\n&quot;,mp[&#x27;c&#x27;]);  //输出30    return 0;&#125;//2.通过迭代器访问map&lt;key,value&gt;::iterator it;//map可以使用it-&gt;first来访问键，使用it-&gt;second来访问值。#include &lt;stdio.h&gt;#include &lt;map&gt;using namespace std;int main()&#123;    map&lt;char,int&gt; mp;    mp[&#x27;m&#x27;]=20;    mp[&#x27;r&#x27;]=30;    mp[&#x27;a&#x27;]=40;    for(map&lt;char,int&gt;::iterator it = mp.begin();it!=mp.end();it++)    &#123;        printf(&quot;%c %d\n&quot;,it-&gt;first,it-&gt;second);    &#125;            return 0;&#125;// 输出：map会以键从小到大的顺序自动排序// a 40// m 20// r 30
map常用函数


通过向 map 中插入一个类型为 pair&lt;Key, T&gt; 的值可以达到插入元素的目的，例如 mp.insert(pair&lt;string,int&gt;(&quot;Alan&quot;,100));；


find(x): 若容器内存在键为 x 的元素，会返回该元素的迭代器；否则返回 end()。


erase(key) 函数会删除键为 key 的 所有 元素。返回值为删除元素的数量。


​       erase(pos): 删除迭代器为 pos 的元素，要求迭代器必须合法。
​       erase(first,last): 删除迭代器在 [first,last) 范围内的所有元素。


clear() 函数会清空整个容器。


count(x): 返回容器内键为 x 的元素数量。复杂度为 （关于容器大小对数复杂度，加上匹配个数)。


lower_bound(x): 返回指向首个不小于给定键的元素的迭代器。


upper_bound(x): 返回指向首个大于给定键的元素的迭代器。若容器内所有元素均小于或等于给定键，返回 end()。


empty(): 返回容器是否为空。


size(): 返回容器内元素个数。


无序（关联式）容器


无序（多重）集合(unordered_set/unordered_multiset)C++11，与 set/multiset 的区别在于元素无序，只关心「元素是否存在」，使用哈希实现。


无序（多重）映射(unordered_map/unordered_multimap)C++11，与 map/multimap 的区别在于键 (key) 无序，只关心 “键与值的对应关系”，使用哈希实现。


容器适配器
容器适配器其实并不是容器。它们不具有容器的某些特点（如：有迭代器、有 clear() 函数……）。

「适配器是使一种事物的行为类似于另外一种事物行为的一种机制」，适配器对容器进行包装，使其表现出另外一种行为。


栈(stack) 后进先出 (LIFO) 的容器，默认是对双端队列（deque）的包装。
队列(queue) 先进先出 (FIFO) 的容器，默认是对双端队列（deque）的包装。
优先队列(priority_queue) 元素的次序是由作用于所存储的值对上的某种谓词决定的的一种队列，默认是对向量（vector）的包装。

stack（栈）
STL 栈(std::stack) 是一种后进先出 (Last In, First Out) 的容器适配器，仅支持查询或删除最后一个加入的元素（栈顶元素），不支持随机访问，且为了保证数据的严格有序性，不支持迭代器。用来模拟实现一些递归。
stack定义
#include&lt;stack&gt;std::stack&lt;TypeName&gt; name;  // 使用默认底层容器 deque，数据类型为 TypeNamestd::stack&lt;TypeName, Container&gt; name;  // 使用 Container 作为底层容器std::stack&lt;TypeName&gt; s2(s1);        // 将 s1 复制一份用于构造 s2
stack容器内元素的访问
由于栈本身就是一种后进先出的数据结构，在STL的stack中只能通过top()来访问栈顶元素。
stack常用函数


top() 访问栈顶元素（如果栈为空，此处会出错）


push(x) 向栈中插入元素 x


pop() 删除栈顶元素


size() 查询容器中的元素数量


empty() 询问容器是否为空


queue（队列）
STL 队列(std::queue) 是一种先进先出 (First In, First Out) 的容器适配器，仅支持查询或删除第一个加入的元素（队首元素），不支持随机访问，且为了保证数据的严格有序性，不支持迭代器。
queue定义
#include&lt;queue&gt;std::queue&lt;TypeName&gt; name;  // 使用默认底层容器 deque，数据类型为 TypeNamestd::queue&lt;TypeName, Container&gt; name;  // 使用 Container 作为底层容器std::queue&lt;TypeName&gt; q2(q1);  // 将 s1 复制一份用于构造 q2
queue容器内元素的访问
由于队列本身就是一种先进先出的数据结构，在STL的queue中只能通过front()来访问队首元素，通过back()访问队尾元素。
queue常用函数


front() 访问队首元素（如果队列为空，此处会出错）


back() 访问队尾元素


push(x) 向队列中插入元素 x


pop() 删除队首元素


size() 查询容器中的元素数量


empty() 询问容器是否为空


priority_queue（优先队列）
优先队列 std::priority_queue 是一种 堆，一般为 二叉堆。队首元素一定是当前队列中优先级最高的那一个。
priority_queue定义
#include&lt;queue&gt;priority_queue&lt;TypeName&gt; name;             // 数据类型为 TypeNamepriority_queue&lt;TypeName, Container&gt; name;  // 使用 Container 作为底层容器priority_queue&lt;TypeName, Container, Compare&gt; name;// 使用 Container 作为底层容器，使用 Compare 作为比较类型
priority_queue容器内元素的访问
和队列不一样的是，优先队列没有front()和back()，只能通过top()访问队首元素(堆顶元素)。
priority_queue常用函数


top() 访问堆顶元素（此时优先队列不能为空）


pop() 删除堆顶元素（此时优先队列不能为空）


push(x) 插入元素，并对底层容器排序


size() 查询容器中的元素数量


empty() 询问容器是否为空


STL算法
STL 提供了大约 100 个实现算法的模版函数，基本都包含在 &lt;algorithm&gt; 之中，还有一部分包含在 &lt;numeric&gt; 和 &lt;functional&gt;。
algorithm
&lt;algorithm&gt; 头文件提供了大量通用算法，适用于多种容器。所有算法均通过迭代器操作，不对容器进行直接修改（除非明确说明）。
常用算法列表



算法
功能说明




sort(beg, end, cmp)
对区间[beg,end)排序，cmp为可选比较函数（默认升序）


reverse(beg, end)
反转指定区间的元素顺序


max(a, b) / min(a, b)
返回两个值的较大/较小值（C++11支持初始化列表：max(&#123;1,2,3&#125;)）


swap(a, b)
交换两个变量的值


find(beg, end, val)
在区间内查找值，返回首个匹配的迭代器，未找到返回end


count(beg, end, val)
统计区间内指定值出现的次数


fill(beg, end, val)
用指定值填充区间


copy(src_beg, src_end, dest_beg)
复制源区间到目标位置


unique(beg, end)
去除相邻重复元素，返回去重后的新结尾迭代器（通常先排序后使用）


lower_bound(beg, end, val)
在有序区间中找第一个不小于val的元素位置


upper_bound(beg, end, val)
在有序区间中找第一个大于val的元素位置


binary_search(beg, end, val)
检查有序区间中是否存在指定值



典型使用示例
// 自定义排序std::vector&lt;int&gt; vec = &#123;3,1,4,2&#125;;std::sort(vec.begin(), vec.end(), [](int a, int b)&#123; return a &gt; b; &#125;); // 降序排列// 去重操作std::sort(vec.begin(), vec.end());auto last = std::unique(vec.begin(), vec.end());vec.erase(last, vec.end());// 查找元素auto it = std::find(vec.begin(), vec.end(), 3);if (it != vec.end()) std::cout &lt;&lt; &quot;Found: &quot; &lt;&lt; *it;
pair
std::pair 是一个模板类，用于将两个值组合成一个单元。常用于需要返回两个值的场景，或作为map容器的元素类型。通过灵活使用 pair，可以轻松应对 需要将关联数据捆绑存储、处理 的场景。
pair定义
#include &lt;utility&gt;//可以在定义时直接完成 pair 的初始化。pair&lt;int, double&gt; p0(1, 2.0);//也可以使用先定义，后赋值的方法完成 pair 的初始化。pair&lt;int, double&gt; p1;   // 默认构造：int=0, double=0.0p1.first = 1;p1.second = 2.0;//还可以使用 std::make_pair 函数。该函数接受两个变量，并返回由这两个变量组成的 pair。pair&lt;int, double&gt; p2 = make_pair(1, 2.0);//在 C++11 以及之后的版本中，make_pair 可以配合 auto 使用，以避免显式声明数据类型。auto p3 = make_pair(3.14, &quot;PI&quot;);          // 自动推导类型（C++11）
pair元素访问



成员变量
说明




first
访问第一个元素


second
访问第二个元素



常用操作



操作
说明




比较运算符（==, !=, &lt;等）
按字典序比较：先比较first，相等时再比较second


swap
使用 swap 函数交换 pair 的值。


赋值
将 pair 的值赋给另一个类型一致的 pair。p0 = p1;



string
std::string 是 C++ 标准库提供的字符串类，用于存储和操作字符序列。它在内存中以连续块存储字符，支持高效的随机访问和动态调整大小。
string定义
#include &lt;string&gt;std::string str1;                // 空字符串std::string str2 = &quot;Hello&quot;;      // 用C风格字符串初始化std::string str3(5, &#x27;A&#x27;);        // 创建含5个&#x27;A&#x27;的字符串，输出&quot;AAAAA&quot;std::string str4(str2, 1, 3);    // 从str2下标1开始取3个字符，输出&quot;ell&quot;
string容器内元素的访问
//1. 通过下标访问str[index]//2. 通过迭代器访问string::iterator it;//可以通过*it访问string里的每一位for(string::iterator it= str.begin();it!=str.end();it++)&#123;    printf(&quot;%c&quot;,*it);&#125;//string和vector一样，支持直接对迭代器进行加减某个字，str.begin()+3
string常用函数



函数
功能说明




append(str)
在字符串末尾追加内容


push_back(c)
追加单个字符


pop_back()
删除最后一个字符（C++11）


insert(pos, str)
在指定位置插入字符串


erase(pos, len)
从pos开始删除len个字符


replace(pos, len, str)
替换从pos开始的len个字符为str


find(str, pos)
从pos开始查找子串，返回首次出现的位置，未找到返回string::npos


compare(str)
比较字符串（返回0表示相等，负数表示小于，正数表示大于）


c_str()
返回C风格字符串（const char*）


clear()
清空字符串内容


resize(n, c)
调整字符串长度为n，多出部分用字符c填充


capacity()
返回当前分配的存储容量


reserve(n)
预分配至少能存储n个字符的内存空间



]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>set</tag>
        <tag>map</tag>
        <tag>queue</tag>
        <tag>stack</tag>
        <tag>deque</tag>
        <tag>STL</tag>
        <tag>vector</tag>
        <tag>string</tag>
        <tag>algorithm</tag>
        <tag>priority_queue</tag>
      </tags>
  </entry>
  <entry>
    <title>Transformer</title>
    <url>/2025/04/Transformer/</url>
    <content><![CDATA[Attention Is All You Need
个人理解 transformer 编码器是把人能理解的东西转化成计算机能理解的东西。对比与论文写作的这个过程来说，位置编码就是作者写这篇论文的顺序，反复打磨论文这个过程就对应着这个n个编码器，第一遍的初稿相当于第一个编码器，可能效果不尽人意。把人能理解的东西编码成论文。到读者来说就是解码的过程，每一次读论文就是一次解码的过程，你必须多次解码才能对这个论文理解的更加透彻，还要时刻注意mask操作，写作时要时刻注意读者理解到什么地步，读者的阅读是按顺序进行的。q就是你感兴趣的地方，k就是论文中的关键点。
Transformer 是一种基于注意力机制（Attention Mechanism）的深度学习模型，摒弃了传统的循环神经网络（RNN）和卷积神经网络（CNN），完全依赖注意力机制处理序列数据。
RNN处理长序列时容易出现梯度消失或梯度爆炸的问题，健达来说就是就像一个记性不好的老人，处理长内容时，前面的内容记不住，后面又容易混淆。
CNN虽然在提取局部特征上表现出色，但对长距离依赖关系的捕捉能力欠佳，就好比只盯着眼前的局部风景，而忽略了远方的整体美景。
Transformer则巧妙地摒弃了RNN的顺序处理方式和CNN的局部处理局限，引入了自注意力机制，这就像是给大模型装上了一个“全局扫描雷达”，能够同时关注输入序列中的各个位置，极大地提升了对长序列的处理能力，完美解决了上述两个难题。
注意力机制通过注意力汇聚将查询（自主性提示）和键（非自主性提示）结合在一起，实现对值（感官输入）的选择倾向，这是与 CNN 等模型的关键区别。


]]></content>
      <categories>
        <category>论文精读</category>
        <category>自然语言处理</category>
      </categories>
      <tags>
        <tag>论文精读</tag>
        <tag>transformer</tag>
      </tags>
  </entry>
  <entry>
    <title>基础知识--哈希表</title>
    <url>/2025/02/%E5%93%88%E5%B8%8C%E8%A1%A8/</url>
    <content><![CDATA[哈希表
哈希表概述
​	哈希表：又称散列表，一种以关键码的值「key-value」而直接进行访问的数据结构。任意的键值 key  都唯一对应到内存中的某个位置。只需要输入查找的键值，就可以快速地找到其对应的  value。
​	哈希函数：根据键值计算索引的函数就叫做哈希函数。
​	**冲突：**不同的关键码映射到同一散列位置。key1!=key2，但是H(key1)=H(key2)。
​	**同义词：**具有相同函数值的多个关键字。
​	All in all:  将元素通过一个函数转换为整数，使得该整数可以尽量唯一地代表这个元素 。
​	**需要解决的问题：**1. 哈希函数的构造。   2. 冲突解决的方法。
哈希函数构造方法
​	哈希函数应当易于计算，并且尽量使计算出来的索引均匀分布，以避免冲突。
直接定址法
**概述：**直接取关键字的某个线性函数值为哈希函数。
**哈希函数：**H(key) = key 或 H(key) = a*key + b   ( a和b为常数 )
**特点：**计算简单，不会产生冲突，适合关键字分布连续的情况（若不连续，则存储空间浪费很多，空间效率低）。
除留余数法
**概述：**指把key除以一个数mod得到的余数作为hash值的方法。当mod是一个质数时，H(key)能尽可能均匀覆盖每一个数。所以取mod为不大于表长Tsize但接近或等于表长的质数，即mod&lt;=Tsize且为质数。
**哈希函数：**H(key) = key % mod
**特点：**比较常用，关键在mod的选择，如何使得每个关键字通过该函数转换后等概率映射到散列空间的任一地址。
平方取中法
**概述：**指取key的平方的中间若干位作为hash值的方法，不常用。
**特点：**适合于关键字的每位取值都不够均匀或均小于散列地址所需位数。
处理冲突的方法
开放定址法（开地址法）
**基本思想：**有冲突时就去寻找下一个空的散列地址，只要散列表足够大，空的散列地址总能找到，并将数据元素存入。Hi = (H(key) + di) % Tsize (di为增量序列)   计算新的哈希值。
线性探查法
​	di = 0, 1, 2, … , Tsize-1
​	发生冲突时，顺序表查看表中下一个元素，直到有空闲单元。会出现聚集现象，降低查询效率。
平方探查法
​	di = 0² , +1² ,  -1² , +2² , -2² , … , +k² , -k²
​	不会出现聚集现象，不能探测所有单元，但至少能探测一半
伪随机探测法
​	di = 伪随机数序列
链地址法（拉链法）
**基本思想：**和上边方法不同，链地址法不计算新的哈希值，而是把相同散列地址的记录链成一单链表。m个散列地址就设m个单链表，然后用一个数组将m个单链表的表头指针存储起来，形成一个动态的结构。
**优点：**1. 非同义词不会冲突，无&quot;聚集&quot;现象。
​	   2. 链表上结点空间动态申请，更适合于表长不确定的情况（经常插入删除）。

哈希的查找及性能分析
查找过程
​	检测由散列函数形成的地址上是否有记录，若无记录则失败； 若有记录比较关键字值，若相等则查找成功，否则散列函数更新增量值，重复执行。
性能分析
​	在列表查找中，使用最广泛的二分查找算法，复杂度为O(log2n)，但其始终只能用于有序列表。普通无序列表只能采用遍历查找，复杂度为O(n)。而拥有较为理想的哈希函数实现的哈希表，对其任意元素的查找速度始终为常数级，即O(1)。  链地址法优于开放定址法，除留余数法作散列函数优于其它类型函数。
**装填因子：**∂=表中记录数/散列表长度。平均查找长度直接依赖于装填因子大小。也就是说，装填因子大小会直接影响到查找效率。装填因子越大，发生冲突的可能性越大。

​	查找效率三个因素影响：哈希函数、装填因子、处理冲突方法。
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>数组</tag>
        <tag>链表</tag>
        <tag>哈希表</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title>基础知识--回溯算法</title>
    <url>/2025/03/%E5%9B%9E%E6%BA%AF%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[回溯算法
​	回溯算法 是一种通过试错的方式寻找问题解的算法。它尝试逐步构建解决方案，如果在构建过程中的某一步发现当前的构建方案不可行，它会回溯（即取消最近一步的选择），然后尝试其他的可能性。这个过程就像是在迷宫中探索路径，当遇到死路时就退回上一个岔路口，选择另一条路继续前进。
核心思想

试探性选择:  在每一步，都面临多个选择，回溯算法会先选择其中一个进行尝试。
逐步构建:  它一步一步地构建可能的解。
可行性判断 (约束条件): 在每一步构建后，都会检查当前的部分解是否满足问题的约束条件。
回溯 (撤销选择): 如果发现当前部分解不可行，则撤销上一步的选择，回到之前的状态，并尝试其他的选择。
终止条件: 当找到一个完整的可行解，或者当所有可能的选择都尝试完毕且没有找到解时，算法终止。

基本步骤


定义问题的解空间： 确定问题的解可能存在的所有可能组合。例如，对于一个排列问题，解空间就是所有可能的排列。


确定约束条件：  定义问题解必须满足的条件。这些条件用于判断当前构建的部分解是否有效。


选择搜索策略 (通常是深度优先搜索 DFS)：  回溯算法通常使用深度优先搜索的方式来遍历解空间。


设计递归函数 (或迭代方式模拟递归)：
递归函数是实现回溯算法的关键。该函数通常包含以下几个部分：

基本情况 (终止条件)：  判断是否找到了一个完整的解，或者是否已经遍历完所有可能性但没有找到解。
选择步骤：  在当前状态下，有哪些选择可以进行？
扩展状态：  对于每个选择，更新状态，并递归调用自身进入下一层搜索。
回溯步骤：  在递归调用返回后，需要撤销当前的选择，恢复到之前的状态，以便尝试其他的选择。



剪枝优化 (可选但重要)：  在搜索过程中，如果发现某个部分解已经不可能导致最终解，可以提前结束对该分支的搜索，以提高效率。这称为剪枝。


应用示例
回溯算法可以应用于解决许多经典问题，包括但不限于：

组合问题：

组合总和 (Combination Sum):  在一个数字集合中找到所有和为目标值的组合。
子集 (Subsets):  找出给定集合的所有子集。
电话号码的字母组合 (Letter Combinations of a Phone Number):  给定数字字符串，返回所有可能的字母组合。


排列问题：

全排列 (Permutations):  生成给定集合的所有排列。
下一个排列 (Next Permutation):  找到给定排列的下一个字典序排列。


图论问题：

N 皇后问题 (N-Queens Problem):  在 NxN 的棋盘上放置 N 个皇后，使其互不攻击。
数独 (Sudoku Solver):  解决数独谜题。
迷宫寻路 (Maze Solving):  找到迷宫的路径。
图的着色问题 (Graph Coloring):  给图的顶点着色，使得相邻顶点颜色不同。
旅行商问题 (Traveling Salesman Problem - TSP) (近似解或小规模问题)：  虽然TSP通常使用更优化的算法，但在小规模情况下，回溯可以找到解。


其他问题：

0-1 背包问题 (0-1 Knapsack Problem)：  虽然动态规划更常用，但回溯也可以解决。
正则表达式匹配 (Regular Expression Matching) (某些情况)：  复杂的正则表达式匹配问题可以使用回溯解决。
解方程 (Solving Equations) (某些类型)：  例如，约束满足问题 (Constraint Satisfaction Problems - CSPs)。



回溯算法模板
回溯法其实就是暴力查找，回溯法解决的问题都可以抽象为树形结构（N叉树）。
void backtracking(参数) &#123;    if (终止条件) &#123;        存放结果;        return;    &#125;    for (选择：本层集合中元素（树中节点孩子的数量就是集合的大小）) &#123;        处理节点;        backtracking(路径，选择列表); // 递归        回溯，撤销处理结果    &#125;&#125;
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>回溯</tag>
      </tags>
  </entry>
  <entry>
    <title>图神经网络</title>
    <url>/2025/09/%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[图神经网络（GNN）全面指：从基础到高级应用
引言
在数据爆炸的时代，传统深度学习模型如CNN和RNN在处理结构化数据（如图像和序列）上取得了巨大成功，但现实世界中的许多数据都具有图结构（Graph Structure），例如社交网络、分子结构、知识图谱、交通网络等。这些数据是非欧几里德的（Non-Euclidean），节点之间存在复杂的拓扑关系，无法直接用网格或序列表示。这就是图神经网络（Graph Neural Networks, GNN）登场的原因。
GNN 通过模拟节点间的消息传递机制，捕捉图的局部和全局结构，实现对图数据的表示学习。它已在推荐系统、药物发现、蛋白质折叠预测等领域大放异彩。本文将从基础概念入手，逐步深入GNN的核心原理、经典模型、实现技巧和实际应用，帮助你全面掌握这一技术。无论你是初学者还是有经验的从业者，这篇指南都能提供实用价值。
图数据基础
图的定义与表示
图 $ G = (V, E) $ 由节点集 $ V $（Vertices）和边集 $ E $（Edges）组成：

节点（Nodes）：实体，如用户、原子。
边（Edges）：关系，如友谊、化学键。
类型：

无向图：边无方向（e.g., 社交网络）。
有向图：边有方向（e.g., 网页链接）。
加权图：边有权重 $ w_{uv} $（e.g., 相似度分数）。
异构图：节点/边有多种类型（e.g., 知识图谱）。



图的常见表示方法：

邻接矩阵（Adjacency Matrix） $ A \in \mathbb{R}^{|V| \times |V|} $：$ A_{uv} = 1 $ 如果存在边 $ (u, v) $，否则为0。适合小图，但空间复杂度 $ O(|V|^2) $。
边列表（Edge List）：稀疏表示，如 $[ (u_1, v_1), (u_2, v_2), \dots ] $，适合大图。
度矩阵（Degree Matrix） $ D $，对角线 $ D_{ii} = \sum_j A_{ij} $（节点i的度）。
拉普拉斯矩阵（Laplacian Matrix） $ L = D - A $，用于谱分析：它是半正定的，特征分解 $ L = U \Lambda U^T $，其中 $ U $ 是傅里叶基。

图任务类型
GNN 针对不同粒度的数据设计：

节点级任务：节点分类（e.g., 预测论文类别）、节点回归（e.g., 预测节点影响力）。
边级任务：链接预测（e.g., 推荐朋友）。
图级任务：图分类（e.g., 判断分子是否毒性）、图回归（e.g., 预测分子能量）。

数据集示例：

节点分类：Cora（论文引用网络，2708节点，5429边）。
图分类：MUTAG（188个分子图）。

GNN 核心原理
GNN 的本质是**消息传递神经网络（Message Passing Neural Network, MPNN）**框架，由Scarselli等人在2009年提出。它通过多层迭代，让每个节点从邻居聚合信息，逐步捕捉多跳（multi-hop）依赖。
数学基础：图信号处理
图傅里叶变换：
给定图拉普拉斯矩阵 $L = D - A$ 的特征分解 $L = U\Lambda U^T$，其中 $U$ 是特征向量矩阵，$\Lambda$ 是特征值对角矩阵。
图信号 $x \in \mathbb{R}^{|V|}$ 的傅里叶变换定义为：
$$\hat{x} = U^T x$$
逆变换为：
$$x = U\hat{x}$$
图卷积的谱定义：
图上的卷积操作定义为：
$$g_\theta * x = U((U^T g_\theta) \odot (U^T x)) = Ug_\theta(\Lambda)U^T x$$
其中 $g_\theta(\Lambda)$ 是谱域的滤波器，$\odot$ 是元素级乘积。
从谱域到空间域：
计算特征分解的复杂度为 $O(|V|^3)$，不可扩展。通过多项式近似（如Chebyshev多项式）可以避免显式特征分解：
$$g_\theta(\Lambda) \approx \sum_{k=0}^{K} \theta_k T_k(\tilde{\Lambda})$$
其中 $T_k$ 是Chebyshev多项式，$\tilde{\Lambda} = \frac{2}{\lambda_{max}}\Lambda - I$。
消息传递机制
假设初始节点特征 $ h_v^{(0)} = x_v $（节点v的输入特征）。 在第 $ k $ 层：

消息生成（Message Generation）：对于每条边 $ (u, v) $，生成消息 $ m_{uv}^{(k)} = f(h_u^{(k-1)}, h_v^{(k-1)}, e_{uv}) $，其中 $ f $ 是可学习函数（如MLP），$ e_{uv} $ 是边特征。
聚合（Aggregation）：节点v聚合邻居消息 $ \tilde{h}v^{(k)} = \text{AGGREGATE}({ m{uv}^{(k)} : u \in \mathcal{N}(v) }) $。

常见AGG：Sum（求和）、Mean（平均）、Max（最大）、Attention（注意力）。


更新（Update）：$ h_v^{(k)} = \text{UPDATE}(\tilde{h}_v^{(k)}, h_v^{(k-1)}) $，UPDATE 如GRU、MLP + ReLU。
读出（Readout）（仅图级任务）：全局池化 $ \hat{y} = \text{READOUT}({ h_v^{(K)} : v \in V }) $，如mean pooling或sum。

数学上，整个过程可并行化，使用稀疏矩阵运算。关键假设：同质性（Homophily），相连节点相似。
谱方法 vs 空间方法

谱方法（Spectral GNN）：基于图信号处理（Graph Signal Processing）。图卷积定义为 $ g_\theta * x = U g_\theta(\Lambda) U^T x $，其中 $ g_\theta(\lambda) $ 是滤波器（e.g., 多项式）。优点：理论基础强；缺点：计算 $ U $ 成本高（O(|V|^3)）。

示例：ChebNet（2017），用Chebyshev多项式近似滤波器，K阶多项式只需O(K)参数。


空间方法（Spatial GNN）：直接在节点邻域操作，更高效、可扩展。主流模型如GCN、GAT均属此类。

经典GNN模型详解
Graph Convolutional Network (GCN)
Kipf &amp; Welling (2017) 的开创性工作，将CNN推广到图。
详细数学推导
从谱卷积到GCN：


起点：谱卷积
$$g_\theta * x = Ug_\theta(\Lambda)U^T x$$


一阶Chebyshev近似（$K=1$）
$$g_\theta(\Lambda) \approx \theta_0 + \theta_1 \Lambda$$
代入得：
$$g_\theta * x \approx \theta_0 x + \theta_1 L x$$


参数简化
假设 $\theta = \theta_0 = -\theta_1$，得：
$$g_\theta * x \approx \theta(I - L)x = \theta(I - D + A)x$$
由于 $L = D - A$，可以重写为：
$$g_\theta * x \approx \theta(2I - L)x$$


重归一化技巧
使用 $\tilde{A} = A + I$（添加自环）和对应的度矩阵 $\tilde{D}$：
$$H^{(l+1)} = \sigma(\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}H^{(l)}W^{(l)})$$


直观理解：

$\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}$ 是对称归一化的邻接矩阵
每个节点的特征是其邻居特征的加权平均
权重由节点度数决定，防止度数大的节点主导

GCN的实际意义与应用
为什么GCN如此重要？


计算效率的突破

避免了特征分解的O(N³)复杂度
稀疏矩阵运算，复杂度降至O(E)，E是边数
可以处理百万节点规模的图



表达能力与简洁性的平衡

一阶近似虽简单但足够有效
每层只有一个权重矩阵W，参数量少
实践证明：2-3层GCN往往就能达到好效果



理论与实践的统一

有坚实的谱图理论基础
实现简单，易于集成到深度学习框架
可以自然地与其他神经网络模块结合



GCN的典型应用场景



应用领域
具体任务
为什么适用GCN




社交网络
用户分类、社区发现
利用社交关系传播信息


推荐系统
物品推荐、用户画像
建模用户-物品交互图


知识图谱
实体分类、关系预测
利用知识结构


分子化学
分子属性预测
原子作为节点，化学键作为边


交通网络
流量预测
道路连接的空间依赖



实践中的关键技巧


层数选择

通常2-3层最优，过深会过平滑
使用残差连接可以训练更深的网络
JKNet：跳跃连接聚合所有层的输出



归一化变体

对称归一化：$\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}$（最常用）
随机游走归一化：$\tilde{D}^{-1}\tilde{A}$
行归一化：保持特征尺度



加速技巧

预计算归一化邻接矩阵
使用稀疏矩阵运算库
批处理多个图时使用块对角矩阵



缺点与解决方案：

过平滑问题：深层GCN会导致所有节点表示趋同

解决：残差连接、跳跃连接、DropEdge


固定邻域聚合：不能自适应调整邻居重要性

解决：GAT引入注意力机制


扩展性受限：需要完整邻接矩阵

解决：GraphSAGE的采样策略



Graph Attention Network (GAT)
Veličković等 (2018) 引入注意力机制，提升表达力。
注意力机制详解
核心思想：不同邻居对中心节点的重要性不同，应该学习自适应的聚合权重。
注意力系数计算：


特征变换：
$$ 
\mathbf{z}_v = \mathbf{W}\mathbf{h}_v
$$ 


注意力得分：
$$ 
e_{vu} = \text{LeakyReLU}(\mathbf{a}^T[\mathbf{z}_v \parallel \mathbf{z}_u])
$$    $$
其中 $\parallel$ 表示拼接操作，$\mathbf{a} \in \mathbb{R}^{2F’}$ 是可学习的注意力向量。


归一化（softmax）：
$$ 
\alpha_{vu} = \frac{\exp(e_{vu})}{\sum_{k \in \mathcal{N}(v) \cup \{v\}} \exp(e_{vk})}
$$    $$


特征聚合：
$$ 
\mathbf{h}_v' = \sigma\left(\sum_{u \in \mathcal{N}(v) \cup \{v\}} \alpha_{vu} \mathbf{z}_u\right)
$$    $$


多头注意力机制
GAT使用多头注意力来稳定学习过程：
$$ 
\mathbf{h}_v' = \mathop{\Big\Vert}_{k=1}^K \sigma\left(\sum_{u \in \mathcal{N}(v) \cup \{v\}} \alpha_{vu}^k \mathbf{W}^k\mathbf{h}_u\right)
$$ 
其中 $\Big\Vert$ 表示拼接，$K$ 是注意力头的数量。
最后一层使用平均而非拼接：
$$ 
\mathbf{h}_v' = \sigma\left(\frac{1}{K}\sum_{k=1}^K \sum_{u \in \mathcal{N}(v) \cup \{v\}} \alpha_{vu}^k \mathbf{W}^k\mathbf{h}_u\right)
$$ 
GAT vs GCN



特性
GCN
GAT




聚合权重
固定（基于度）
可学习


计算复杂度
$O(EF)$
$O(EF^2)$


表达能力
受限于拓扑
更灵活


可解释性
低
高（注意力可视化）



GAT的实践指南
何时选择GAT而非GCN？


异构性较强的图

节点的邻居重要性差异大
存在噪声边或无关连接
需要学习复杂的关系模式



需要可解释性

注意力权重可以可视化
帮助理解模型决策依据
发现重要的连接模式



动态图或时序图

边的重要性随时间变化
需要自适应调整聚合策略



GAT的调参技巧



超参数
典型值
调参建议




注意力头数
4-8
太少欠拟合，太多过拟合


隐藏维度
64-256
与图规模成正比


Dropout率
0.5-0.6
GAT容易过拟合，需要较大dropout


LeakyReLU负斜率
0.2
通常不需要调整


层数
2-3
深层GAT同样有过平滑问题



注意力机制的计算细节
步骤1：线性变换h&#x27;_i = W·h_i  (将d维特征映射到F&#x27;维)步骤2：计算注意力系数e_ij = LeakyReLU(a^T[h&#x27;_i || h&#x27;_j])其中 || 表示拼接，a是2F&#x27;维的可学习向量步骤3：归一化（softmax）α_ij = exp(e_ij) / Σ_k∈N(i) exp(e_ik)步骤4：加权聚合h&#x27;&#x27;_i = σ(Σ_j∈N(i) α_ij·h&#x27;_j)
常见问题与解决


注意力权重趋于均匀

原因：特征区分度不够
解决：增加特征维度，使用更深的变换



训练不稳定

原因：注意力机制增加了优化难度
解决：使用warmup，降低初始学习率



内存消耗大

原因：需要存储所有边的注意力权重
解决：使用稀疏注意力或采样



GraphSAGE
Hamilton等 (2017) 针对大图设计，支持归纳学习。

采样聚合：随机采样固定大小的k-hop邻居，避免全图计算。
聚合函数：

Mean：$ \text{AGG} = \text{mean}({ \mathbf{h}_u : u \in \text{sample}(\mathcal{N}(v)) }) $。
Pool：每个邻居用MLP池化后sum。
LSTM：顺序处理邻居消息。


更新：$ \mathbf{h}_v^{(k)} = \sigma( \mathbf{W}^{(k)} \cdot \text{CONCAT}( \mathbf{h}_v^{(k-1)}, \text{AGG} ) ) $。
优点：可扩展到百万节点图；缺点：采样引入方差。
应用：Pinterest的引脚推荐。

Graph Isomorphism Network (GIN)
Xu等 (2019) 提升图级表示的区分力。
公式：
$$ 
\mathbf{h}_v^{(k)} = \text{MLP}^{(k)} \left( (1 + \epsilon^{(k)}) \mathbf{h}_v^{(k-1)} + \sum_{u \in \mathcal{N}(v)} \mathbf{h}_u^{(k-1)} \right)
$$ 

$\epsilon^{(k)}$ 可学习，控制自环权重。

读出：
$$ 
\mathbf{h}_G = \text{MLP}\left( \sum_v \mathbf{h}_v^{(K)} \right)
$$ 

理论：等价于Weisfeiler-Lehman (WL) 图同构测试，能区分更多非同构图。
优点：SOTA于图分类基准（如OGB）。

实现与实践
框架选择

PyTorch Geometric (PyG)：基于PyTorch，易用。安装：pip install torch-geometric
Deep Graph Library (DGL)：支持PyTorch/TensorFlow/MXNet，适合异构图
Spektral：Keras接口

代码实现
GCN完整实现（PyTorch Geometric）
import torchimport torch.nn as nnimport torch.nn.functional as Ffrom torch_geometric.nn import GCNConvfrom torch_geometric.datasets import Coraclass GCN(nn.Module):    &quot;&quot;&quot;图卷积网络实现&quot;&quot;&quot;    def __init__(self, input_dim, hidden_dim, output_dim, dropout=0.5):        super(GCN, self).__init__()        self.conv1 = GCNConv(input_dim, hidden_dim)        self.conv2 = GCNConv(hidden_dim, output_dim)        self.dropout = dropout        def forward(self, x, edge_index):        # 第一层GCN + ReLU + Dropout        x = self.conv1(x, edge_index)        x = F.relu(x)        x = F.dropout(x, p=self.dropout, training=self.training)                # 第二层GCN        x = self.conv2(x, edge_index)        return F.log_softmax(x, dim=1)# 训练函数def train_gcn(model, data, optimizer, epochs=200):    model.train()    for epoch in range(epochs):        optimizer.zero_grad()        out = model(data.x, data.edge_index)        loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])        loss.backward()        optimizer.step()                if epoch % 50 == 0:            model.eval()            pred = model(data.x, data.edge_index).argmax(dim=1)            acc = (pred[data.test_mask] == data.y[data.test_mask]).float().mean()            print(f&#x27;Epoch &#123;epoch&#125;, Loss: &#123;loss:.4f&#125;, Test Acc: &#123;acc:.4f&#125;&#x27;)            model.train()# 使用示例dataset = Cora(root=&#x27;/tmp/Cora&#x27;)data = dataset[0]model = GCN(dataset.num_features, 16, dataset.num_classes)optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)train_gcn(model, data, optimizer)
GAT实现
from torch_geometric.nn import GATConvclass GAT(nn.Module):    &quot;&quot;&quot;图注意力网络实现&quot;&quot;&quot;    def __init__(self, input_dim, hidden_dim, output_dim, heads=8, dropout=0.6):        super(GAT, self).__init__()        self.conv1 = GATConv(input_dim, hidden_dim, heads=heads, dropout=dropout)        self.conv2 = GATConv(hidden_dim * heads, output_dim, heads=1, dropout=dropout)        self.dropout = dropout        def forward(self, x, edge_index):        x = F.dropout(x, p=self.dropout, training=self.training)        x = self.conv1(x, edge_index)        x = F.elu(x)        x = F.dropout(x, p=self.dropout, training=self.training)        x = self.conv2(x, edge_index)        return F.log_softmax(x, dim=1)
GraphSAGE实现
from torch_geometric.nn import SAGEConvclass GraphSAGE(nn.Module):    &quot;&quot;&quot;GraphSAGE实现&quot;&quot;&quot;    def __init__(self, input_dim, hidden_dim, output_dim, aggregator=&#x27;mean&#x27;):        super(GraphSAGE, self).__init__()        self.conv1 = SAGEConv(input_dim, hidden_dim, aggregator=aggregator)        self.conv2 = SAGEConv(hidden_dim, output_dim, aggregator=aggregator)        def forward(self, x, edge_index):        x = self.conv1(x, edge_index)        x = F.relu(x)        x = F.dropout(x, training=self.training)        x = self.conv2(x, edge_index)        return F.log_softmax(x, dim=1)
应用案例
1. 社交网络节点分类
# 社交网络影响力预测def social_network_influence_prediction(graph_data):    &quot;&quot;&quot;    预测社交网络中用户的影响力        节点特征：用户画像（年龄、兴趣、活跃度等）    边：社交关系（关注、互动）    任务：预测用户影响力评分    &quot;&quot;&quot;    model = GAT(        input_dim=graph_data.num_features,        hidden_dim=64,        output_dim=1,  # 回归任务        heads=4    )    # 训练过程略...    return model
2. 分子属性预测
# 药物毒性预测def molecular_toxicity_prediction(molecular_graphs):    &quot;&quot;&quot;    预测分子的毒性        节点：原子（特征：原子类型、度、电荷等）    边：化学键（特征：键类型、键长等）    任务：二分类（有毒/无毒）    &quot;&quot;&quot;    model = GIN(        input_dim=atomic_features_dim,        hidden_dim=128,        output_dim=2  # 二分类    )    # 图级任务，需要全局池化    return model
3. 推荐系统
# 基于GNN的推荐系统class GNNRecommender(nn.Module):    &quot;&quot;&quot;用户-商品二部图推荐&quot;&quot;&quot;    def __init__(self, num_users, num_items, embedding_dim=64):        super().__init__()        self.user_embedding = nn.Embedding(num_users, embedding_dim)        self.item_embedding = nn.Embedding(num_items, embedding_dim)        self.conv1 = GCNConv(embedding_dim, embedding_dim)        self.conv2 = GCNConv(embedding_dim, embedding_dim)        def forward(self, user_item_edges):        # 获取嵌入        user_emb = self.user_embedding.weight        item_emb = self.item_embedding.weight        x = torch.cat([user_emb, item_emb], dim=0)                # 图卷积        x = self.conv1(x, user_item_edges)        x = F.relu(x)        x = self.conv2(x, user_item_edges)                # 分离用户和商品嵌入        user_emb_final = x[:num_users]        item_emb_final = x[num_users:]                return user_emb_final, item_emb_final
优化技巧
1. 过平滑问题及解决方案
class ResGCN(nn.Module):    &quot;&quot;&quot;带残差连接的GCN，缓解过平滑&quot;&quot;&quot;    def __init__(self, input_dim, hidden_dim, num_layers=4):        super().__init__()        self.convs = nn.ModuleList()        self.bns = nn.ModuleList()                self.convs.append(GCNConv(input_dim, hidden_dim))        self.bns.append(nn.BatchNorm1d(hidden_dim))                for _ in range(num_layers - 1):            self.convs.append(GCNConv(hidden_dim, hidden_dim))            self.bns.append(nn.BatchNorm1d(hidden_dim))        def forward(self, x, edge_index):        for i, (conv, bn) in enumerate(zip(self.convs, self.bns)):            identity = x if i &gt; 0 else None            x = conv(x, edge_index)            x = bn(x)            x = F.relu(x)            if identity is not None:                x = x + identity  # 残差连接        return x
2. 可扩展性优化
class MiniBatchGraphSAGE:    &quot;&quot;&quot;小批量训练GraphSAGE&quot;&quot;&quot;    def __init__(self, model, num_samples=[10, 10]):        self.model = model        self.num_samples = num_samples  # 每层采样邻居数        def sample_neighbors(self, node_ids, edge_index, num_samples):        &quot;&quot;&quot;邻居采样&quot;&quot;&quot;        # 实现采样逻辑        sampled_edges = []        for node_id in node_ids:            neighbors = edge_index[1][edge_index[0] == node_id]            if len(neighbors) &gt; num_samples:                neighbors = neighbors[torch.randperm(len(neighbors))[:num_samples]]            sampled_edges.append(neighbors)        return sampled_edges
3. 注意力机制优化
class ImprovedGAT(nn.Module):    &quot;&quot;&quot;改进的GAT：添加边特征和多尺度注意力&quot;&quot;&quot;    def __init__(self, node_dim, edge_dim, hidden_dim):        super().__init__()        self.node_transform = nn.Linear(node_dim, hidden_dim)        self.edge_transform = nn.Linear(edge_dim, hidden_dim)        self.attention = nn.MultiheadAttention(hidden_dim, num_heads=4)        def forward(self, x, edge_index, edge_attr):        # 节点特征变换        h = self.node_transform(x)                # 边特征融入注意力计算        edge_h = self.edge_transform(edge_attr)                # 多头注意力        attn_output, _ = self.attention(h, h, h)        return attn_output
未来方向
1. 动态图神经网络

处理时序变化的图结构
应用：社交网络演化、交通流预测

2. 图生成模型

GraphVAE、GraphGAN
应用：分子生成、网络设计

3. 可解释性

注意力可视化
子图重要性分析

4. 大规模图处理

分布式GNN训练
图采样和压缩技术

总结
图神经网络作为处理非欧几里德数据的强大工具，已经在多个领域展现出巨大潜力。从基础的GCN到复杂的GAT、GraphSAGE，每种模型都有其独特优势和适用场景。
核心要点：

消息传递是GNN的核心机制
聚合函数的选择影响表达能力
过平滑是深层GNN的主要挑战
可扩展性是实际应用的关键

随着研究的深入，GNN正在向更高效、更可解释、更通用的方向发展。掌握GNN不仅需要理解理论，更需要大量实践。希望本文能为你的GNN学习之旅提供帮助。
参考文献

Kipf, T. N., &amp; Welling, M. (2017). Semi-supervised classification with graph convolutional networks. ICLR 2017.
Veličković, P., et al. (2018). Graph Attention Networks. ICLR 2018.
Hamilton, W. L., et al. (2017). Inductive representation learning on large graphs. NeurIPS 2017.
Xu, K., et al. (2019). How powerful are graph neural networks? ICLR 2019.
Wu, Z., et al. (2020). A comprehensive survey on graph neural networks. IEEE TNNLS.

]]></content>
      <categories>
        <category>论文精读</category>
        <category>图神经网络</category>
      </categories>
      <tags>
        <tag>论文精读</tag>
        <tag>GNN</tag>
        <tag>图神经网络</tag>
      </tags>
  </entry>
  <entry>
    <title>基础知识--图论</title>
    <url>/2025/03/%E5%9B%BE%E8%AE%BA/</url>
    <content><![CDATA[基础知识–图论
图论是数学的一个分支，以图为研究对象。  图论中的“图”是一种抽象的数学结构，由顶点（点）和连接顶点的边（线）构成，用于描述事物之间特定的关系。

核心思想:  用点代表事物，用连接两点的线表示事物之间的关系。

图的基本概念


图 (Graph)
一个图 G 由两个基本集合构成：

顶点集 (Vertex Set) V(G):  图中所有顶点的集合。 顶点通常用点、小圆圈或标签表示。
边集 (Edge Set) E(G):  图中所有边的集合。 边连接一对顶点，表示顶点之间的关系。 边通常用线段、曲线或箭头表示。

我们可以用数学符号表示一个图：  G = (V, E)


顶点 (Vertex / Node / Point)

图的基本组成部分，代表研究对象或实体。
示例:

在社交网络中，顶点可以代表 人。
在交通网络中，顶点可以代表 城市。
在电路图中，顶点可以代表 电子元件。





边 (Edge / Arc / Line)

连接两个顶点的线，表示顶点之间存在的关系。
示例:

在社交网络中，边可以表示两个人之间的 朋友关系。
在交通网络中，边可以表示两个城市之间的 道路。
在电路图中，边可以代表 导线。





关联 (Incidence)

如果一条边 e 连接了顶点 u 和 v，则称边 e 与顶点 u 和 v 关联。
简单来说，就是边“连接到”哪些顶点。



邻接 (Adjacency)

顶点邻接: 如果两个顶点 u 和 v 被一条边直接连接，则称顶点 u 和 v 是邻接的。
边邻接: 如果两条边 共享 一个公共顶点，则称这两条边是邻接的。



度 (Degree)


一个顶点的度是指与该顶点关联的边的数量。  度反映了顶点与其他顶点的连接数量。


有向图的度:  对于有向图，度分为两种：

入度 (In-degree):  指向该顶点的边的数量 (有多少边进入该顶点)。
出度 (Out-degree):  从该顶点出发的边的数量 (有多少边从该顶点出发)。





路径 (Path)

图中从一个顶点到另一个顶点，依次经过的顶点和边的序列。
路径中通常不重复经过顶点，除非是环路。



环路/回路 (Cycle)

一种特殊的路径，起点和终点是同一个顶点。
环路表示从一个点出发，可以回到原点的路径。



简单路径 (Simple Path)

路径中所有顶点都不同的路径。
简单路径避免了在路径中重复访问同一个顶点。



简单环路/简单回路 (Simple Cycle)

环路中，除了起点和终点相同外，所有其他顶点都不同的环路。
简单环路是最基本的环路形式，避免了在环路中重复访问除起点/终点之外的顶点。



图的类型
有向图 vs 无向图


无向图: 边 没有方向，表示连接的两个顶点是互通的。 通常用  (v, w)  表示顶点 v 和 w 之间的无向边。


有向图: 边 有方向，表示连接的两个顶点之间是单向关系。  通常用  &lt;v, w&gt;  表示从顶点 v 指向顶点 w 的有向边。


有权图 vs 无权图


有权图: 图的每条边都被赋予一个 权重 (weight)，通常是一个数字。 权重可以代表 距离、成本、时间 等实际含义。


无权图: 图的边 没有权重。 可以理解为所有边的权重都相同（例如权重为 1）。


连通图 vs 非连通图


连通图 (针对无向图):  图中 任意两个顶点之间都存在路径。  这意味着从图中任何一个顶点出发，都可以到达其他任何顶点。


非连通图 (针对无向图):  图中 至少存在一对顶点之间没有路径。  非连通图由多个互相独立的“部分”组成。


连通分量 (Connected Component):  非连通图可以被划分成多个 连通的子图，每个这样的连通子图被称为一个 连通分量。 连通图自身只有一个连通分量，就是它本身。


强连通 vs 单连通

强连通 (Strongly Connected):  有向图 中，任意两个顶点之间都存在互相可达的路径。  即从顶点 u 可以到达 v，同时从顶点 v 也可以到达 u。
单连通 (Unilaterally Connected): 有向图 中，任意两个顶点之间都存在至少一个方向可达的路径 （无需互相可达）。  即对于任意两个顶点 u 和 v，要么从 u 可以到达 v，要么从 v 可以到达 u，或者两者都成立。

图的表示方法
邻接矩阵表示法
邻接矩阵是一个二维数组，用于表示顶点之间的连接关系：

对于无权图，矩阵元素 A[i][j] = 1 表示顶点 i 和 j 之间有边相连，A[i][j]= 0 表示没有边相连
对于有权图，矩阵元素 A[i][j]表示顶点 i 和 j 之间边的权值，通常用一个特殊值（如∞或0）表示不存在的边

优点：

实现简单，便于理解
查询两点间是否有边的时间复杂度为 O(1)
适合表示稠密图

缺点：

空间复杂度为 O(V²)，其中 V 是顶点数，对于稀疏图会浪费大量空间
添加/删除顶点的操作较为复杂

邻接表表示法
邻接表使用一个数组，数组的每个元素是一个链表，用于存储与该顶点相邻的所有顶点：

数组索引 i 对应顶点 i
链表中存储的是与顶点 i 相邻的所有顶点

优点：

节省空间，特别适合稀疏图
容易找到给定顶点的所有邻接点
添加顶点操作简单

缺点：

查询两点间是否有边的时间复杂度为 O(V)，不如邻接矩阵高效
对有向图求逆邻接表较困难

十字链表表示法
十字链表是邻接表的改进版本，主要用于有向图：

结合了邻接表和逆邻接表的特点
每个顶点有一个出边表和一个入边表
每条边用一个结点表示，同时出现在起点的出边表和终点的入边表中

优点：

容易找到顶点的所有出边和入边
适合需要频繁查询入度和出度的应用场景

邻接多重表
邻接多重表主要用于无向图：

每条边只存储一次
每个顶点有一个边表
每条边连接到与其关联的两个顶点的边表中

优点：

便于删除和查找特定边
节省空间

边集数组表示法
边集数组直接存储图中所有的边：

使用一个一维数组存储所有顶点信息
使用另一个数组存储所有边的信息（包括起点、终点和权值）

优点：

实现简单
适合只关注边的操作，如最小生成树的Kruskal算法
适合稀疏图

缺点：

查找操作效率较低
不易找到与特定顶点相连的所有边

选择哪种表示方法取决于图的特性（如稠密度）和需要执行的操作类型（如是否需要频繁查询、添加或删除顶点和边）。
图的遍历方法
DFS(深度优先搜索)
深度优先搜索沿着图的深度尽可能远地探索，直到不能再深入为止，然后回溯到前一个节点，继续探索其他路径。
基本算法步骤

选择一个起始顶点，将其标记为已访问
对该顶点的每个未访问的邻接点，递归地应用DFS
如果当前顶点没有未访问的邻接点，则回溯

时间复杂度与空间复杂度

时间复杂度：O(V + E)
空间复杂度：O(V)

应用场景

拓扑排序
寻找连通分量
判断图中是否有环
寻找路径（如迷宫问题）

BFS(广度优先搜索)
广度优先搜索是一种按&quot;层次&quot;访问节点的方法，先访问起始顶点的所有邻接点，然后再访问这些邻接点的邻接点，以此类推。
基本算法步骤

选择一个起始顶点，将其标记为已访问，并放入队列中
当队列不为空时，执行以下操作：

取出队列中的第一个顶点u
访问顶点u
将u的所有未访问过的邻接点标记为已访问并加入队列



时间复杂度与空间复杂度

时间复杂度：O(V + E)，其中V是顶点数，E是边数
空间复杂度：O(V)，用于存储访问状态和队列

应用场景

寻找最短路径（无权图）
网络爬虫
社交网络中的关系距离（如&quot;六度分隔&quot;理论）
层次遍历

图的应用
最小生成树算法
无向图 G 的生成树是具有 G 的全部顶点，但边数最少的连通子图（连通子图并非连通分量）。一个图的生成树可能有多个。
Kruskal算法


思想：贪心策略，每次选择图中权值最小的边，加入生成树中（前提是不形成环）。
步骤：

对所有边按照权值进行排序。
依次从小到大考虑每条边，如果当前边加入后不构成环，则加入生成树。
重复直到生成树中包含 n−1 条边。


特点：适合边比较少的稀疏图，利用并查集来判断是否形成环。

Prim算法

思想：贪心策略，从一个起始顶点开始，每次选择与当前生成树相连的、权值最小的边，将新的顶点加入生成树。
步骤：

从任一顶点开始，将其加入生成树。
找出所有与当前生成树相连的边，选择其中权值最小的边，将边的另一端顶点加入生成树。
重复直到所有顶点都被加入生成树。


特点：适合边较多的稠密图，通过优先队列（堆）优化可以达到较高效率。

最短路径算法
Dijkstra算法
从起点开始，每次选择当前已知最短距离的顶点，然后更新与它相邻的顶点的距离。
基本流程

初始化：源点距离设为0，其他顶点距离设为无穷大
每次选择未访问的距离最小的顶点，标记为已访问
更新该顶点的邻居顶点的距离
重复步骤2-3直到所有顶点被访问

算法复杂度

时间复杂度：O(V²)，其中V是顶点数。如果使用优先队列优化，可以降低到O((V+E)logV)，其中E是边数。
空间复杂度：O(V)

算法的局限性

迪杰斯特拉算法不能处理负权边
在稠密图中，性能可能不如其他算法（如贝尔曼-福特算法）

应用场景

导航系统
网络路由协议
社交网络分析
电信网络规划

Floyd-Warshall算法
对于两个顶点i和j之间的最短路径，考虑是否存在一个中间顶点k，使得从i到k再到j的路径比直接从i到j的路径更短。算法通过三重循环遍历所有可能的中间顶点，不断更新距离矩阵。
基本流程

初始化一个距离矩阵，矩阵中元素dist[i][j]表示从顶点i到j的直接距离。如果i和j之间没有直接连接，则设为无穷大
对于每一个顶点k，检查所有顶点对(i,j)
对于每一个顶点对(i,j)，如果dist[i][k] + dist[k][j] &lt; dist[i][j]，则更新dist[i][j]的值
重复步骤2和3，直到遍历完所有顶点

算法复杂度

时间复杂度：O(V³)，其中V是顶点数
空间复杂度：O(V²)

与迪杰斯特拉算法的比较

范围不同：迪杰斯特拉是单源最短路径算法，而弗洛伊德是全源最短路径算法
适用场景：

对于稀疏图，运行V次迪杰斯特拉算法更高效
对于稠密图，弗洛伊德算法更优


负权边处理：弗洛伊德可以处理负权边，但两者都不能处理负权环

算法优势

实现简单，代码简洁
可以处理有向图和负权边（但不能有负权环）
一次运行可以得到所有顶点对之间的最短路径

应用场景

网络路由算法
交通规划
寻找图中的传递闭包
计算最大流问题

A*算法
A*算法是一种启发式搜索算法，常用于路径规划问题。

结合了Dijkstra算法和启发式搜索的优点
使用估价函数指导搜索方向
在有好的启发函数时效率很高

基本流程

初始化：起点放入开放列表
每次从开放列表中选择f值最小的节点n
如果n是目标节点，算法结束
否则，将n移到关闭列表，并检查所有邻居节点
对于每个邻居，计算经过n的路径长度g和估计总长度f=g+h
更新邻居节点信息并加入开放列表
重复步骤2-6直到找到目标或开放列表为空

拓扑排序
拓扑排序是一种对有向无环图 (DAG, Directed Acyclic Graph) 中顶点进行线性排序的算法，使得对于图中的每一条有向边 (u, v)，顶点 u 在排序中都出现在顶点 v 之前。拓扑排序常用于表示具有依赖关系的任务调度问题。
算法原理
每次选择入度为0的顶点（即没有前驱顶点的顶点），将其输出，然后删除该顶点及其所有出边，重复此过程直到图为空或无法找到入度为0的顶点。
时间复杂度与空间复杂度

时间复杂度: O(V + E)，其中V是顶点数，E是边数
空间复杂度: O(V)，需要存储顶点的访问状态和结果

特性和局限性

唯一性: 拓扑排序的结果通常不唯一，可能有多种合法的排序方式
环检测: 如果图中存在环，则无法进行拓扑排序
适用范围: 只适用于有向无环图（DAG）
初始点要求: 至少有一个顶点的入度为0，否则无法开始排序

]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>图论</tag>
      </tags>
  </entry>
  <entry>
    <title>基于深度学习的图像分类</title>
    <url>/2025/04/%E5%9F%BA%E4%BA%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[使用ResNet18预训练模型
由于笔记本性能太差，所以在服务器上运行的，显卡配置为4090。经大量实验判断，初始学习率为0.01最后效果较差，所以初始学习率应设为0.001。全部代码代码已上传到：https://github.com/wp-a/-CIFAR10-.git
库函数导入
import matplotlib.pyplot as pltimport torchimport torch.nn as nnimport torchvisionimport torchvision.transforms as transformsfrom sklearn.metrics import confusion_matrix, classification_reportfrom itertools import chainimport multiprocessingdevice = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
数据集加载及增强操作
transform_train = transforms.Compose([    transforms.Resize(224),	#图像从32x32放大到224x224是通过在原始像素之间插入新的像素点来实现的。插入的像素值是根据周围原始像素的值，通过不同的插值算法计算出来的，默认使用双线性插值。    transforms.RandomHorizontalFlip(), #以 0.5 的概率水平随机翻转图像    transforms.RandomRotation(10),  #将图像随机旋转 -10 到 10 度之间的角度    transforms.ToTensor(),  #将图像从 PIL 图像格式转换为 PyTorch 张量    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))     #使用为三个颜色通道中的每一个提供的平均和标准差来标准化图像的像素值(归一化)])transform_test = transforms.Compose([    transforms.Resize(224),    transforms.ToTensor(),    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])# 加载CIFAR-10数据集train_set = torchvision.datasets.CIFAR10(&quot;./data&quot;, download=True, transform=transform_train)test_set = torchvision.datasets.CIFAR10(&quot;./data&quot;, download=True, train=False, transform=transform_test)batch_size = 64  train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0)classes = (&#x27;plane&#x27;, &#x27;car&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;, &#x27;deer&#x27;, &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;)#返回数字对应的类名def output_label(label):    output_mapping = &#123;        0: &quot;plane&quot;, 1: &quot;car&quot;, 2: &quot;bird&quot;, 3: &quot;cat&quot;, 4: &quot;deer&quot;,        5: &quot;dog&quot;, 6: &quot;frog&quot;, 7: &quot;horse&quot;, 8: &quot;ship&quot;, 9: &quot;truck&quot;    &#125;    input = (label.item() if type(label) == torch.Tensor else label)    return output_mapping[input]
加载预训练模型
def get_resnet18(pretrained=True):    model = torchvision.models.resnet18(pretrained=pretrained)    model.fc = nn.Linear(512, 10)  # 修改最后一层以适应CIFAR10的10个类别    return modelmodel = get_resnet18()model = model.to(device)
模型训练超参数设置
#定义损失函数，初始学习率，优化器criterion = nn.CrossEntropyLoss()learning_rate = 0.001optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#学习率调节器，前期需要较大步长来快速收敛，后期如还用较大步长可能会在极小值周围震荡，所以后期学习率逐步衰减。可以提高训练效率和性能。Adam负责在参数层面进行自适应的学习率调整，以加快收敛。学习率调度器负责在训练过程的宏观层面调整全局学习率，以提高模型的最终性能和泛化能力。二者不会产生冲突。def exp_lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_epoch=2):    lr = init_lr * (0.1 ** (epoch // lr_decay_epoch))    if epoch % lr_decay_epoch == 0:        print(f&#x27;LR is set to &#123;lr&#125;&#x27;)    for param_group in optimizer.param_groups:        param_group[&#x27;lr&#x27;] = lr    return optimizer
模型训练
num_epochs = 6count = 0loss_list = []iteration_list = []accuracy_list = []predictions_list = []labels_list = []for epoch in range(num_epochs):    model.train()     running_loss = 0.0    optimizer = exp_lr_scheduler(optimizer, epoch, init_lr=learning_rate, lr_decay_epoch=2)    for i, (images, labels) in enumerate(train_loader):        images, labels = images.to(device), labels.to(device)        outputs = model(images)        loss = criterion(outputs, labels)        optimizer.zero_grad()        loss.backward()        optimizer.step()        running_loss += loss.item()        count += 1        if (i + 1) % 50 == 0:            print(f&#x27;Epoch [&#123;epoch + 1&#125;/&#123;num_epochs&#125;], Step [&#123;i + 1&#125;/&#123;len(train_loader)&#125;], Loss: &#123;loss.item():.4f&#125;&#x27;)            model.eval()              total = 0            correct = 0            test_predictions = []            test_labels = []            with torch.no_grad():                for images, labels in test_loader:                    images, labels = images.to(device), labels.to(device)                    test_labels.extend(labels.cpu().numpy())                    outputs = model(images)                    _, predicted = torch.max(outputs.data, 1)                    test_predictions.extend(predicted.cpu().numpy())                    total += labels.size(0)                    correct += (predicted == labels).sum().item()            accuracy = 100 * correct / total            print(f&#x27;Accuracy on test set: &#123;accuracy:.2f&#125;%&#x27;)            loss_list.append(loss.item())            iteration_list.append(count)            accuracy_list.append(accuracy)            predictions_list.append(test_predictions)            labels_list.append(test_labels)            model.train()print(&#x27;Finished Training&#x27;)
实验结果保存
torch.save(model.state_dict(), &#x27;resnet18_cifar10.pth&#x27;)print(&#x27;Model saved to resnet18_cifar10.pth&#x27;)plt.figure(figsize=(10, 5))plt.plot(iteration_list, loss_list)plt.xlabel(&quot;No. of Iteration&quot;)plt.ylabel(&quot;Loss&quot;)plt.title(&quot;Iterations vs Loss&quot;)plt.savefig(&#x27;loss_curve.png&#x27;)plt.show()plt.figure(figsize=(10, 5))plt.plot(iteration_list, accuracy_list)plt.xlabel(&quot;No. of Iteration&quot;)plt.ylabel(&quot;Accuracy&quot;)plt.title(&quot;Iterations vs Accuracy&quot;)plt.savefig(&#x27;accuracy_curve.png&#x27;)plt.show()class_correct = [0. for _ in range(10)]total_correct = [0. for _ in range(10)]model.eval()with torch.no_grad():    for images, labels in test_loader:        images, labels = images.to(device), labels.to(device)        outputs = model(images)        _, predicted = torch.max(outputs, 1)        c = (predicted == labels).squeeze()        for i in range(labels.size(0)):            label = labels[i]            class_correct[label] += c[i].item()            total_correct[label] += 1for i in range(10):    print(f&quot;Accuracy of &#123;classes[i]&#125;: &#123;100 * class_correct[i] / total_correct[i]:.2f&#125;%&quot;)flat_predictions = list(chain.from_iterable(predictions_list))flat_labels = list(chain.from_iterable(labels_list))cm = confusion_matrix(flat_labels, flat_predictions)print(&quot;Confusion Matrix:&quot;)print(cm)print(&quot;Classification report for ResNet on CIFAR-10:&quot;)print(classification_report(flat_labels, flat_predictions, target_names=classes))
实验结果分析
lr分析
由实验结果可得lr=0.01时，效果较差，所以直接设置初始学习率为0.001可以更节省时间，提高效率。当学习率为1e-6时，发现准确率更新较小，所以准确率最小设置为1e-6。即学习率梯度为1e-3,1e-4,1e-5,1e-6，可以有较好的效果。即令epoch / lr_decay_epoch = 3或4 都可以，具体以epoch大小为准。
lr=0.01

lr=0.001

lr=1e6

batchsize分析
Batchsize：64    epoch：6      lr_decay_epoch：2      初始学习率为0.001       94.46%




Batchsize：128       epoch：12      lr_decay_epoch：3        初始学习率为0.001     95.23%




Batchsize：128    epoch：20      lr_decay_epoch：5       初始学习率为0.01        85.87%
和分析的一致，对比下面实验，控制变量，只有初始学习率改变，精度提升10%左右。




Batchsize：128    epoch：20      lr_decay_epoch：5       初始学习率为0.001        95.44%




Batchsize：64      epoch：20      lr_decay_epoch：5       初始学习率为0.001        95.66%




使用LeNet网络
与Resnet相比换了一个网络和改了数据加载模块，其他没啥变化。
库函数导入
import matplotlib.pyplot as pltimport torchimport torch.nn as nnimport torchvisionimport torchvision.transforms as transformsfrom sklearn.metrics import confusion_matrix, classification_reportfrom itertools import chainimport multiprocessingdevice = torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
数据集加载及增强操作
transform = transforms.Compose(        [transforms.RandomHorizontalFlip(),         transforms.RandomCrop(32, padding=4),         transforms.ToTensor(),         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])trainset = torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;, train=True,                                            download=True, transform=transform)train_loader = torch.utils.data.DataLoader(trainset, batch_size=32,                                              shuffle=True, num_workers=2)testset = torchvision.datasets.CIFAR10(root=&#x27;./data&#x27;, train=False,                                           download=True, transform=transform)test_loader = torch.utils.data.DataLoader(testset, batch_size=32,                                             shuffle=False, num_workers=2)classes = (&#x27;plane&#x27;, &#x27;car&#x27;, &#x27;bird&#x27;, &#x27;cat&#x27;, &#x27;deer&#x27;, &#x27;dog&#x27;, &#x27;frog&#x27;, &#x27;horse&#x27;, &#x27;ship&#x27;, &#x27;truck&#x27;)def output_label(label):    output_mapping = &#123;        0: &quot;plane&quot;, 1: &quot;car&quot;, 2: &quot;bird&quot;, 3: &quot;cat&quot;, 4: &quot;deer&quot;,        5: &quot;dog&quot;, 6: &quot;frog&quot;, 7: &quot;horse&quot;, 8: &quot;ship&quot;, 9: &quot;truck&quot;    &#125;    input = (label.item() if type(label) == torch.Tensor else label)    return output_mapping[input]
LeNet模型
class C1(nn.Module):    def __init__(self):        super(C1, self).__init__()        self.c1 = nn.Sequential(OrderedDict([            (&#x27;conv1&#x27;, nn.Conv2d(3, 6, kernel_size=(5, 5))),            (&#x27;relu1&#x27;, nn.ReLU()),            (&#x27;pool1&#x27;, nn.MaxPool2d(kernel_size=(2, 2), stride=2))        ]))    def forward(self, img):        output = self.c1(img)        return outputclass C3(nn.Module):    def __init__(self):        super(C3, self).__init__()        self.c3 = nn.Sequential(OrderedDict([            (&#x27;conv3&#x27;, nn.Conv2d(6, 16, kernel_size=(5, 5))),            (&#x27;relu3&#x27;, nn.ReLU()),            (&#x27;pool3&#x27;, nn.MaxPool2d(kernel_size=(2, 2), stride=2))        ]))    def forward(self, img):        output = self.c3(img)        return outputclass F4(nn.Module):    def __init__(self):        super(F4, self).__init__()        self.f4 = nn.Sequential(OrderedDict([            (&#x27;fc4&#x27;, nn.Linear(16 * 5 * 5, 120)),            (&#x27;relu4&#x27;, nn.ReLU())        ]))    def forward(self, img):        output = self.f4(img)        return outputclass F5(nn.Module):    def __init__(self):        super(F5, self).__init__()        self.f5 = nn.Sequential(OrderedDict([            (&#x27;fc5&#x27;, nn.Linear(120, 84)),            (&#x27;relu5&#x27;, nn.ReLU())        ]))    def forward(self, img):        output = self.f5(img)        return outputclass F6(nn.Module):    def __init__(self):        super(F6, self).__init__()        self.f6 = nn.Sequential(OrderedDict([            (&#x27;fc6&#x27;, nn.Linear(84, 10))        ]))    def forward(self, img):        output = self.f6(img)        return outputclass LeNet5(nn.Module):    def __init__(self):        super(LeNet5, self).__init__()        self.c1 = C1()        self.c3 = C3()        self.f4 = F4()        self.f5 = F5()        self.f6 = F6()    def forward(self, img):        output = self.c1(img)        output = self.c3(output)        output = output.view(-1, 16 * 5 * 5)        output = self.f4(output)        output = self.f5(output)        output = self.f6(output)        return output
模型训练超参数设置
#定义损失函数，初始学习率，优化器criterion = nn.CrossEntropyLoss()learning_rate = 0.001optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)#学习率调节器，前期需要较大步长来快速收敛，后期如还用较大步长可能会在极小值周围震荡，所以后期学习率逐步衰减。可以提高训练效率和性能。def exp_lr_scheduler(optimizer, epoch, init_lr=0.001, lr_decay_epoch=2):    lr = init_lr * (0.1 ** (epoch // lr_decay_epoch))    if epoch % lr_decay_epoch == 0:        print(f&#x27;LR is set to &#123;lr&#125;&#x27;)    for param_group in optimizer.param_groups:        param_group[&#x27;lr&#x27;] = lr    return optimizer
模型训练
num_epochs = 20count = 0loss_list = []iteration_list = []accuracy_list = []predictions_list = []labels_list = []for epoch in range(num_epochs):    model.train()     running_loss = 0.0    optimizer = exp_lr_scheduler(optimizer, epoch, init_lr=learning_rate, lr_decay_epoch=2)    for i, (images, labels) in enumerate(train_loader):        images, labels = images.to(device), labels.to(device)        outputs = model(images)        loss = criterion(outputs, labels)        optimizer.zero_grad()        loss.backward()        optimizer.step()        running_loss += loss.item()        count += 1        if (i + 1) % 50 == 0:            print(f&#x27;Epoch [&#123;epoch + 1&#125;/&#123;num_epochs&#125;], Step [&#123;i + 1&#125;/&#123;len(train_loader)&#125;], Loss: &#123;loss.item():.4f&#125;&#x27;)            model.eval()             total = 0            correct = 0            test_predictions = []            test_labels = []            with torch.no_grad():                for images, labels in test_loader:                    images, labels = images.to(device), labels.to(device)                    test_labels.extend(labels.cpu().numpy())                    outputs = model(images)                    _, predicted = torch.max(outputs.data, 1)                    test_predictions.extend(predicted.cpu().numpy())                    total += labels.size(0)                    correct += (predicted == labels).sum().item()            accuracy = 100 * correct / total            print(f&#x27;Accuracy on test set: &#123;accuracy:.2f&#125;%&#x27;)            loss_list.append(loss.item())            iteration_list.append(count)            accuracy_list.append(accuracy)            predictions_list.append(test_predictions)            labels_list.append(test_labels)            model.train()print(&#x27;Finished Training&#x27;)
实验结果保存
torch.save(model.state_dict(), &#x27;lenet5_cifar10.pth&#x27;) print(&#x27;Model saved to lenet5_cifar10.pth&#x27;)plt.figure(figsize=(10, 5))plt.plot(iteration_list, loss_list)plt.xlabel(&quot;No. of Iteration&quot;)plt.ylabel(&quot;Loss&quot;)plt.title(&quot;Iterations vs Loss&quot;)plt.savefig(&#x27;loss_curve.png&#x27;)plt.show()plt.figure(figsize=(10, 5))plt.plot(iteration_list, accuracy_list)plt.xlabel(&quot;No. of Iteration&quot;)plt.ylabel(&quot;Accuracy&quot;)plt.title(&quot;Iterations vs Accuracy&quot;)plt.savefig(&#x27;accuracy_curve.png&#x27;)plt.show()class_correct = [0. for _ in range(10)]total_correct = [0. for _ in range(10)]model.eval()with torch.no_grad():    for images, labels in test_loader:        images, labels = images.to(device), labels.to(device)        outputs = model(images)        _, predicted = torch.max(outputs, 1)        c = (predicted == labels).squeeze()        for i in range(labels.size(0)):            label = labels[i]            class_correct[label] += c[i].item()            total_correct[label] += 1for i in range(10):    print(f&quot;Accuracy of &#123;classes[i]&#125;: &#123;100 * class_correct[i] / total_correct[i]:.2f&#125;%&quot;)flat_predictions = list(chain.from_iterable(predictions_list))flat_labels = list(chain.from_iterable(labels_list))cm = confusion_matrix(flat_labels, flat_predictions)print(&quot;Confusion Matrix:&quot;)print(cm)print(&quot;Classification report for LeNet on CIFAR-10:&quot;) print(classification_report(flat_labels, flat_predictions, target_names=classes))
实验结果分析
使用图像增强操作
Batchsize：128      epoch：20      lr_decay_epoch：5     初始学习率为 0.001       60.56%




未使用图像增强操作
Batchsize：128      epoch：20      lr_decay_epoch：5     初始学习率为 0.001       62.66%




使用FashionNet
代码详见github
图像增强操作训练结果分析
使用图像增强操作
Batchsize：128      epoch：20      lr_decay_epoch：5     初始学习率为 0.001        71.51%


未使用图像增强操作
Batchsize：128      epoch：30      lr_decay_epoch：6     初始学习率为 0.01        71.69%




Batchsize：128      epoch：20      lr_decay_epoch：5     初始学习率为 0.001        74.25%




Gradcam实现图像特征可视化
Grad-CAM 的目标层均为最后一个卷积层
Resnet效果图
参数配置    Batch_size：64    epoch：20      lr_decay_epoch：5     lr：0.001      95.66%
图片来自谷歌。
  
      
FashionNet效果图
参数配置      Bachsize：128      epoch：20      lr_decay_epoch：5     初始学习率为 0.001        74.25%
  
      
LeNet效果图
参数配置      Bachsize：128      epoch：20      lr_decay_epoch：5     初始学习率为 0.001       60.56%
  
      
总结
数据集在不同模型上的准确率



模型
准确率




ResNet
95.66%


LeNet
62.66%


FashionNet
74.25%



LeNet对数据集进行图像增强操作的影响
分析：由于模型过于简单，本来就会出现欠拟合现象，继续进行图像增强操作后会导致模型更加欠拟合。所以出现三个模型精度差距较大，主要是因为模型复杂度的差距。虽然是欠拟合，但是继续增加epoch也并不会提高精度，因为模型对数据已经学到了尽可能多的知识。



未归一化
归一化
图像增强操作
大量图像增强操作




58.75%
62.66%
60.56%
56.78%



神经网络参数对模型准确率的影响
batch_size：64或128并无太大影响。
初始学习率：由实验结果可得lr=0.01时，效果较差，三个网络都使用了0.01进行测试得出的结果，有的实验结果没贴图。所以直接设置初始学习率为0.001可以更节省时间，提高效率。当学习率为1e-6时，发现准确率更新较小，所以准确率最小设置为1e-6。即学习率梯度为1e-3,1e-4,1e-5,1e-6，可以有较好的效果。
lr_decay_epoch和epoch：即学习率梯度为1e-3,1e-4,1e-5,1e-6，可以有较好的效果。即令epoch / lr_decay_epoch = 3或4 都可以，具体以epoch大小为准。
]]></content>
      <categories>
        <category>手撕代码</category>
        <category>图像分类</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>图像分类</tag>
        <tag>Resnet</tag>
        <tag>Lenet</tag>
        <tag>CIFAR10</tag>
      </tags>
  </entry>
  <entry>
    <title>实例判别学习 - Non-Parametric Instance Discrimination精读</title>
    <url>/2025/11/%E5%AE%9E%E4%BE%8B%E5%88%A4%E5%88%AB%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[Unsupervised Feature Learning via Non-Parametric Instance Discrimination
论文地址：https://arxiv.org/pdf/1805.01978
代码地址：https://github.com/zhirongw/lemniscate.pytorch
引言
实例判别（Instance Discrimination） 是2018年提出的一种无监督特征学习方法，它将对比学习的思想推向极致：将每个图像实例视为一个独立的类别，通过区分不同实例来学习特征表示。这篇论文是MoCo、SimCLR等现代对比学习方法的重要先驱工作。
论文的核心洞察来自对监督学习的观察：在ImageNet上训练的神经网络，即使没有显式指导，也能自动发现视觉上相似的类别（如leopard和jaguar）之间的关联。作者将这一观察延伸到实例级别：如果能够区分每个实例，那么学习到的特征应该能够捕获实例间的视觉相似性。
实例判别的核心创新
将无监督问题转化为监督问题：
实例判别的天才之处在于一个简单的转换：

传统无监督学习：没有标签，难以定义学习目标
实例判别：每个图像就是自己的标签，变成N分类问题
好处：可以直接使用成熟的分类框架和技术

为什么这种方法有效？


视觉相似性的自然涌现

虽然每个实例是独立类别，但视觉相似的实例会在特征空间聚集
原因：它们共享底层视觉模式（边缘、纹理、形状等）
结果：学到的特征捕获了语义信息



信息论的解释

区分N个实例需要log(N)比特信息
模型被迫学习最有效的编码
这种编码自然对应于语义特征



避免平凡解

不能简单记住每个实例（泛化要求）
必须学习可迁移的特征
数据增强强制学习不变性



技术挑战与解决方案
挑战1：计算Softmax的分母
当有百万级实例时，计算softmax分母需要遍历所有实例，计算成本巨大。
解决方案：NCE近似
原始softmax概率：P(i|v) = exp(v·f_i) / Σ_j exp(v·f_j)NCE近似：将其转化为二分类问题（实例i vs 噪声）
挑战2：存储所有实例的特征
需要存储所有训练图像的特征表示，内存需求大。
解决方案：Memory Bank

使用动量更新：新特征 = m×旧特征 + (1-m)×当前特征
好处：平滑特征变化，提高训练稳定性
内存需求：128维×100万实例 ≈ 500MB（可接受）

挑战3：负样本采样
从百万实例中采样负样本，如何保证采样质量？
解决方案：Proximal Regularization

不是随机采样，而是基于特征相似度
优先采样相似但不同的实例（困难负样本）
提高学习效率

核心思想
基本动机
关键观察：

监督学习中，模型会自动学习到视觉相似类别之间的关联
这种相似性不是来自语义标注，而是来自视觉数据本身
如果将类别级别的监督推向实例级别，能否学到更好的表示？

核心假设：

每个图像实例本身就是一个独特的&quot;类别&quot;
通过区分不同实例，模型会学习到捕获视觉相似性的特征
视觉相似的实例在特征空间中应该更接近

方法概述
将无监督学习问题转化为实例级别的分类问题：

每个训练图像是一个独立的类别
使用非参数softmax进行分类
使用NCE（Noise-Contrastive Estimation）解决计算问题

方法详解
非参数Softmax分类器
参数化Softmax的问题
传统的参数化softmax：
$$
P(i|v) = \frac{\exp(w_i^T v)}{\sum_{j=1}^{n} \exp(w_j^T v)}
$$
其中 $w_j$ 是类别 $j$ 的权重向量。
问题：

权重向量 $w_j$ 只对训练类别有效，无法泛化到新实例
权重向量作为类别原型，阻止了实例间的直接比较
需要存储和更新大量权重参数

非参数Softmax
将权重向量 $w_j$ 替换为特征向量 $v_j$：
$$
P(i|v) = \frac{\exp(v_i^T v / \tau)}{\sum_{j=1}^{n} \exp(v_j^T v / \tau)}
$$
其中：

$v_i, v_j$ 是归一化后的特征向量（$||v|| = 1$）
$\tau$ 是温度参数，控制分布的尖锐程度

优势：

直接比较实例：特征向量直接作为&quot;类别原型&quot;
泛化能力强：学习到的特征可以应用到任何新实例
计算高效：无需存储和更新权重参数
训练测试一致：训练和测试都使用相同的度量空间

Memory Bank机制
问题：计算 $P(i|v)$ 需要所有实例的特征 ${v_j}$，但每次迭代只更新当前batch的特征。
解决方案：维护一个Memory Bank $V = {v_j}$ 存储所有实例的特征。
更新策略：

初始化：Memory Bank中的特征初始化为随机单位向量
更新：每次迭代后，将当前batch的特征更新到Memory Bank
使用：计算损失时，从Memory Bank中读取特征

优势：

避免每次重新计算所有特征
保持特征的历史信息
计算效率高

Noise-Contrastive Estimation (NCE)
问题：当实例数量 $n$ 很大（如ImageNet的1.2M）时，计算完整的softmax不可行。
解决方案：使用NCE将多类分类问题转化为二分类问题。
NCE原理
将问题转化为：区分数据样本和噪声样本。
定义：

数据分布：$P_d(i\mid v) = \frac{\exp(v_i^\top v / \tau)}{Z_i}$，其中 $Z_i = \sum_{j=1}^{n} \exp(v_j^\top v / \tau)$
噪声分布：$P_n(i) = 1/n$（均匀分布）
噪声样本频率：$m$ 倍于数据样本

后验概率：
$$ 
h(i, v) = P(D=1\mid i, v) = \frac{P_d(i\mid v)}{P_d(i\mid v) + m \cdot P_n(i)}
$$ 
损失函数：
$$ 
\mathcal{L}_{\text{NCE}}(\theta) = -\mathbb{E}_{(i,v)\sim P_d}[\log h(i, v)] - m \cdot \mathbb{E}_{(i,v')\sim P_n}[\log\big(1 - h(i, v')\big)]
$$ 
归一化常数估计
计算 $Z_i$ 仍然昂贵，使用蒙特卡洛估计：
$$ 
Z_i \approx \frac{n}{m} \sum_{k=1}^{m} \exp\big(v_{j_k}^\top v / \tau\big)
$$ 
其中 ${j_k}$ 是随机采样的索引。
复杂度：从 $O(n)$ 降低到 $O(1)$ 每个样本。
Proximal Regularization（近端正则化）
问题：每个&quot;类别&quot;只有一个实例，每个epoch每个类别只访问一次，训练过程振荡严重。
解决方案：引入近端正则化项，鼓励训练过程的平滑性。
正则化项：
$$ 
\lambda \big\lVert v_i^{(t)} - v_i^{(t-1)} \big\rVert_2^2
$$ 
其中：

$v_i^{(t)}$ 是当前迭代的特征
$v_i^{(t-1)}$ 是Memory Bank中存储的特征（上一迭代）

完整损失：
$$ 
\mathcal{L}_{\text{NCE}}(\theta) = -\mathbb{E}_{(i,v)\sim P_d}\Big[\log h\big(i, v_i^{(t-1)}\big) - \lambda \big\lVert v_i^{(t)} - v_i^{(t-1)} \big\rVert_2^2\Big] - m \cdot \mathbb{E}_{(i,v')\sim P_n}\Big[\log\big(1 - h(i, v'^{(t-1)})\big)\Big]
$$ 
加权k-NN分类器
测试时分类：

计算特征：$\hat{f} = f_\theta(\hat{x})$
相似度计算：$s_i = \cos(v_i, \hat{f})$
k-NN检索：找到top-k最近邻 $N_k$
加权投票：类别 $c$ 的权重为
$$
w_c = \sum_{i \in N_k} \alpha_i \cdot \mathbf{1}(c_i = c)
$$
其中 $\alpha_i = \exp(s_i / \tau)$

参数设置：

$k = 200$
$\tau = 0.07$（与训练时相同）

实验分析
参数化 vs 非参数化Softmax
在CIFAR-10上的对比实验：



方法
Linear SVM
k-NN




参数化Softmax
60.3%
63.0%


非参数化Softmax
75.4%
80.8%



关键发现：

非参数化方法显著优于参数化方法（+18%）
k-NN性能接近线性SVM，说明学习到的特征度量质量高

NCE近似质量
不同负样本数量 $m$ 的影响：



m
k-NN Accuracy




1
42.5%


10
63.4%


512
78.4%


4096
80.4%



结论：随着 $m$ 增加，NCE近似质量提升，$m=4096$ 时接近完整softmax。
ImageNet分类结果
不同网络架构的性能：



方法
conv5 (Linear)
k-NN
特征维度




Random
14.1%
3.5%
10K


Split-Brain
35.2%
11.8%
10K


Ours (AlexNet)
35.6%
31.3%
128


Ours (VGG16)
39.2%
33.9%
128


Ours (ResNet-18)
44.5%
41.0%
128


Ours (ResNet-50)
54.0%
46.5%
128



关键发现：

显著超越SOTA：在ImageNet上大幅超越之前的方法
网络深度优势：从AlexNet到ResNet-50，性能持续提升
紧凑表示：仅用128维特征就达到优异性能
存储高效：1.28M图像的特征仅需600MB存储

特征泛化能力
在Places数据集上的零样本评估（使用ImageNet训练的特征）：



方法
ResNet-50 (conv5)
ResNet-50 (k-NN)




Ours
45.5%
41.6%



结论：学习到的特征具有良好的跨数据集泛化能力。
训练目标与测试目标的一致性
关键观察：

训练损失持续下降
测试准确率同步提升
无过拟合迹象

意义：说明训练目标（实例判别）与测试目标（语义分类）是一致的，学习到的特征确实捕获了视觉相似性。
消融实验
特征维度：



维度
Top-1 Accuracy




32
34.0%


64
38.8%


128
41.0%


256
40.1%



结论：128维是最优选择，性能在128维达到峰值。
训练数据量：



数据比例
Accuracy




0.1%
3.9%


1%
10.7%


10%
23.1%


30%
31.7%


100%
41.0%



结论：性能随训练数据量增加而持续提升，说明方法具有良好的可扩展性。
半监督学习
使用不同比例的标注数据进行微调：



标注比例
Ours (ResNet)
Scratch (ResNet)
Split-Brain (AlexNet)




1%
48.0%
38.0%
35.0%


2%
57.0%
46.0%
42.0%


4%
63.0%
54.0%
50.0%


10%
70.0%
65.0%
62.0%


20%
75.0%
72.0%
70.0%



结论：在少样本场景下优势明显，1%标注数据时领先10%。
目标检测
在PASCAL VOC 2007上的检测性能：



方法
AlexNet
VGG16
ResNet-50




Supervised
56.8%
67.3%
76.2%


Ours
48.1%
60.5%
65.4%



结论：在检测任务上达到无监督方法的SOTA，且随网络加深性能提升。
代码实现
核心损失函数实现
import torchimport torch.nn as nnimport torch.nn.functional as Fclass InstanceDiscriminationLoss(nn.Module):    &quot;&quot;&quot;实例判别损失（使用NCE近似）&quot;&quot;&quot;        def __init__(self, memory_bank, temperature=0.07, m=4096, lambda_reg=10.0):        super().__init__()        self.memory_bank = memory_bank  # [n, dim] 所有实例的特征        self.temperature = temperature        self.m = m  # 负样本数量        self.lambda_reg = lambda_reg  # 正则化系数        def forward(self, features, indices, memory_bank_prev):        &quot;&quot;&quot;        Args:            features: [batch_size, dim] 当前batch的特征            indices: [batch_size] 当前batch的实例索引            memory_bank_prev: [batch_size, dim] Memory Bank中的特征（上一迭代）        &quot;&quot;&quot;        batch_size = features.size(0)        device = features.device                # L2归一化        features = F.normalize(features, p=2, dim=1)                # 从Memory Bank获取正样本特征        pos_features = memory_bank_prev  # [batch_size, dim]                # 随机采样负样本        neg_indices = torch.randint(0, len(self.memory_bank), (batch_size, self.m), device=device)        neg_features = self.memory_bank[neg_indices]  # [batch_size, m, dim]                # 计算相似度        pos_sim = torch.sum(features * pos_features, dim=1, keepdim=True) / self.temperature  # [batch_size, 1]        neg_sim = torch.bmm(            features.unsqueeze(1),  # [batch_size, 1, dim]            neg_features.transpose(1, 2)  # [batch_size, dim, m]        ) / self.temperature  # [batch_size, 1, m]                # 估计归一化常数（蒙特卡洛）        Z_approx = (len(self.memory_bank) / self.m) * torch.sum(torch.exp(neg_sim), dim=2)  # [batch_size, 1]                # 计算概率        pos_prob = torch.exp(pos_sim) / (torch.exp(pos_sim) + self.m * (1.0 / len(self.memory_bank)) * Z_approx)                # NCE损失        nce_loss = -torch.mean(torch.log(pos_prob + 1e-8))                # 近端正则化        reg_loss = self.lambda_reg * torch.mean(torch.sum((features - memory_bank_prev) ** 2, dim=1))                total_loss = nce_loss + reg_loss                return total_loss, nce_loss, reg_loss
完整训练流程
import torchimport torch.optim as optimfrom torch.utils.data import DataLoaderclass InstanceDiscriminationTrainer:    def __init__(self, model, memory_bank, dataset_size, temperature=0.07, m=4096):        self.model = model        self.memory_bank = memory_bank  # 初始化为随机单位向量        self.temperature = temperature        self.m = m                # 初始化Memory Bank        self.memory_bank.data = F.normalize(            torch.randn(dataset_size, 128), p=2, dim=1        )        def train_epoch(self, dataloader, optimizer, criterion):        self.model.train()        total_loss = 0                for batch_idx, (images, indices) in enumerate(dataloader):            # 前向传播            features = self.model(images)  # [batch_size, 128]                        # 从Memory Bank获取上一迭代的特征            memory_bank_prev = self.memory_bank[indices].clone()                        # 计算损失            loss, nce_loss, reg_loss = criterion(                features, indices, memory_bank_prev            )                        # 反向传播            optimizer.zero_grad()            loss.backward()            optimizer.step()                        # 更新Memory Bank（动量更新）            with torch.no_grad():                self.memory_bank[indices] = F.normalize(features, p=2, dim=1)                        total_loss += loss.item()                        if batch_idx % 100 == 0:                print(f&#x27;Batch &#123;batch_idx&#125;, Loss: &#123;loss.item():.4f&#125;, &#x27;                      f&#x27;NCE: &#123;nce_loss.item():.4f&#125;, Reg: &#123;reg_loss.item():.4f&#125;&#x27;)                return total_loss / len(dataloader)
k-NN分类器实现
def knn_classify(query_features, memory_bank, memory_labels, k=200, temperature=0.07):    &quot;&quot;&quot;    使用k-NN对查询特征进行分类        Args:        query_features: [n_query, dim] 查询特征        memory_bank: [n_memory, dim] Memory Bank中的特征        memory_labels: [n_memory] Memory Bank中的标签        k: 最近邻数量        temperature: 温度参数    &quot;&quot;&quot;    # 计算相似度矩阵    similarity = torch.mm(        F.normalize(query_features, p=2, dim=1),        F.normalize(memory_bank, p=2, dim=1).t()    )  # [n_query, n_memory]        # 找到top-k最近邻    _, topk_indices = torch.topk(similarity, k, dim=1)  # [n_query, k]    topk_similarities = torch.gather(similarity, 1, topk_indices)  # [n_query, k]    topk_labels = memory_labels[topk_indices]  # [n_query, k]        # 加权投票    weights = torch.exp(topk_similarities / temperature)  # [n_query, k]        # 对每个类别求和权重    num_classes = memory_labels.max().item() + 1    class_weights = torch.zeros(query_features.size(0), num_classes, device=query_features.device)        for c in range(num_classes):        mask = (topk_labels == c)  # [n_query, k]        class_weights[:, c] = (weights * mask.float()).sum(dim=1)        # 预测类别    predictions = class_weights.argmax(dim=1)        return predictions
技术细节
Memory Bank更新策略
选项1：直接替换
memory_bank[indices] = features
选项2：动量更新
memory_bank[indices] = momentum * memory_bank[indices] + (1 - momentum) * features
选项3：仅在训练时更新

训练时：每次迭代更新
测试时：固定不变

温度参数选择

典型值：0.07（与SimCLR、MoCo相同）
调优范围：0.05 - 0.15
影响：控制softmax分布的尖锐程度

NCE负样本数量

最小值：$m = 1$（性能较差）
推荐值：$m = 4096$（性能接近完整softmax）
权衡：$m$ 越大，性能越好，但计算成本也越高

近端正则化系数

典型值：$\lambda = 10.0$
作用：稳定训练，加速收敛
调优：根据训练稳定性调整

优缺点分析
优点

概念简单：将无监督学习转化为实例分类问题
非参数化：特征直接作为&quot;类别原型&quot;，泛化能力强
存储高效：128维特征，1M图像仅需600MB
可扩展性好：性能随数据和网络深度提升
训练测试一致：都使用相同的度量空间

缺点

计算成本：需要大量负样本（NCE）
Memory Bank维护：需要存储所有实例的特征
更新延迟：Memory Bank更新有延迟，可能影响性能
对数据增强依赖：需要合理的数据增强策略

与后续工作的关系
对MoCo的启发

Memory Bank → 队列：MoCo用队列替代Memory Bank
直接更新 → 动量更新：MoCo使用动量编码器
一致性保证：两者都关注特征的一致性

对SimCLR的启发

实例判别思想：SimCLR也使用实例判别
端到端训练：SimCLR去除了Memory Bank，使用大batch
数据增强重要性：SimCLR强调了数据增强的关键作用

对SupCon的启发

监督信号融入：SupCon将标签信息融入对比学习
同类样本作为正样本：SupCon扩展了正样本的定义

总结
实例判别学习通过将每个图像实例视为独立类别，使用非参数softmax和NCE来学习特征表示。其核心贡献包括：

非参数化设计：特征直接作为类别原型，泛化能力强
NCE近似：解决了大规模实例分类的计算问题
Memory Bank机制：高效存储和更新所有实例的特征
近端正则化：稳定训练过程

虽然后续的MoCo、SimCLR等方法在实现上更加优雅，但实例判别学习奠定了对比学习的基础思想，是这一领域的重要里程碑。
参考文献


Wu, Z., Xiong, Y., Yu, S. X., &amp; Lin, D. (2018). Unsupervised feature learning via non-parametric instance discrimination. CVPR 2018. https://arxiv.org/pdf/1805.01978


Gutmann, M., &amp; Hyvärinen, A. (2010). Noise-contrastive estimation: A new estimation principle for unnormalized statistical models. AISTATS 2010.


He, K., et al. (2020). Momentum Contrast for Unsupervised Visual Representation Learning. CVPR 2020.


Chen, T., et al. (2020). A Simple Framework for Contrastive Learning of Visual Representations. ICML 2020.


思考题

为什么非参数softmax比参数化softmax更适合实例判别任务？
NCE如何将多类分类问题转化为二分类问题？为什么这样有效？
Memory Bank机制的优势和局限性是什么？与MoCo的队列机制有何区别？
近端正则化为什么能稳定训练？其背后的数学原理是什么？
实例判别学习与后续的MoCo、SimCLR在思想上有何联系和区别？
为什么k-NN分类器在测试时表现良好？这说明了什么？

思考题答案
1. 为什么非参数softmax比参数化softmax更适合实例判别任务？
参数化softmax的问题：

泛化能力弱：权重向量 $w_j$ 只对训练实例有效，无法应用到新实例
阻止直接比较：权重向量作为&quot;类别原型&quot;，阻止了实例特征间的直接比较
参数冗余：需要为每个实例存储一个权重向量，参数量大

非参数softmax的优势：

直接比较实例：特征向量 $v_j$ 直接作为&quot;类别原型&quot;，允许实例间的直接比较
泛化能力强：学习到的特征可以应用到任何新实例
参数高效：无需存储权重参数，只需存储特征
训练测试一致：训练和测试都使用相同的特征度量空间

实验验证：在CIFAR-10上，非参数方法比参数方法性能提升18%，证明了其优势。
2. NCE如何将多类分类问题转化为二分类问题？为什么这样有效？
转化过程：

原始问题：区分 $n$ 个类别（实例），需要计算所有类别的概率
NCE转化：将问题转化为&quot;区分数据样本和噪声样本&quot;的二分类问题
后验概率：
$$
h(i, v) = \frac{P_d(i\mid v)}{P_d(i\mid v) + m \cdot P_n(i)}
$$
其中 $P_d$ 是数据分布，$P_n$ 是噪声分布（均匀分布）

为什么有效：

计算效率：从 $O(n)$ 降低到 $O(1)$ 每个样本
近似质量：当负样本数量 $m$ 足够大时，近似质量接近完整softmax
理论基础：NCE有坚实的理论保证，是unnormalized模型的标准估计方法
实践验证：实验表明 $m=4096$ 时性能接近完整softmax

关键洞察：不需要计算所有类别的概率，只需要区分&quot;是正样本&quot;还是&quot;是噪声样本&quot;。
3. Memory Bank机制的优势和局限性是什么？与MoCo的队列机制有何区别？
Memory Bank的优势：

存储所有特征：可以访问训练集中所有实例的特征
计算高效：避免每次重新计算所有特征
历史信息：保留特征的历史状态

Memory Bank的局限性：

更新延迟：特征更新有延迟（使用上一迭代的特征）
内存需求：需要存储所有实例的特征
一致性挑战：特征可能因为编码器变化而变得不一致

与MoCo队列的区别：



特性
Memory Bank
MoCo队列




大小
所有训练实例
固定大小（如65536）


更新
直接替换
FIFO（先进先出）


一致性
可能不一致
通过动量编码器保证


存储
所有实例
仅最近batch的特征



MoCo的改进：

使用动量编码器保证Key的一致性
队列大小固定，内存可控
FIFO更新保证队列中的特征相对新鲜

4. 近端正则化为什么能稳定训练？其背后的数学原理是什么？
问题背景：

每个&quot;类别&quot;只有一个实例
每个epoch每个类别只访问一次
随机采样导致训练过程振荡严重

近端正则化的作用：

平滑性约束：鼓励当前特征 $v_i^{(t)}$ 与上一迭代特征 $v_i^{(t-1)}$ 接近
减少振荡：防止特征因为随机采样而剧烈变化
稳定梯度：使梯度更新更加平滑

数学原理：
近端正则化项：
$$
\lambda \big\lVert v_i^{(t)} - v_i^{(t-1)} \big\rVert_2^2
$$
这等价于在优化问题中加入平滑性约束：

当 $\lambda \to 0$：退化为原始损失
当 $\lambda \to \infty$：强制 $v_i^{(t)} = v_i^{(t-1)}$（不更新）

优化视角：
近端正则化是近端梯度方法的应用，用于优化非光滑或约束优化问题。在这里，它起到了稳定化的作用。
实验验证：图3显示，加入正则化后训练损失曲线更平滑，收敛更快。
5. 实例判别学习与后续的MoCo、SimCLR在思想上有何联系和区别？
共同思想：

实例判别：都将每个实例视为独立类别
对比学习：通过区分正负样本来学习特征
特征归一化：都使用L2归一化
温度参数：都使用温度缩放

主要区别：



特性
Instance Discrimination
MoCo
SimCLR




负样本来源
Memory Bank
队列
当前batch


特征更新
延迟更新
动量更新
实时更新


计算方式
NCE近似
完整softmax
完整softmax


batch size
小（256）
中等（1024）
大（≥4096）


实现复杂度
中等
较高
较低



演进关系：

Instance Discrimination：提出非参数softmax和Memory Bank
MoCo：改进Memory Bank为队列，引入动量编码器
SimCLR：去除Memory Bank，使用大batch和端到端训练

核心改进：

MoCo解决了Memory Bank的一致性问题
SimCLR简化了实现，但需要更多计算资源

6. 为什么k-NN分类器在测试时表现良好？这说明了什么？
k-NN表现良好的原因：

训练测试一致：训练和测试都使用相同的特征度量空间
非参数化设计：特征直接作为&quot;类别原型&quot;，适合k-NN
度量质量高：学习到的特征确实捕获了视觉相似性

实验证据：

在ImageNet上，k-NN准确率（46.5%）接近线性SVM（54.0%）
说明学习到的特征度量质量很高

深层含义：

训练目标有效：实例判别目标与语义分类目标一致
特征质量高：特征空间中的距离确实反映了视觉相似性
泛化能力强：学习到的表示可以泛化到新任务

对比其他方法：

Split-Brain：k-NN准确率（11.8%）远低于线性SVM（35.2%）
说明其学习到的特征度量质量较低

结论：k-NN的良好表现证明了实例判别学习的有效性，学习到的特征确实捕获了视觉相似性，而不仅仅是适合特定分类器的表示。
深入理解与实践思考

实例判别与语义判别的关系：虽然每个实例都被视作一个类别，但模型最终学习到的特征仍然会聚合出语义簇。这一现象说明视觉数据的结构性远强于我们赋予的标签结构。实际操作中可以通过t-SNE/UMAP观察到同类样本自然聚团。
Memory Bank vs. 队列：Memory Bank提供了全局视角，但需要处理“陈旧”特征的问题。后来MoCo中的动量编码器与固定长度队列，可以被视作对“特征一致性”与“可扩展性”的不同取舍。若业务中GPU显存紧张，可采用分片Memory Bank或结合近邻图的稀疏更新。
正则化的更广义含义：近端正则化不仅平滑了优化，还暗含“特征轨迹不能跳跃太远”的约束，相当于引入了一个时间维度的Lipschitz限制。这提醒我们，在设计自监督任务时，需要关注优化轨迹是否稳定。
评价指标的选择：k-NN性能高说明学到的度量空间质量好，但在工业场景往往还需关注召回、延迟等指标。实例判别学习天然适合构建向量检索服务（如图像去重、相似商品推荐）。
与现代方法的衔接：若希望复现最新SOTA，可在此框架上引入更强的编码器（ViT、ConvNeXt）、更丰富的数据增强（RandAugment、CutMix）以及更加稳定的优化器（AdamW + Cosine）。同时也可以尝试将SupCon的标签约束融入Memory Bank以获得更平滑的语义结构。

开放问题与研究方向

Memory更新策略：能否利用动量更新与自适应权重结合，既保持全局视野又不过度依赖旧特征？
负样本质量：如何更智能地采样“困难负样本”，避免CNN在易区分的负样本上浪费容量？
多模态扩展：能否直接在该框架中支持图像-文本或多模态实例判别，减少对比学习与跨模态模型之间的割裂？
理论解释：实例判别为何能自动恢复语义结构？是否存在可证明的聚类或流形假设支撑？
增量学习：面对不断新增的数据集，如何无缝扩展Memory Bank并避免遗忘？

]]></content>
      <categories>
        <category>论文精读</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>论文精读</tag>
        <tag>对比学习</tag>
        <tag>实例判别</tag>
        <tag>无监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>对比学习综述</title>
    <url>/2025/11/%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[对比学习综述：从理论到实践全面解析
引言
对比学习（Contrastive Learning） 是近年来自监督学习领域最重要的突破之一，它通过&quot;拉近正样本、推远负样本&quot;的简单思想，在无需大量标注数据的情况下学习到强大的视觉表示。从2020年的SimCLR、MoCo开始，对比学习在ImageNet等基准上取得了与监督学习相当甚至更好的性能，彻底改变了我们对无监督表示学习的认知。
对比学习的核心优势在于：

无需标注数据：可以在海量无标注图像上预训练
学习鲁棒表示：对数据增强、噪声等具有强鲁棒性
迁移能力强：预训练的特征在下游任务上表现优异
可扩展性好：可以轻松扩展到大规模数据和模型

什么是对比学习？
核心思想
对比学习的核心思想可以用一句话概括：通过对比正样本对和负样本对，学习到区分性的表示。
正样本对（Positive Pairs）：应该相似的样本对

无监督：同一图像的不同增强视图
有监督：同一类别的不同样本

负样本对（Negative Pairs）：应该不相似的样本对

无监督：不同图像的增强视图
有监督：不同类别的样本

学习目标：让模型学习到的特征空间中，正样本对的距离近，负样本对的距离远。
为什么需要对比学习？
1. 标注数据稀缺问题

获取大规模标注数据成本高昂（ImageNet标注花费数百万美元）
很多领域缺乏专家标注（医疗、卫星图像等）
标注质量难以保证，存在标注噪声

2. 自监督学习的优势

利用数据自身的结构作为监督信号
可以在海量无标注数据上预训练
学习到的特征更通用，迁移性更好

3. 对比学习的独特价值

判别性强：通过对比学习到的特征比重建任务（如自编码器）更有判别性
计算高效：比生成模型（GAN、VAE）训练更稳定、收敛更快
理论基础：有信息论的理论支撑（互信息最大化）

对比学习的工作原理
核心机制详解：


正负样本构造

正样本对：同一图像通过不同数据增强得到的两个视图
负样本对：来自不同图像的视图
关键点：正样本共享语义信息，负样本语义不同



特征提取流程


特征提取流程
graph LRA[输入图像] --&gt; B[数据增强]B --&gt; C[编码器]C --&gt; D[特征向量]D --&gt; E[投影头]E --&gt; F[对比损失]

编码器：提取高维语义特征（如ResNet输出2048维）
投影头：映射到低维空间（通常128维），便于计算相似度



相似度计算

使用余弦相似度：$sim(z_i, z_j) = \frac{z_i \cdot z_j}{||z_i|| \cdot ||z_j||}$
温度缩放：$sim(z_i, z_j) / \tau$，控制分布的集中程度



优化目标

最大化正样本对的相似度
最小化负样本对的相似度
通过InfoNCE损失实现这一目标



对比学习的发展历程
早期工作（2010s）

Triplet Loss（2015）：最早的形式化对比学习思想
NCE（Noise Contrastive Estimation）：从语言模型引入对比思想
Instance Discrimination：将每个样本视为一个类别

现代对比学习（2020-）

SimCLR（2020）：端到端训练，大batch size
MoCo（2020）：动量编码器 + 队列机制
SupCon（2020）：监督对比学习
BYOL/SimSiam（2020-2021）：无需负样本的对比学习
CLIP（2021）：跨模态对比学习

核心损失函数：InfoNCE / NT-Xent
InfoNCE损失详解
损失函数定义：
给定一个正样本对 $(x, x^+)$ 和 N-1 个负样本 ${x_i^-}_{i=1}^{N-1}$，InfoNCE损失定义为：
$$ 
\mathcal{L}_{\text{InfoNCE}} = -\log \frac{\exp(sim(x, x^+) / \tau)}{\exp(sim(x, x^+) / \tau) + \sum_{i=1}^{N-1} \exp(sim(x, x_i^-) / \tau)}
$$ 
逐步理解损失函数：


相似度计算 $sim(x, x^+)$：

计算查询样本$x$与正样本$x^+$的余弦相似度
值域：[-1, 1]，1表示完全相同，-1表示完全相反



温度缩放 $sim/\tau$：

$\tau$通常设置为0.07-0.5
较小的$\tau$让模型更关注困难负样本
较大的$\tau$让优化更平滑



Softmax归一化：

将相似度转换为概率分布
正样本的&quot;概率&quot;应该接近1
每个负样本的&quot;概率&quot;应该接近0



负对数似然：

最小化损失 = 最大化正样本的概率
这等价于N分类问题，正确类别是正样本



为什么InfoNCE有效？

归一化：特征先进行L2归一化
温度缩放：$\tau$ 控制softmax分布的尖锐程度

温度参数 $\tau$ 的作用
温度参数 $\tau$ 是对比学习中的关键超参数：


$\tau$ 较小（如0.05）：

分布更尖锐，模型更关注困难负样本
学习到的表示区分性更强
但可能训练不稳定



$\tau$ 较大（如0.2）：

分布更平滑，对所有样本的关注更均匀
训练更稳定
但区分性可能较弱



典型取值：0.07（SimCLR、MoCo等常用）


主要方法详解
1. SimCLR（A Simple Framework for Contrastive Learning）
论文：https://arxiv.org/pdf/2002.05709
代码：https://github.com/google-research/simclr
核心思想
SimCLR提出了一个简单而有效的对比学习框架：

对每个样本应用两次随机增强，得到两个视图
使用共享编码器提取特征
通过投影头映射到对比空间
使用NT-Xent损失进行对比学习

关键创新

强数据增强：发现数据增强是对比学习成功的关键
投影头：在编码器和损失之间加入非线性投影头
大batch size：需要大量负样本（batch size ≥ 4096）

架构
架构
graph LR    subgraph SimCLR架构    I[输入图像] --&gt; T1[增强视图 1]    I --&gt; T2[增强视图 2]    T1 --&gt; E1[编码器 f]    T2 --&gt; E2[编码器 f]    E1 --&gt; H1[投影头 g]    E2 --&gt; H2[投影头 g]    H1 --&gt; Z1[特征 z1]    H2 --&gt; Z2[特征 z2]    Z1 &lt;--&gt; L[对比损失]    Z2 &lt;--&gt; L    end
优缺点
优点：

框架简单，易于实现
端到端训练，无需额外机制
性能优异

缺点：

需要大batch size，对计算资源要求高
对数据增强策略敏感

2. MoCo（Momentum Contrast）
论文：https://arxiv.org/pdf/1911.05722
代码：https://github.com/facebookresearch/moco
核心思想
MoCo将对比学习看作字典查找任务：

Query：当前样本的编码
Key：字典中的样本编码
目标：Query与匹配的Key相似，与其他Key不相似

关键创新

动量编码器：使用动量更新维护一个缓慢变化的编码器
队列机制：用队列存储历史样本的特征，提供大量负样本
一致性：动量更新保证字典中Key的一致性

架构
架构
graph LR    subgraph MoCo架构    Q[Query图像] --&gt; EQ[编码器]    EQ --&gt; QF[Query特征]    K[Key图像] --&gt; EK[动量编码器]    EK --&gt; KF[Key特征]    KF --&gt; Que[队列 Dictionary]    QF &lt;--&gt; Loss[对比损失]    Que &lt;--&gt; Loss    end
优缺点
优点：

不依赖大batch size
训练稳定，收敛快
内存效率高

缺点：

实现相对复杂
需要维护队列和动量编码器

3. SupCon（Supervised Contrastive Learning）
论文：https://arxiv.org/pdf/2004.11362
代码：https://github.com/HobbitLong/SupContrast
核心思想
将标签信息融入对比学习：

正样本：同一类别的所有样本
负样本：不同类别的样本

损失函数
$$
\mathcal{L}{sup}^i = -\frac{1}{|P(i)|} \sum{p \in P(i)} \log \frac{\exp(z_i \cdot z_p / \tau)}{\sum_{a \in A(i)} \exp(z_i \cdot z_a / \tau)}
$$
其中 $P(i)$ 是与样本 $i$ 同类的样本集合。
优缺点
优点：

利用标签信息，性能更优
鲁棒性显著提升
在长尾学习、少样本学习上表现优异

缺点：

需要标注数据
计算复杂度较高（$O(N^2)$）

4. BYOL / SimSiam（无需负样本）
BYOL论文：https://arxiv.org/pdf/2006.07733
SimSiam论文：https://arxiv.org/pdf/2011.10566
核心思想
通过预测任务替代对比任务，无需负样本：

一个视图预测另一个视图
使用停止梯度（stop-gradient）防止崩溃

关键机制

预测头：预测一个视图的特征
停止梯度：防止模型学习到平凡解（所有特征相同）
对称损失：同时优化两个方向

优缺点
优点：

无需负样本，计算更高效
训练更稳定

缺点：

理论理解仍在发展中
性能可能略低于有负样本的方法

5. SwAV (Swapping Assignments between Views)
论文：https://arxiv.org/pdf/2006.09882
代码：https://github.com/facebookresearch/swav
核心思想
SwAV 将对比学习与聚类相结合。它不直接对比两个视图的特征，而是对比它们在聚类中心的分配（Assignment）。

核心假设：同一图像的两个视图应该属于同一个聚类中心。
机制：用一个视图的特征去预测另一个视图的聚类分配。

架构
graph LR    subgraph SwAV架构    I[输入图像] --&gt; V1[视图 1]    I --&gt; V2[视图 2]    V1 --&gt; E1[编码器]    V2 --&gt; E2[编码器]    E1 --&gt; Z1[特征 Z1]    E2 --&gt; Z2[特征 Z2]    Z1 --&gt; P1[原型 Prototypes]    Z2 --&gt; P2[原型 Prototypes]    P1 --&gt; C1[聚类分配 Q1]    P2 --&gt; C2[聚类分配 Q2]    Z1 -.预测.-&gt; C2    Z2 -.预测.-&gt; C1    end
优缺点

优点：无需大量负样本，无需大batch size，训练效率高。
缺点：需要在线聚类，实现稍复杂。

6. CLIP (Contrastive Language-Image Pre-training)
论文：https://arxiv.org/pdf/2103.00020
代码：https://github.com/openai/CLIP
核心思想
将对比学习扩展到多模态领域。使用海量的（图像，文本）对进行训练。

正样本：匹配的（图像，文本）对。
负样本：不匹配的（图像，文本）对。

架构
graph LR    subgraph CLIP架构    Img[图像] --&gt; ImgEnc[图像编码器]    Txt[文本] --&gt; TxtEnc[文本编码器]    ImgEnc --&gt; ImgFeat[图像特征]    TxtEnc --&gt; TxtFeat[文本特征]    ImgFeat &lt;--&gt; Loss[对比损失]    TxtFeat &lt;--&gt; Loss    end
影响
CLIP 的出现标志着对比学习从单纯的视觉表示学习走向了通用的多模态理解，为后来的 DALL-E、Stable Diffusion 等生成模型奠定了基础。
技术细节与实践指南
数据增强策略详解
核心增强技术：


随机裁剪（RandomResizedCrop）

最重要的增强，强制模型学习局部-整体关系
参数：scale=(0.08, 1.0)，ratio=(0.75, 1.33)
作用：模拟不同视角和距离



颜色抖动（ColorJitter）

调整亮度、对比度、饱和度、色相
参数：brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1
作用：学习颜色不变的特征



高斯模糊（GaussianBlur）

SimCLR发现这是关键增强之一
参数：kernel_size=图像宽度的1/10，sigma=[0.1, 2.0]
作用：强制关注高层语义而非纹理细节



随机灰度化（RandomGrayscale）

概率：通常设为0.2
作用：学习不依赖颜色的形状特征



增强组合的重要性：
# SimCLR推荐的增强pipelinetransforms = [    RandomResizedCrop(224, scale=(0.08, 1.0)),    RandomHorizontalFlip(p=0.5),    RandomApply([ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8),    RandomGrayscale(p=0.2),    RandomApply([GaussianBlur(kernel_size=23)], p=0.5),    ToTensor(),    Normalize(mean, std)]
投影头设计原理
为什么需要投影头？


信息瓶颈作用

编码器输出包含丰富信息（2048维）
投影到低维（128维）强制提取关键信息
防止模型记住无关细节



任务分离

编码器学习通用表示（用于下游任务）
投影头学习对比特定表示（训练后丢弃）
保护编码器特征不被对比任务&quot;污染&quot;



实验发现

无投影头：下游任务性能下降约10%
线性投影头：有改善但不够
非线性投影头（2层MLP）：最佳性能



投影头架构：
# 典型的投影头设计projection_head = nn.Sequential(    nn.Linear(2048, 2048),  # 隐藏层    nn.ReLU(),    nn.Linear(2048, 128)    # 输出层)
训练技巧


学习率：

大batch size时使用大学习率（如0.3）
使用LARS优化器（大batch）或AdamW



学习率调度：

Cosine annealing
Warmup（10%的训练步数）



Batch Size：

SimCLR：≥ 4096
MoCo：256-1024即可
SupCon：根据类别数调整



训练时长：

通常需要较长的训练（100-1000 epochs）
使用更多数据可以缩短训练时间



特征归一化
为什么需要归一化？

控制特征尺度，避免某些维度 dominate
使余弦相似度计算有意义
提高训练稳定性

归一化方式：
z = F.normalize(features, p=2, dim=1)  # L2归一化
代码实现
InfoNCE损失实现
import torchimport torch.nn as nnimport torch.nn.functional as Fclass InfoNCELoss(nn.Module):    &quot;&quot;&quot;InfoNCE损失函数&quot;&quot;&quot;        def __init__(self, temperature=0.07):        super().__init__()        self.temperature = temperature        def forward(self, z1, z2):        &quot;&quot;&quot;        Args:            z1, z2: [batch_size, feature_dim] 归一化后的特征        Returns:            loss: scalar        &quot;&quot;&quot;        batch_size = z1.size(0)                # 合并所有特征        z = torch.cat([z1, z2], dim=0)  # [2*batch_size, feature_dim]                # 计算相似度矩阵        sim_matrix = torch.mm(z, z.t()) / self.temperature  # [2*batch_size, 2*batch_size]                # 构建正样本mask        labels = torch.arange(batch_size, device=z.device)        labels = torch.cat([labels + batch_size, labels], dim=0)  # [2*batch_size]        mask = torch.eq(labels.unsqueeze(1), labels.unsqueeze(0)).float()                # 移除自身相似度        logits_mask = torch.scatter(            torch.ones_like(mask),            1,            torch.arange(2 * batch_size, device=z.device).view(-1, 1),            0        )        mask = mask * logits_mask                # 计算exp        exp_logits = torch.exp(sim_matrix) * logits_mask                # 计算log_prob        log_prob = sim_matrix - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)                # 平均正样本的log_prob        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)                # 损失（取负）        loss = -mean_log_prob_pos.mean()                return loss
完整的对比学习训练示例
import torchimport torch.nn as nnimport torch.optim as optimfrom torch.utils.data import DataLoaderclass ContrastiveModel(nn.Module):    def __init__(self, encoder, projection_dim=128):        super().__init__()        self.encoder = encoder        # 移除分类头        if hasattr(encoder, &#x27;fc&#x27;):            self.encoder.fc = nn.Identity()                # 投影头        encoder_dim = 2048  # ResNet-50的输出维度        self.projector = nn.Sequential(            nn.Linear(encoder_dim, 2048),            nn.ReLU(),            nn.Linear(2048, projection_dim)        )        def forward(self, x):        features = self.encoder(x)        projections = self.projector(features)        return F.normalize(projections, dim=1)def train_contrastive(model, dataloader, num_epochs=100):    criterion = InfoNCELoss(temperature=0.07)    optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.1)    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)        model.train()    for epoch in range(num_epochs):        for batch_idx, (images, _) in enumerate(dataloader):            # 数据增强（假设已经在dataloader中完成）            # images: [batch_size, 2, C, H, W] (两个增强视图)            batch_size = images.size(0)            images = images.view(batch_size * 2, *images.shape[2:])                        # 前向传播            projections = model(images)  # [2*batch_size, projection_dim]            z1, z2 = projections.chunk(2, dim=0)                        # 计算损失            loss = criterion(z1, z2)                        # 反向传播            optimizer.zero_grad()            loss.backward()            optimizer.step()                        if batch_idx % 100 == 0:                print(f&#x27;Epoch &#123;epoch&#125;, Batch &#123;batch_idx&#125;, Loss: &#123;loss.item():.4f&#125;&#x27;)                scheduler.step()
应用场景
1. 图像分类

预训练：在ImageNet等大规模数据集上预训练
微调：在下游分类任务上微调编码器
性能：可以达到或超越监督预训练的性能

2. 目标检测

Backbone预训练：使用对比学习预训练检测器的backbone
迁移学习：将预训练特征迁移到检测任务
性能提升：显著提升检测精度，特别是少样本场景

3. 语义分割

特征提取器预训练：预训练分割网络的特征提取部分
少样本分割：在少样本分割任务上表现优异

4. 图像检索

特征学习：学习到适合检索的判别性特征
相似度计算：直接使用学习到的特征进行检索

5. 长尾学习

SupCon优势：监督对比学习在长尾分布上表现优异
类间分离：显式推远异类样本，提高尾部类别性能

对比学习 vs 其他方法
vs. 监督学习



特性
监督学习
对比学习




数据需求
需要大量标注
无需标注


表示质量
任务相关
通用性强


鲁棒性
一般
更强


计算成本
较低
较高（大batch）



vs. 生成式方法（VAE、GAN）



特性
生成式方法
对比学习




目标
重建/生成
表示学习


训练稳定性
不稳定
较稳定


表示质量
可能包含无关信息
更聚焦判别性


计算效率
较低
较高



vs. 自编码器



特性
自编码器
对比学习




目标
重建输入
区分样本


表示性质
可能包含冗余
更紧凑


下游任务
需要额外设计
直接可用



扩展领域：NLP中的对比学习
对比学习不仅在CV领域大放异彩，在NLP领域也同样重要。
SimCSE (Simple Contrastive Learning of Sentence Embeddings)
论文：https://arxiv.org/pdf/2104.08821
核心思想：

无监督 SimCSE：利用 Dropout 作为数据增强。将同一个句子输入预训练模型（如BERT）两次，由于 Dropout 的存在，得到两个略有不同的 embedding，作为正样本对。
有监督 SimCSE：利用 NLI 数据集中的（蕴含，前提）作为正样本，（矛盾，前提）作为负样本。

影响：SimCSE 极大地提升了句向量的质量，成为 NLP 句向量表示的标准基线。
前沿探讨：对比学习 vs 掩码图像建模 (MIM)
随着 MAE (Masked Autoencoders) 和 BEiT 的提出，视觉预训练领域出现了新的范式竞争。
掩码图像建模 (MIM)

代表作：MAE, BEiT, SimMIM
核心思想：类似 BERT，遮挡图像的一部分 patch，让模型重建被遮挡的像素或特征。
优势：

训练效率高（只需处理可见 patch）。
学习到的特征包含更多细节信息，利于检测和分割任务。
扩展性极强（Scaling Law）。



对比学习 (CL) vs MIM



特性
对比学习 (CL)
掩码图像建模 (MIM)




核心目标
区分样本 (全局语义)
重建细节 (局部关系)


数据增强
极其依赖 (强增强)
不太依赖 (仅需 Mask)


特征性质
线性可分性好，适合分类
细节丰富，适合定位/分割


训练效率
较低 (需处理全图)
较高 (仅处理部分)


当前趋势
多模态对齐 (CLIP)
视觉基础模型 (ViT Pretraining)



结论：两者并非对立，正在趋于融合（如 IBOT, EVA 等工作尝试结合两者的优势）。
当前挑战与解决方案
主要技术挑战
1. 大批次训练的硬件需求
问题：

SimCLR需要4096-8192的batch size才能达到最佳性能
需要多GPU训练，单GPU难以实现

解决方案：

MoCo方法：使用队列存储负样本，减少GPU内存需求
梯度累积：多次前向传播累积梯度，模拟大batch
混合精度训练：使用FP16减少内存使用

2. 负样本的质量问题
问题：

随机采样的负样本可能包含语义相似的样本（假负样本）
简单负样本提供的学习信号有限

解决方案：

困难负样本挖掘：选择相似度较高的负样本
去偏采样：使用先验知识避免假负样本
自适应温度：动态调整温度参数关注困难样本

3. 数据增强的设计
问题：

不同任务需要不同的增强策略
过强增强可能破坏语义信息

解决方案：

AutoAugment：自动搜索最优增强策略
任务特定增强：根据下游任务设计增强
增强强度调度：训练过程中逐渐增强强度

常见问题与调试
1. 模型崩溃（所有样本映射到同一点）
症状：损失快速下降到0，所有特征相同
解决：

检查是否有stop-gradient操作
确保使用了负样本
添加正则化项

2. 性能不提升
可能原因：

Batch size太小（&lt; 256）
温度参数设置不当
数据增强太弱或太强

调试步骤：

可视化增强后的图像，确保保留语义
监控正负样本相似度分布
尝试不同的温度参数（0.05-0.5）

3. 下游任务性能差
原因分析：

预训练与下游任务domain gap
使用了投影头的特征而非编码器特征
预训练不充分

改进方法：

在目标domain数据上预训练
使用编码器特征进行下游任务
增加预训练epochs

总结
对比学习通过&quot;拉近正样本、推远负样本&quot;的简单思想，在无需大量标注数据的情况下学习到强大的视觉表示。从SimCLR、MoCo到SupCon，对比学习的方法不断演进，性能不断提升。
关键要点：

数据增强是关键：强数据增强是对比学习成功的重要因素
负样本数量很重要：需要足够的负样本才能学到好的表示
温度参数需要调优：$\tau$ 对性能有重要影响
投影头很重要：在编码器和损失之间加入投影头能提升性能
可以结合监督信号：SupCon证明了标签信息可以进一步提升性能

对比学习的成功证明了无监督表示学习的巨大潜力，为未来的研究指明了方向。
参考文献


Chen, T., et al. (2020). A Simple Framework for Contrastive Learning of Visual Representations. ICML 2020. https://arxiv.org/pdf/2002.05709


He, K., et al. (2020). Momentum Contrast for Unsupervised Visual Representation Learning. CVPR 2020. https://arxiv.org/pdf/1911.05722


Khosla, P., et al. (2020). Supervised Contrastive Learning. NeurIPS 2020. https://arxiv.org/pdf/2004.11362


Grill, J. B., et al. (2020). Bootstrap Your Own Latent: A New Approach to Self-Supervised Learning. NeurIPS 2020. https://arxiv.org/pdf/2006.07733


Chen, X., &amp; He, K. (2021). Exploring Simple Siamese Representation Learning. CVPR 2021. https://arxiv.org/pdf/2011.10566


Radford, A., et al. (2021). Learning Transferable Visual Models From Natural Language Supervision. ICML 2021. https://arxiv.org/pdf/2103.00020


思考题

为什么对比学习需要大量的负样本？负样本数量如何影响学习效果？
温度参数 $\tau$ 的物理意义是什么？如何根据任务选择合适的 $\tau$？
数据增强在对比学习中的作用是什么？为什么某些增强（如crop）比其他增强更重要？
MoCo的动量编码器和队列机制是如何解决SimCLR的大batch size问题的？
监督对比学习（SupCon）相比无监督对比学习（SimCLR/MoCo）的优势和劣势是什么？
为什么BYOL和SimSiam可以在没有负样本的情况下工作？停止梯度机制的作用是什么？

思考题答案
1. 为什么对比学习需要大量的负样本？负样本数量如何影响学习效果？
为什么需要大量负样本？

提供对比信号：负样本提供了&quot;什么不应该相似&quot;的信息，帮助模型学习区分性
防止崩溃：足够的负样本防止模型学习到平凡解（所有特征相同）
提高表示质量：更多负样本意味着更丰富的对比信号，学习到的表示更具判别性

负样本数量的影响：

太少（&lt; 64）：对比信号不足，模型难以学习到好的表示
适中（256-4096）：性能随负样本数量增加而提升
太多（&gt; 8192）：收益递减，计算成本显著增加

实验发现：

SimCLR：batch size从256增加到8192，性能持续提升
MoCo：队列大小从128增加到65536，性能提升但收益递减

2. 温度参数 $\tau$ 的物理意义是什么？如何根据任务选择合适的 $\tau$？
物理意义：
温度参数 $\tau$ 控制softmax分布的尖锐程度（entropy）：

$\tau \to 0$：分布接近one-hot，模型只关注最相似的样本
$\tau \to \infty$：分布接近均匀，模型对所有样本的关注相等

数学上：$\tau$ 是softmax中的缩放因子，影响梯度的尺度
选择策略：

起始值：0.07（SimCLR、MoCo等常用）
任务特性：

细粒度分类（类别相似）→ 较小的$\tau$（0.05）
粗粒度分类（类别差异大）→ 较大的$\tau$（0.1-0.15）


观察训练：

损失下降快但验证性能差 → 降低$\tau$
训练不稳定 → 提高$\tau$


网格搜索：在[0.05, 0.07, 0.1, 0.15, 0.2]范围内搜索

3. 数据增强在对比学习中的作用是什么？为什么某些增强（如crop）比其他增强更重要？
数据增强的作用：

构造正样本对：通过增强同一图像得到不同的视图，作为正样本
提高鲁棒性：学习对增强不变的表示，提高泛化能力
增加数据多样性：在有限数据上模拟更多场景

为什么crop最重要？

语义保持：crop保留了图像的主要语义内容
视角变化：模拟了不同的观察视角，是自然的变化
空间不变性：帮助模型学习空间不变的特征

增强的重要性排序（SimCLR实验）：

RandomResizedCrop（最重要）
RandomHorizontalFlip
ColorJitter
RandomGrayscale
GaussianBlur

组合效应：多个增强的组合效果 &gt; 单个增强的简单叠加
4. MoCo的动量编码器和队列机制是如何解决SimCLR的大batch size问题的？
SimCLR的问题：

需要大batch size（≥ 4096）提供足够负样本
对GPU内存和计算资源要求高

MoCo的解决方案：


队列机制：

维护一个FIFO队列存储历史样本的特征
队列大小可以很大（如65536），远超batch size
每次用新batch的特征替换最旧的队列元素



动量编码器：

Key编码器通过动量更新：$\theta_k \leftarrow m \theta_k + (1-m) \theta_q$
保证队列中Key的一致性（不会因为编码器快速变化而失效）
动量系数通常为0.999



优势：

不需要大batch size（256-1024即可）
队列提供大量且一致的负样本
内存效率高（只存储特征，不存储图像）

5. 监督对比学习（SupCon）相比无监督对比学习（SimCLR/MoCo）的优势和劣势是什么？
优势：

正样本更明确：同类样本作为正样本，比增强视图更可靠
性能更优：在分类任务上通常超越无监督方法
鲁棒性更强：对对抗样本、噪声等更鲁棒
长尾学习：在类别不平衡数据上表现优异
少样本学习：学习到的表示泛化能力更强

劣势：

需要标注数据：无法利用无标注数据
计算成本高：需要计算所有样本对的相似度（$O(N^2)$）
任务相关：学习到的表示可能更偏向特定任务
类别依赖：需要知道类别信息，限制了应用场景

适用场景：

SupCon：有标注数据，关注分类性能和鲁棒性
无监督：无标注数据，需要通用表示

6. 为什么BYOL和SimSiam可以在没有负样本的情况下工作？停止梯度机制的作用是什么？
为什么可以工作？

预测任务替代对比：通过预测一个视图的特征来学习表示
对称损失：同时优化两个方向的预测
停止梯度：防止模型学习到平凡解

停止梯度机制：
在BYOL/SimSiam中，一个分支的梯度被停止：
# SimSiam示例z1 = encoder(x1)z2 = encoder(x2)p1 = predictor(z1)p2 = predictor(z2)# 停止z2的梯度loss = 0.5 * (d(p1, z2.detach()) + d(p2, z1.detach()))
作用：

防止崩溃：如果没有停止梯度，两个分支可能学习到相同的表示（平凡解）
非对称性：创造非对称的学习信号，使模型必须学习有意义的表示
稳定训练：避免两个分支相互&quot;追逐&quot;，训练更稳定

理论理解：

停止梯度创造了一个&quot;教师-学生&quot;的关系
一个分支作为&quot;教师&quot;提供目标，另一个作为&quot;学生&quot;学习
这种非对称性防止了表示空间的坍塌

深度思考与实践经验

对比信号的本质：无论是SimCLR还是MoCo，本质上都在重建一个“相似样本的局部图结构”。从这个角度看，数据增强、负样本采样、温度参数都是在调节局部图的形状。实践中可以通过构建邻接矩阵或最近邻图来检查模型学习到的结构是否符合预期。
大batch与动量编码器的权衡：SimCLR依赖大batch，MoCo依赖动量编码器与队列。前者更适合TPU或多节点GPU环境，后者对资源要求更低但需要额外调节动量系数。在工业部署时，可根据硬件与延迟要求选择不同方案。
Projection Head的价值：许多工程实践表明，只要下游任务不是k-NN检索，就应当保留投影头并在微调时丢弃。投影头相当于一个“噪声抑制器”，把与对比任务高度相关但与下游任务无关的因素隔离开。
数据增强的语义边界：对比学习依赖“语义不变”的增强。如果增强破坏了语义一致性（例如在细粒度识别中使用过强的随机裁剪），模型可能误学到错误关联。设计增强时应结合业务常识：什么变化对用户看来仍是同一对象？
InfoNCE作为下界：InfoNCE提供了互信息的可计算下界。下界松紧程度受负样本数量、温度、特征容量、优化状态影响。若训练良好却仍觉得效果不足，可以尝试提高下界（更多负样本、更低温度）或改用其他目标（如Barlow Twins、VICReg）。

开放问题

困难负样本自动发现：目前多靠随机采样，能否结合难例挖掘或生成模型来构建更具区分度的负样本？
跨模态对比的统一框架：CLIP等方法表明文本-图像对比极具潜力，是否存在统一的对比学习范式涵盖视觉、语言、音频？
长序列与视频：视频对比学习如何解决时间维度的冗余与语义错配问题？现有工作（VideoMAE、TimeSformer）仍在探索。
理论上界与可解释性：对比学习能否提供误差上界或泛化保证？如何解释实例判别自动聚类的现象？
增量与联邦场景：当数据分布随时间变化或分散在不同客户端时，如何稳定地维护对比学习的记忆（队列/Memory Bank）？

]]></content>
      <categories>
        <category>论文精读</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>自监督学习</tag>
        <tag>对比学习</tag>
        <tag>深度学习</tag>
        <tag>无监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>开学三个月小记</title>
    <url>/2025/12/%E5%BC%80%E5%AD%A6%E4%B8%89%E4%B8%AA%E6%9C%88%E5%B0%8F%E8%AE%B0/</url>
    <content><![CDATA[时光飞逝，转眼间开学已经三个月了。如果一直这么下去就又荒废了三年。
第一没有输入，感觉三个月没有什么知识输入，输出也没有，因为基础太差了，感觉陷入了一个恶性循环，没有时间学习，好吧，其实是不知道学啥，也不想学，静不下心来去学习，需要补的基础的东西太多了，不知道从哪里开始。
第二过度依赖AI，用AI写的博客基本上也没认真看，AI虽然好用，但是现在完全没有发挥出它的作用帮我在能力上有所提升。
第三生活比较混乱，主要是没有平衡好每天该做什么，又回到高中大学那种天天想干啥就干啥的状态了，课也基本上都不用去上，其实从高中开始就经常逃课，晚自习不上，大学疫情更是如此了，自由习惯了，很难再改变。每天过的倒是挺自由，也快一个月没开过组会了，也不知道要汇报啥。倒是偶尔健身，健身一个多月了，虽然也是三天打鱼两天晒网，但是确实是有效果的。
上边三点的解决方法是现在急需制定一个切实可行的大体方案，每天按照计划去做，但是经常会忘记去看每日计划，效果一般，可以每天记录反思一下做了什么，这样应该可以，单独创建一个记事本，正好今天下载了一个新的笔记管理软件，尝试每天记录一下。其实就和我当时创建网站的目的一样，当时是为了监督我复试学习，每天记录一下做了什么，以防像第一年复试笔试没准备完，面试和机试一点没准备，以初试第三被刷掉。对于AI的话，如果用AI进行学习的话，还是很不错的，不需要繁琐的信息检索，可以达到及时反馈修改错误直觉的作用。


“生活不是等待暴风雨过去，而是学会在雨中跳舞。”

]]></content>
      <categories>
        <category>生活记录</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>随笔</tag>
        <tag>研究生生活</tag>
      </tags>
  </entry>
  <entry>
    <title>手撕 Vision Transformer</title>
    <url>/2025/06/%E6%89%8B%E6%92%95%20Vision%20Transformer/</url>
    <content><![CDATA[手撕 Vision Transformer

​	之前接触过挺多pytorch框架写的代码的，但是一直没有学过，觉得没啥可学的，上个月看了b站上的一个博主的速成课，感觉确实没啥学的，就是几个函数而已，不过通一下也是很有收获的。我现在准备练习一下代码能力，所以尝试手写一下Vit代码。这也是第一次写除了算法题之外的代码，之前复试结束后联系了一个老师问我写过代码吗，我说没有，也是很尴尬了，最后老师也没要我，嫌我基础太差了，希望能在开学之前把代码能力练好，并且把基础的一些东西弄明白。
​	根据Gemini给我生成了个提示，手写了一遍，不过中间有好几处错误，目前已经更正，不是很熟练，还需要再练习一下。
import torchimport torch.nn as nn# 1. 图像分块与嵌入 (Patch Embedding)# 模块： PatchEmbedding(nn.Module)class PatchEmbedding(nn.Module):    def __init__(self,in_channels,patch_size,embed_dim,image_size):        super().__init__()        self.patch_num=(image_size//patch_size)**2        self.emb=nn.Conv2d(in_channels,embed_dim,kernel_size=patch_size,stride=patch_size)        self.pos_emb=nn.Parameter(torch.randn(1,self.patch_num+1,embed_dim))        self.cls_emb=nn.Parameter(torch.randn(1,1,embed_dim))    def forward(self,x):        x=self.emb(x)        b,d,h,w=x.shape        x=x.permute(0,2,3,1).reshape(b,h*w,d)        cls_emb=self.cls_emb.expand(b,-1,-1)        x=torch.cat((cls_emb,x),dim=1)        out=x+self.pos_emb[:,:1+h*w]        return out# 2. 多头自注意力机制 (Multi-Head Self-Attention, MSA)# 模块： MultiHeadSelfAttention(nn.Module)class MultiHeadSelfAttention(nn.Module):    def __init__(self,embed_dim,num_heads,dropout=0.0):        super().__init__()        self.embed_dim=embed_dim        self.num_heads=num_heads        self.head_dim=embed_dim//num_heads        self.proj_q=nn.Linear(embed_dim,embed_dim)        self.proj_k=nn.Linear(embed_dim,embed_dim)        self.proj_v=nn.Linear(embed_dim,embed_dim)        self.out_proj=nn.Linear(embed_dim,embed_dim)        self.drop=nn.Dropout(dropout)        def forward(self,x):        b,l,_=x.shape        q = self.proj_q(x).reshape(b, l, self.num_heads, self.head_dim).transpose(1, 2)        k = self.proj_k(x).reshape(b, l, self.num_heads, self.head_dim).transpose(1, 2)        v = self.proj_v(x).reshape(b, l, self.num_heads, self.head_dim).transpose(1, 2)        atten_score=torch.matmul(q,k.transpose(-2,-1))/self.head_dim**0.5        atten_weight=torch.nn.functional.softmax(atten_score,dim=-1)        atten_weight = self.drop(atten_weight)        atten = torch.matmul(atten_weight, v).transpose(1, 2).reshape(b, l, self.embed_dim)        out=self.out_proj(atten)        out=self.drop(out)        return out# 3. 多层感知机块 (MLP Block)# 模块： MlpBlock(nn.Module)class MlpBlock(nn.Module):    def __init__(self,embed_dim,mlp_dim,out_dim,dropout=0.0):        super().__init__()        self.fc1=nn.Linear(embed_dim,mlp_dim)        self.fc2=nn.Linear(mlp_dim,out_dim)        self.act=nn.GELU()        self.drop=nn.Dropout(dropout)        def forward(self,x):        x=self.fc1(x)        x=self.act(x)        x=self.drop(x)        x=self.fc2(x)        out=self.drop(x)        return out# 4. Transformer 编码器块 (Transformer Encoder Block)# 模块： TransformerEncoderBlock(nn.Module)class TransformerEncoderBlock(nn.Module):    def __init__(self,embed_dim,num_heads,mlp_dim,dropout=0.0):        super().__init__()        self.norm1=nn.LayerNorm(embed_dim)        self.norm2=nn.LayerNorm(embed_dim)        self.mlp = MlpBlock(embed_dim, mlp_dim, embed_dim, dropout)         self.msa = MultiHeadSelfAttention(embed_dim, num_heads, dropout)        def forward(self,x):        norm=self.norm1(x)        msa=self.msa(norm)        res=msa+x        norm=self.norm2(res)        mlp=self.mlp(norm)        out=mlp+res        return out# 5. Transformer 编码器 (Transformer Encoder)# 模块： TransformerEncoder(nn.Module)class TransformerEncoder(nn.Module):    def __init__(self,embed_dim,num_heads,mlp_dim,depth,dropout=0.0):        super().__init__()        self.layers=nn.ModuleList([])        for _ in range(depth):             layer = TransformerEncoderBlock(embed_dim, num_heads, mlp_dim, dropout)            self.layers.append(layer)        self.norm=nn.LayerNorm(embed_dim)    def forward(self,x):        for layer in self.layers:             x = layer(x)         out=self.norm(x)        return out# 6. 完整的 Vision Transformer (ViT) 模型# 模块： VisionTransformer(nn.Module)class VisionTransformer(nn.Module):    def __init__(self,image_size,in_channels,num_classes,patch_size,embed_dim,depth,num_heads,mlp_dim,dropout=0.0):        super().__init__()        self.emb=PatchEmbedding(in_channels,patch_size,embed_dim,image_size)        self.trans=TransformerEncoder(embed_dim,num_heads,mlp_dim,depth,dropout)        self.lin=nn.Linear(embed_dim,num_classes)        def forward(self,x):        emb=self.emb(x)        trans_output=self.trans(emb)        cls_token_output = trans_output[:, 0]        out=self.lin(cls_token_output)        return out
]]></content>
      <categories>
        <category>手撕代码</category>
        <category>图像分类</category>
      </categories>
      <tags>
        <tag>Vit</tag>
        <tag>手撕代码</tag>
      </tags>
  </entry>
  <entry>
    <title>基础知识--排序算法</title>
    <url>/2025/03/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[排序算法详解
排序算法是计算机科学中最基础也是最重要的算法之一。本文将详细介绍几种常见的排序算法，包括它们的实现原理、时间复杂度和适用场景。本文所有代码示例使用 C++ 实现，需要包含以下头文件：
#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;
1. 冒泡排序 (Bubble Sort)
冒泡排序是最简单的排序算法之一，它重复地遍历要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。
实现原理

时间复杂度：O(n²)
空间复杂度：O(1)
稳定性：稳定

实现代码
void bubbleSort(vector&lt;int&gt;&amp; arr) &#123;    int n = arr.size();    bool swapped;    for(int i = 0; i &lt; n-1; i++) &#123;        swapped = false;        // 每一轮比较        for(int j = 0; j &lt; n-i-1; j++) &#123;            // 相邻元素比较并交换            if(arr[j] &gt; arr[j+1]) &#123;                swap(arr[j], arr[j+1]);                swapped = true;            &#125;        &#125;        // 如果没有发生交换，说明数组已经有序        if(!swapped) break;    &#125;&#125;
2. 选择排序 (Selection Sort)
选择排序的工作原理是每次从待排序的数据中选出最小（或最大）的元素，存放在序列的起始位置。
实现原理

时间复杂度：O(n²)
空间复杂度：O(1)
稳定性：不稳定

实现代码
void selectionSort(vector&lt;int&gt;&amp; arr) &#123;    int n = arr.size();    for(int i = 0; i &lt; n-1; i++) &#123;        int min_idx = i;        // 在未排序部分找最小值        for(int j = i+1; j &lt; n; j++) &#123;            if(arr[j] &lt; arr[min_idx]) &#123;                min_idx = j;            &#125;        &#125;        // 将找到的最小值放到已排序序列的末尾        if(min_idx != i) &#123;            swap(arr[i], arr[min_idx]);        &#125;    &#125;&#125;
3. 插入排序 (Insertion Sort)
插入排序的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。
实现原理

时间复杂度：O(n²)
空间复杂度：O(1)
稳定性：稳定

实现代码
void insertionSort(vector&lt;int&gt;&amp; arr) &#123;    int n = arr.size();    for(int i = 1; i &lt; n; i++) &#123;        int key = arr[i];        int j = i - 1;        // 将大于key的元素都向后移动        while(j &gt;= 0 &amp;&amp; arr[j] &gt; key) &#123;            arr[j+1] = arr[j];            j--;        &#125;        arr[j+1] = key;    &#125;&#125;
4. 快速排序 (Quick Sort)
快速排序是一种分治算法，它通过选择一个&quot;基准&quot;元素，将数组分成两个子数组，小于基准的元素放在左边，大于基准的元素放在右边。
实现原理

时间复杂度：平均 O(nlogn)，最坏 O(n²)
空间复杂度：O(logn)
稳定性：不稳定

实现代码
int partition(vector&lt;int&gt;&amp; arr, int low, int high) &#123;    int pivot = arr[high];    // 选择最右边的元素作为基准    int i = low - 1;          // 小于基准的元素的最后一个位置    for(int j = low; j &lt; high; j++) &#123;        // 如果当前元素小于基准，则将其交换到前面        if(arr[j] &lt; pivot) &#123;            i++;            swap(arr[i], arr[j]);        &#125;    &#125;    swap(arr[i + 1], arr[high]);    return i + 1;&#125;void quickSort(vector&lt;int&gt;&amp; arr, int low, int high) &#123;    if(low &lt; high) &#123;        // 获取分区点        int pi = partition(arr, low, high);        // 递归排序左右两部分        quickSort(arr, low, pi - 1);        quickSort(arr, pi + 1, high);    &#125;&#125;// 封装函数，方便调用void quickSort(vector&lt;int&gt;&amp; arr) &#123;    quickSort(arr, 0, arr.size() - 1);&#125;
5. 归并排序 (Merge Sort)
归并排序是一种分治算法，它将数组分成两半，递归地排序两半，然后将它们合并起来。
实现原理

时间复杂度：O(nlogn)
空间复杂度：O(n)
稳定性：稳定

实现代码
void merge(vector&lt;int&gt;&amp; arr, int left, int mid, int right) &#123;    vector&lt;int&gt; temp(right - left + 1);    int i = left, j = mid + 1, k = 0;        // 合并两个有序数组    while(i &lt;= mid &amp;&amp; j &lt;= right) &#123;        if(arr[i] &lt;= arr[j]) &#123;            temp[k++] = arr[i++];        &#125; else &#123;            temp[k++] = arr[j++];        &#125;    &#125;        // 复制剩余元素    while(i &lt;= mid) temp[k++] = arr[i++];    while(j &lt;= right) temp[k++] = arr[j++];        // 将临时数组复制回原数组    for(i = 0; i &lt; k; i++) &#123;        arr[left + i] = temp[i];    &#125;&#125;void mergeSort(vector&lt;int&gt;&amp; arr, int left, int right) &#123;    if(left &lt; right) &#123;        int mid = left + (right - left) / 2;        mergeSort(arr, left, mid);        mergeSort(arr, mid + 1, right);        merge(arr, left, mid, right);    &#125;&#125;// 封装函数，方便调用void mergeSort(vector&lt;int&gt;&amp; arr) &#123;    mergeSort(arr, 0, arr.size() - 1);&#125;
6. 堆排序 (Heap Sort)
堆排序是利用堆这种数据结构所设计的一种排序算法。它通过构建最大堆或最小堆来进行排序。
实现原理

时间复杂度：O(nlogn)
空间复杂度：O(1)
稳定性：不稳定

实现代码
void heapify(vector&lt;int&gt;&amp; arr, int n, int i) &#123;    int largest = i;    int left = 2 * i + 1;    int right = 2 * i + 2;    // 如果左子节点大于根节点    if(left &lt; n &amp;&amp; arr[left] &gt; arr[largest]) &#123;        largest = left;    &#125;        // 如果右子节点大于最大值    if(right &lt; n &amp;&amp; arr[right] &gt; arr[largest]) &#123;        largest = right;    &#125;        // 如果最大值不是根节点    if(largest != i) &#123;        swap(arr[i], arr[largest]);        heapify(arr, n, largest);    &#125;&#125;void heapSort(vector&lt;int&gt;&amp; arr) &#123;    int n = arr.size();        // 构建最大堆    for(int i = n/2-1; i &gt;= 0; i--) &#123;        heapify(arr, n, i);    &#125;        // 一个个从堆顶取出元素    for(int i = n-1; i &gt; 0; i--) &#123;        swap(arr[0], arr[i]);        heapify(arr, i, 0);    &#125;&#125;
排序算法的比较



排序算法
平均时间复杂度
最坏时间复杂度
空间复杂度
稳定性




冒泡排序
O(n²)
O(n²)
O(1)
稳定


选择排序
O(n²)
O(n²)
O(1)
不稳定


插入排序
O(n²)
O(n²)
O(1)
稳定


快速排序
O(nlogn)
O(n²)
O(logn)
不稳定


归并排序
O(nlogn)
O(nlogn)
O(n)
稳定


堆排序
O(nlogn)
O(nlogn)
O(1)
不稳定



如何选择排序算法？

数据量小（n &lt; 50）：插入排序
数据量大：

要求稳定：归并排序
不要求稳定：快速排序


内存空间有限：堆排序
数据基本有序：插入排序
数据量特别大且有重复：计数排序/基数排序

总结
每种排序算法都有其特点和适用场景。在实际应用中，我们需要根据具体情况（数据规模、稳定性要求、空间限制等）来选择合适的排序算法。大多数编程语言的标准库中的排序实现都是一种改进的快速排序，它能够很好地适应各种情况。
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>排序</tag>
        <tag>冒泡排序</tag>
        <tag>选择排序</tag>
        <tag>插入排序</tag>
        <tag>快速排序</tag>
        <tag>归并排序</tag>
        <tag>堆排序</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习优化器全家桶：从 SGD 到 AdamW 及未来</title>
    <url>/2025/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BC%98%E5%8C%96%E5%99%A8/</url>
    <content><![CDATA[在深度学习的训练过程中，优化器 (Optimizer) 扮演着至关重要的角色。它决定了网络参数更新的方式，直接影响模型的收敛速度和最终性能。本文将深入剖析深度学习中常见的优化器，从最基础的 SGD 到目前最流行的 AdamW，以及一些前沿的变体。
1. 梯度下降家族 (Gradient Descent Variants)
1.1 BGD, SGD 与 Mini-batch SGD

BGD (Batch Gradient Descent)：每次迭代使用全部样本计算梯度。

优点：梯度准确，收敛稳定。
缺点：计算量大，内存无法承受，无法在线更新。


SGD (Stochastic Gradient Descent)：每次迭代使用一个样本。

优点：计算快，引入噪声有助于跳出局部最优。
缺点：震荡剧烈，收敛慢，无法利用向量化加速。


Mini-batch SGD：折中方案，每次使用一批样本（如 32, 64）。这是实际中最常用的形式。
$$ w_{t+1} = w_t - \eta \cdot \nabla L(w_t) $$

1.2 Momentum (动量法)
为了抑制 SGD 的震荡（特别是在峡谷地形），引入了物理学中的动量概念。
$$ v_t = \gamma v_{t-1} + \eta \nabla L(w_t) $$
$$ w_{t+1} = w_t - v_t $$

核心：参数更新方向不仅取决于当前梯度，还保留了之前的速度 $v_{t-1}$。
效果：在梯度方向一致的维度加速，在梯度方向改变的维度减速（抑制震荡）。

1.3 NAG (Nesterov Accelerated Gradient)
Momentum 是“盲目”的冲刺，NAG 则是“先看一眼再走”。
$$ v_t = \gamma v_{t-1} + \eta \nabla L(w_t - \gamma v_{t-1}) $$
$$ w_{t+1} = w_t - v_t $$

区别：NAG 先按动量走一步，计算那个位置的梯度，再修正。这使得 NAG 收敛更快，震荡更小。

2. 自适应学习率家族 (Adaptive Learning Rate)
SGD 系列对所有参数使用相同的学习率，这在稀疏数据或特征频率差异大时效果不佳。
2.1 AdaGrad
$$ G_t = G_{t-1} + g_t^2 $$
$$ w_{t+1} = w_t - \frac{\eta}{\sqrt{G_t + \epsilon}} g_t $$

机制：累积历史梯度的平方和 $G_t$ 作为分母。梯度大的参数，学习率衰减快；梯度小的参数，学习率衰减慢。
缺点：$G_t$ 单调递增，导致学习率过早衰减至 0，训练提前停止。

2.2 RMSProp
为了解决 AdaGrad 的问题，Geoff Hinton 提出了 RMSProp（在 Coursera 课程中提出，未发表论文）。
$$ E[g^2]t = \beta E[g^2]{t-1} + (1-\beta) g_t^2 $$
$$ w_{t+1} = w_t - \frac{\eta}{\sqrt{E[g^2]_t + \epsilon}} g_t $$

机制：使用指数加权移动平均来计算梯度平方和。它只关注“最近”的梯度，解决了学习率过早消失的问题。适合 RNN 等变长序列任务。

2.3 Adadelta
Adadelta 也是为了解决 AdaGrad 学习率递减问题，它甚至不需要设置全局学习率 $\eta$，而是维护一个更新量的移动平均。
3. 集大成者：Adam 及其变体
3.1 Adam (Adaptive Moment Estimation)
Adam = Momentum + RMSProp。它同时利用了一阶矩（均值）和二阶矩（方差）。

计算梯度 $g_t$
更新一阶矩：$m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t$
更新二阶矩：$v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2$
偏差修正：$\hat{m}_t = m_t / (1-\beta_1^t)$, $\hat{v}_t = v_t / (1-\beta_2^t)$
更新参数：$w_{t+1} = w_t - \frac{\eta}{\sqrt{\hat{v}_t} + \epsilon} \hat{m}_t$


特点：收敛快，对超参数不敏感，是目前的默认选择。

3.2 AdaMax
Adam 中 $v_t$ 是基于 $L_2$ 范数的，AdaMax 将其推广到 $L_\infty$ 范数，更加稳定。
3.3 Nadam
Nadam = NAG + Adam。将 Nesterov 动量引入 Adam，理论上收敛速度更快。
4. 现代优化器：修正与进化
4.1 AdamW (Decoupled Weight Decay)
这是目前 Transformer (BERT, ViT, GPT) 的标配。

问题：在 Adam 中，L2 正则化通常直接加在梯度上。但在自适应学习率算法中，这样做会导致正则化效果被学习率缩放，变得不均匀。
解决：AdamW 将权重衰减 (Weight Decay) 从梯度更新中剥离，直接作用于权重：
$$ w_{t+1} = w_t - \eta (\dots) - \eta \lambda w_t $$

4.2 RAdam (Rectified Adam)
Adam 在训练初期，由于样本少，二阶矩估计方差大，导致学习率激增，模型发散。RAdam 通过引入“整流器”机制，在初期自动降低学习率（起到 Warmup 的作用），后期恢复正常。
4.3 Lookahead
被称为“优化器的优化器”。它维护两组权重：快权重 (Fast Weights) 和慢权重 (Slow Weights)。快权重由标准优化器（如 Adam）更新 k 次，然后慢权重向快权重方向迈一步。这大大提高了收敛稳定性。
5. 总结与选型指南



优化器
特点
适用场景




SGD + Momentum
收敛慢但稳，泛化性好
CV (ResNet, VGG)，对精度要求极高的任务


Adam
收敛快，自适应
NLP, RL，快速原型开发


AdamW
修正了权重衰减，训练更稳定
Transformer (BERT, ViT)，生成模型


RMSProp
适合非平稳目标
RNN, LSTM



一句话建议：

搞 CV，先试 SGD + Momentum，再试 AdamW。
搞 NLP/Transformer，无脑上 AdamW。
搞 新手入门，用 Adam。

]]></content>
      <categories>
        <category>算法解析</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>优化器</tag>
        <tag>SGD</tag>
        <tag>Adam</tag>
        <tag>算法详解</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习损失函数：从 MSE 到 Focal Loss</title>
    <url>/2025/12/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/</url>
    <content><![CDATA[在深度学习中，损失函数 (Loss Function) 是连接模型预测与真实标签的桥梁，它定义了模型的优化目标。选择合适的损失函数往往能起到事半功倍的效果。本文将对深度学习中常见的损失函数进行梳理，从基础的回归/分类到进阶的难例挖掘和度量学习。
1. 回归任务 (Regression)
回归任务的目标是预测连续值。
1.1 MSE (L2 Loss)
均方误差 (Mean Squared Error)：
$$ L = (y - \hat{y})^2 $$

特点：收敛快，但对异常值 (Outliers) 非常敏感（因为误差被平方放大了）。

1.2 MAE (L1 Loss)
平均绝对误差 (Mean Absolute Error)：
$$ L = |y - \hat{y}| $$

特点：对异常值鲁棒，但在 0 点处不可导，梯度恒定可能导致收敛困难。

1.3 Smooth L1 Loss
结合了 L1 和 L2 的优点：

在误差较小时（$|x| &lt; 1$）使用 L2（平滑，可导）。
在误差较大时（$|x| \ge 1$）使用 L1（梯度恒定，防止梯度爆炸）。
应用：Faster R-CNN 的边界框回归。

2. 分类任务 (Classification)
2.1 Cross Entropy (CE)
交叉熵损失是分类任务的标准配置：
$$ CE = - \sum y \log(p) $$

本质：衡量两个概率分布的距离（KL 散度）。
局限：对噪声标签敏感，且容易导致模型过度自信 (Over-confidence)。

2.2 Label Smoothing
为了解决 CE 的过度自信，Label Smoothing 将 One-hot 标签软化：
$$ y_{new} = (1 - \epsilon) y + \epsilon / K $$

作用：防止模型在训练集上过拟合，提升泛化能力。

3. 进阶：解决不平衡与难例
当数据存在严重的类别不平衡或大量简单负样本时，标准 CE 往往失效。
3.1 Focal Loss
最初用于目标检测 (RetinaNet)，旨在解决 One-stage 检测器中极端的正负样本失衡。

公式：$FL(p_t) = -\alpha_t (1 - p_t)^\gamma \log(p_t)$
核心机制：

$\gamma$ (Focusing Parameter)：降低易分样本（$p_t \approx 1$）的权重，迫使模型关注难分样本。
$\alpha$ (Balancing Parameter)：平衡正负样本比例。


价值：不仅用于检测，在长尾分类任务中也非常有效。

# Focal Loss PyTorch 实现class FocalLoss(nn.Module):    def __init__(self, alpha=1, gamma=2):        super().__init__()        self.alpha = alpha        self.gamma = gamma            def forward(self, inputs, targets):        ce_loss = F.cross_entropy(inputs, targets, reduction=&#x27;none&#x27;)        pt = torch.exp(-ce_loss)        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss        return focal_loss.mean()
4. 进阶：度量学习 (Metric Learning)
目标是学习一个特征空间，使得同类样本距离近，异类样本距离远。
4.1 Triplet Loss
$$ L = \max(d(a, p) - d(a, n) + margin, 0) $$

输入：三元组 (Anchor, Positive, Negative)。
难点：需要复杂的三元组挖掘 (Triplet Mining) 策略，否则训练效率极低。

4.2 InfoNCE (Contrastive Loss)
自监督学习（如 SimCLR, MoCo）的核心。

思想：将 Triplet 扩展到 N 个负样本，转化为一个 N+1 类的分类问题。
优势：利用大量负样本，学习到的特征更具判别性。



总结

回归：首选 Smooth L1 或 MSE。
分类：首选 Cross Entropy，配合 Label Smoothing。
不平衡/难例：必选 Focal Loss。
特征学习：尝试 InfoNCE 或 Triplet Loss。


]]></content>
      <categories>
        <category>算法解析</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>损失函数</tag>
        <tag>基础理论</tag>
      </tags>
  </entry>
  <entry>
    <title>深度学习杂谈：残差、MAE与特征维度的本质思考</title>
    <url>/2025/11/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%9D%82%E8%B0%88%EF%BC%9A%E6%AE%8B%E5%B7%AE%E3%80%81MAE%E4%B8%8E%E7%89%B9%E5%BE%81%E7%BB%B4%E5%BA%A6%E7%9A%84%E6%9C%AC%E8%B4%A8%E6%80%9D%E8%80%83/</url>
    <content><![CDATA[最近有一些问题，正好记录下来了一些，用AI探讨了一下这些问题。
1. 残差 (Residual) 的本质：仅仅是保留原始信息吗？
问题： 残差的本质是什么？为什么有用？是因为保留了之前的原始信息的特征吗？那么添加动量 (Momentum) 也是保留之前的原始信息，和残差的本质有什么区别吗？
残差连接 (Skip Connection)
残差网络 (ResNet) 的核心公式是 $y = F(x) + x$。
确实，从直观上看，$+x$ 这一项直接将上一层的原始信息“保留”并传递到了下一层。这使得网络在初始化阶段即使 $F(x)$ 接近于 0，整个网络也近似于一个恒等映射 (Identity Mapping)，梯度可以无损地反向传播。
本质区别：

残差 (ResNet) 解决的是 模型结构 (Model Architecture) 和 梯度流 (Gradient Flow) 的问题。它是在空间/层级维度上，让深层网络更容易训练，避免梯度消失。它让网络“有机会”去学习恒等映射，如果某一层是多余的，网络可以将 $F(x)$ 权重置为 0，自动“跳过”这一层。
动量 (Momentum) 解决的是 优化算法 (Optimization) 的问题。它是在时间/迭代维度上，利用历史梯度的加权平均来平滑优化路径。它保留的是“之前的更新方向”，而不是“之前的特征图”。动量帮助优化器冲出局部极小值，加速收敛。

总结： 残差保留的是特征信息（为了更好训练深层网络），动量保留的是梯度惯性（为了更快收敛）。两者作用的维度完全不同。

2. MAE 中 Mask 的作用：仅仅是加噪声吗？
问题： MAE (Masked Autoencoders) 中遮住图片块的作用是什么？可以用到我的项目中吗？
回答：
MAE 中遮住 75% 甚至更多的图片块，确实可以被视为一种极端的数据增强 (Data Augmentation) 或 去噪 (Denoising) 任务。

本质： 它的核心目的不仅仅是防止过拟合，而是强迫模型去学习图像的 全局语义上下文 (Global Semantic Context)。如果只遮住 10%，模型可以通过插值等局部纹理信息轻松复原；但遮住 75%，模型必须“理解”画面——“这里是一只狗的尾巴，那么左边大概率是狗的身体”，这种推理需要高层的语义理解。
缺点： 正如你所说，训练非常慢，需要大量的计算资源和数据量才能收敛出好的特征。
能否用于你的项目：

能用： 如果你的任务是自监督预训练 (Self-supervised Pre-training)，且有大量无标签数据，MAE 是非常好的特征提取器。
慎用： 如果你的数据集很小，或者直接在监督任务中作为一种 Augmentation 手段（即输入 Mask 后的图直接做分类），效果可能适得其反，因为丢失了太多信息。



启示： 找经典论文中的方法，要看它解决的根本矛盾是什么。MAE 解决的是 Vision Transformer 如何高效利用无标签数据进行预训练的问题。

3. 特征维度：越高越好吗？
问题： 特征维度越高会不会表征能力越强呢？
回答：
理论上，高维空间能容纳更复杂的信息，但这有一个边际效应递减甚至负面效应的问题：

维度灾难 (Curse of Dimensionality)： 随着维度增加，数据在空间中会变得极度稀疏。为了填满高维空间，所需的数据量是指数级增长的。如果数据量不够，高维特征极易导致过拟合。
流形假设 (Manifold Hypothesis)： 真实世界的图像虽然像素维度很高（如 224x224x3），但它们通常分布在一个低维的流形上。我们希望模型学到的是这个“低维流形”的坐标，而不是简单地把维度撑大。
计算冗余： 过高的维度带来巨大的计算和存储开销。

结论： 维度不是越高越好，而是**“足够表达且紧凑”**最好。通常在 ResNet50 中 2048 维已经非常丰富，很多轻量级模型 512 维甚至 128 维也能达到很好的效果。

4. 编码器后的 MLP (Projection Head)：神来之笔？
问题： 在编码器后边加一个单独的 MLP 层为什么会起作用，数学原理是什么？我在我的算法后边加入 Non-linear 试一下。
回答：
这在对比学习（如 SimCLR, BYOL）中非常常见。

现象： 训练时加上 MLP (Projection Head) 计算 Loss，但在下游任务（如分类）时去掉 MLP，直接用 Encoder 的输出，效果反而更好。
原理 (Information Bottleneck)：

对比学习的目标是让增强后的两个视图特征尽可能一致（Invariant）。
但是，数据增强（如裁剪、变色）会引入一些与物体类别无关的变换信息。
MLP 的作用是作为一个“缓冲区”或“过滤器”。它负责去适应这些变换（吸收掉与下游任务无关的增强信息），从而保护 Encoder 学到的特征保持纯粹的语义不变性。
如果直接用 Encoder 输出算 Loss，Encoder 就被迫去拟合这些变换，导致特征中混入了噪音。



建议： 在你的算法后加入 Non-linear Projection Head (Linear -&gt; ReLU -&gt; Linear) 绝对值得一试！特别是在做特征对齐、对比学习或度量学习的任务中，这往往能带来几个点的提升。


思考总结：
深度学习的很多“黑魔法”，背后往往对应着对信息流、梯度流或优化曲面的某种直觉性的修正。多问几个“为什么”，尝试用不同的视角（如信息论、优化理论）去解释，是进阶的关键。

]]></content>
      <categories>
        <category>学术思考</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>计算机视觉</tag>
        <tag>论文笔记</tag>
        <tag>思考</tag>
      </tags>
  </entry>
  <entry>
    <title>监督对比学习</title>
    <url>/2025/11/%E7%9B%91%E7%9D%A3%E5%AF%B9%E6%AF%94%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[Supervised Contrastive Learning
论文地址：https://arxiv.org/pdf/2004.11362
代码地址：https://github.com/HobbitLong/SupContrast
引言
监督对比学习（Supervised Contrastive Learning, SupCon） 是2020年提出的一种结合监督学习和对比学习优势的深度学习方法。与传统的交叉熵损失相比，SupCon通过显式地拉近同类样本、推远异类样本，在图像分类、鲁棒性学习等任务上取得了显著提升。
为什么需要监督对比学习？
传统交叉熵损失的局限：


只关注分类边界

交叉熵只要求正确分类，不关心特征空间的结构
导致同类样本在特征空间可能很分散
决策边界可能过于接近某些样本



忽略类间关系

将所有错误分类同等对待
&quot;猫被分类为狗&quot;和&quot;猫被分类为汽车&quot;的惩罚相同
无法利用类别间的语义相似性



对噪声标签敏感

错误标签直接影响分类边界
难以从噪声中恢复



监督对比学习的优势：


更好的特征空间结构

同类样本紧密聚集
不同类样本明确分离
形成清晰的聚类结构



更强的鲁棒性

对标签噪声更鲁棒
对对抗样本更鲁棒
更好的泛化能力



灵活的应用

可以自然处理开放集识别
支持少样本学习
便于增量学习新类别



方法对比



特性
交叉熵损失
监督对比损失




优化目标
分类准确率
特征空间结构


类内约束
无
拉近同类样本


类间约束
间接（通过分类）
直接推远异类


特征分布
可能分散
紧密聚类


鲁棒性
一般
更强


计算复杂度
O(NC)
O(N²)



其中N是batch size，C是类别数。
背景知识
对比学习简介
对比学习的核心思想是：通过对比正样本对和负样本对，学习到区分性的表示。
无监督对比学习（如SimCLR、MoCo）：

正样本：同一图像的不同增强视图
负样本：不同图像的增强视图
目标：学习到对数据增强不变的表示

关键挑战：

需要大量负样本才能学到好的表示
对数据增强策略敏感
可能学到与下游任务无关的特征

监督学习与对比学习的结合
传统监督学习（交叉熵）：

只关注样本与标签的匹配
忽略了同类样本间的相似性
对对抗样本和噪声不够鲁棒

监督对比学习的优势：

利用标签信息，正样本对更明确（同类样本）
负样本对更丰富（所有异类样本）
学习到的表示更具判别性和鲁棒性

论文核心思想
主要贡献

提出监督对比损失（Supervised Contrastive Loss）：将标签信息融入对比学习框架
理论分析：证明了SupCon损失的梯度特性优于交叉熵
实验验证：在ImageNet等数据集上取得SOTA性能，并显著提升鲁棒性

核心创新
关键洞察：在监督学习中，同类样本应该聚集在一起，异类样本应该分离。这与对比学习的目标天然一致。
方法：将同一类别的所有样本视为正样本，不同类别的样本视为负样本，构建对比学习目标。
方法原理
监督对比损失（Supervised Contrastive Loss）
给定一个batch的样本 ${x_1, x_2, …, x_N}$ 及其标签 ${y_1, y_2, …, y_N}$，对每个样本 $x_i$：
$$ 
\mathcal{L}_{sup} = \sum_{i=1}^{N} \mathcal{L}_{sup}^i
$$ 
其中：
$$ 
\mathcal{L}_{sup}^i = -\frac{1}{|P(i)|} \sum_{p \in P(i)} \log \frac{\exp(z_i \cdot z_p / \tau)}{\sum_{a \in A(i)} \exp(z_i \cdot z_a / \tau)}
$$ 
符号说明：

$z_i = f(x_i)$：样本 $x_i$ 的归一化特征表示
$P(i) = {p \in A(i): y_p = y_i}$：与 $x_i$ 同类的样本集合（正样本）
$A(i) = {1, 2, …, N} \backslash {i}$：除 $i$ 外的所有样本（正样本+负样本）
$\tau$：温度参数，控制分布的尖锐程度

直观理解：

分子：拉近同类样本的相似度
分母：推远所有样本（包括异类和同类）的相似度
归一化：确保同类样本的贡献相等（$\frac{1}{|P(i)|}$）

与交叉熵损失的对比
交叉熵损失：
$$ 
\mathcal{L}_{CE} = -\log \frac{\exp(W_{y_i}^T z_i)}{\sum_{j=1}^{C} \exp(W_j^T z_i)}
$$ 
关键区别：



特性
交叉熵
监督对比损失




优化目标
样本与分类器权重匹配
样本间相似性


梯度特性
只关注当前样本
同时考虑所有同类/异类样本


表示学习
间接（通过分类器）
直接（样本间关系）


鲁棒性
较弱
更强



训练流程

数据增强：对每个样本应用两次随机增强，得到两个视图
特征提取：使用编码器 $f(\cdot)$ 提取特征
归一化：对特征进行L2归一化
计算损失：使用监督对比损失
反向传播：更新编码器参数

注意：SupCon可以单独使用，也可以与交叉熵损失结合使用。
损失函数详解
温度参数 $\tau$ 的作用

$\tau$ 较小：分布更尖锐，模型更关注困难样本
$\tau$ 较大：分布更平滑，模型对所有样本的关注更均匀
典型取值：0.07 或 0.1

梯度分析
SupCon损失的梯度特性：
$$ 
\frac{\partial \mathcal{L}_{sup}^i}{\partial z_i} = \frac{1}{\tau} \left[ \sum_{p \in P(i)} \frac{z_p}{|P(i)|} - \sum_{a \in A(i)} w_a z_a \right]
$$ 
其中 $w_a$ 是softmax权重。
关键观察：

梯度包含所有同类样本的平均（第一项）
梯度包含所有样本的加权平均（第二项）
这比交叉熵只关注单个样本-权重匹配更丰富

与InfoNCE的关系
SupCon可以看作监督版本的InfoNCE：

InfoNCE：正样本是同一图像的不同增强
SupCon：正样本是同一类别的所有样本

实验分析
数据集
论文在多个数据集上进行了实验：

ImageNet：大规模图像分类基准
CIFAR-10/100：小规模图像分类
STL-10：无监督/半监督学习基准

实验设置
网络架构：

ResNet-50/200 作为backbone
投影头：2层MLP（2048→128）

训练细节：

优化器：LARS（ImageNet）或SGD
学习率：0.3（ImageNet）或0.1（CIFAR）
Batch size：1024（ImageNet）或256（CIFAR）
温度参数：$\tau = 0.07$
数据增强：RandomResizedCrop、ColorJitter、RandomHorizontalFlip等

实验结果
ImageNet分类性能：



方法
Top-1 Acc
Top-5 Acc




Cross-Entropy
76.5%
93.1%


SupCon
78.0%
93.8%


SupCon + CE
78.4%
94.0%



鲁棒性提升：

对对抗攻击的鲁棒性显著提升
对常见数据损坏（噪声、模糊等）的鲁棒性更好
在长尾分布数据集上表现更优

消融实验：

温度参数 $\tau$：0.07 效果最好
投影头维度：128维足够
数据增强：重要，但SupCon对增强策略的敏感性低于无监督对比学习

代码实现
PyTorch实现
import torchimport torch.nn as nnimport torch.nn.functional as Fclass SupConLoss(nn.Module):    &quot;&quot;&quot;Supervised Contrastive Learning Loss&quot;&quot;&quot;        def __init__(self, temperature=0.07, base_temperature=0.07):        super().__init__()        self.temperature = temperature        self.base_temperature = base_temperature    def forward(self, features, labels):        &quot;&quot;&quot;        Args:            features: hidden vector of shape [bsz, n_views, ...] or [bsz * n_views, ...].            labels: ground truth of shape [bsz].        Returns:            A loss scalar.        &quot;&quot;&quot;        device = features.device                # 如果features是[batch_size, n_views, dim]，reshape为[batch_size * n_views, dim]        if len(features.shape) &lt; 3:            features = features.unsqueeze(1)        batch_size = features.shape[0]                if labels is not None:            # 扩展labels以匹配增强后的样本数            labels = labels.contiguous().view(-1, 1)            if labels.shape[0] != batch_size:                raise ValueError(&#x27;Num of labels does not match num of features&#x27;)            mask = torch.eq(labels, labels.T).float().to(device)        else:            # 无监督情况：同一图像的增强视图为正样本            mask = torch.eye(batch_size, dtype=torch.float32).to(device)                # 归一化特征        features = F.normalize(features, dim=-1)                # 计算相似度矩阵        contrast_feature = features        anchor_feature = features                # 计算所有样本对之间的相似度        anchor_dot_contrast = torch.div(            torch.matmul(anchor_feature, contrast_feature.T),            self.temperature        )                # 数值稳定性：减去最大值        logits_max, _ = torch.max(anchor_dot_contrast, dim=1, keepdim=True)        logits = anchor_dot_contrast - logits_max.detach()                # 计算exp        exp_logits = torch.exp(logits)                # 计算log_prob        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True))                # 计算每个样本的正样本平均log_prob        mask = mask.repeat(1, 1)  # 扩展mask以匹配batch_size        mean_log_prob_pos = (mask * log_prob).sum(1) / mask.sum(1)                # 损失        loss = - (self.temperature / self.base_temperature) * mean_log_prob_pos        loss = loss.mean()                return loss# 使用示例class SupConModel(nn.Module):    def __init__(self, encoder, projection_dim=128):        super().__init__()        self.encoder = encoder        self.projector = nn.Sequential(            nn.Linear(encoder.fc.in_features, 2048),            nn.ReLU(),            nn.Linear(2048, projection_dim)        )        # 移除分类头（如果存在）        if hasattr(encoder, &#x27;fc&#x27;):            self.encoder.fc = nn.Identity()        def forward(self, x):        features = self.encoder(x)        projections = self.projector(features)        return F.normalize(projections, dim=-1)# 训练循环示例def train_step(model, images, labels, criterion, optimizer):    # 假设images已经是增强后的[batch_size, 2, C, H, W]    batch_size = images.shape[0]    images = images.view(batch_size * 2, *images.shape[2:])        # 前向传播    features = model(images)    features = features.view(batch_size, 2, -1)        # 计算损失    loss = criterion(features, labels)        # 反向传播    optimizer.zero_grad()    loss.backward()    optimizer.step()        return loss.item()
简化版本
def supervised_contrastive_loss(features, labels, temperature=0.07):    &quot;&quot;&quot;    简化版监督对比损失        Args:        features: [batch_size, feature_dim] 归一化特征        labels: [batch_size] 标签        temperature: 温度参数    &quot;&quot;&quot;    device = features.device    batch_size = features.shape[0]        # 计算相似度矩阵    similarity_matrix = torch.matmul(features, features.T) / temperature        # 构建正样本mask（同类样本）    labels = labels.contiguous().view(-1, 1)    mask = torch.eq(labels, labels.T).float().to(device)        # 移除自身    logits_mask = torch.scatter(        torch.ones_like(mask),        1,        torch.arange(batch_size).view(-1, 1).to(device),        0    )    mask = mask * logits_mask        # 计算exp    exp_logits = torch.exp(similarity_matrix) * logits_mask        # 计算log_prob    log_prob = similarity_matrix - torch.log(exp_logits.sum(1, keepdim=True) + 1e-8)        # 平均正样本的log_prob    mean_log_prob_pos = (mask * log_prob).sum(1) / (mask.sum(1) + 1e-8)        # 损失    loss = -mean_log_prob_pos.mean()        return loss
技术细节与优化
数据增强策略
SupCon对数据增强的依赖低于无监督对比学习，但仍需要合理的增强：
推荐增强：

RandomResizedCrop
RandomHorizontalFlip
ColorJitter（适度）
RandomGrayscale（可选）

避免过度增强：过度增强可能破坏语义信息，反而降低性能。
投影头设计

层数：2层MLP通常足够
维度：128-256维
激活函数：ReLU或GELU
归一化：输出层L2归一化

温度参数调优

起始值：0.07
调优范围：0.05 - 0.2
原则：如果模型难以区分困难样本，降低$\tau$；如果训练不稳定，提高$\tau$

优缺点分析
优点

性能提升：在多个数据集上超越交叉熵损失
鲁棒性强：对对抗样本、噪声、数据损坏更鲁棒
表示质量高：学习到的特征更具判别性和泛化能力
易于实现：损失函数简单，易于集成到现有框架

缺点

计算成本：需要计算所有样本对的相似度，batch size较大时内存消耗高
需要标签：相比无监督对比学习，需要标注数据
超参数敏感：温度参数等需要仔细调优

与其他方法的关系
vs. 交叉熵损失

交叉熵：关注样本-分类器匹配
SupCon：关注样本-样本关系
结合使用：SupCon + CE 通常效果最好

vs. 无监督对比学习

SimCLR/MoCo：正样本是同一图像的不同视图
SupCon：正样本是同一类别的所有样本
优势：SupCon利用标签信息，正样本对更明确

vs. 三元组损失

三元组损失：每次只考虑一个正样本和一个负样本
SupCon：同时考虑所有正样本和负样本
优势：SupCon的梯度更稳定，训练更高效

应用场景

图像分类：提升分类精度和鲁棒性
长尾学习：在类别不平衡数据上表现优异
少样本学习：学习到的表示泛化能力强
鲁棒性训练：提升模型对对抗攻击的防御能力

总结
监督对比学习通过将标签信息融入对比学习框架，成功结合了监督学习和对比学习的优势。其核心思想是：同类样本应该聚集，异类样本应该分离。通过显式优化样本间的相似性关系，SupCon学习到的表示更具判别性、鲁棒性和泛化能力。
SupCon的提出证明了对比学习不仅适用于无监督场景，在监督学习中同样有效，为后续的对比学习研究提供了重要启发。
参考文献


Khosla, P., et al. (2020). Supervised Contrastive Learning. Advances in Neural Information Processing Systems, 33. https://arxiv.org/pdf/2004.11362


Chen, T., et al. (2020). A Simple Framework for Contrastive Learning of Visual Representations. ICML 2020.


He, K., et al. (2020). Momentum Contrast for Unsupervised Visual Representation Learning. CVPR 2020.


Hadsell, R., Chopra, S., &amp; LeCun, Y. (2006). Dimensionality reduction by learning an invariant mapping. CVPR 2006.


思考题

为什么监督对比学习比交叉熵损失更能提升模型的鲁棒性？
温度参数 $\tau$ 如何影响模型的学习？如何选择合适的 $\tau$？
在类别数量很多的情况下，SupCon损失的计算复杂度如何？如何优化？
SupCon与交叉熵损失结合使用时，如何平衡两者的权重？
监督对比学习在少样本学习场景下的优势是什么？

思考题答案
1. 为什么监督对比学习比交叉熵损失更能提升模型的鲁棒性？
原因分析：


表示学习方式不同：

交叉熵：只关注样本与分类器权重的匹配，可能学到与分类器相关的脆弱特征
SupCon：直接优化样本间的相似性，学习到更本质的表示



梯度特性：

交叉熵：梯度只来自当前样本与分类器的匹配
SupCon：梯度来自所有同类和异类样本，信息更丰富，训练更稳定



特征空间结构：

交叉熵：可能形成不规则的决策边界
SupCon：显式地拉近同类、推远异类，形成更紧凑的类内分布和更大的类间间隔



对噪声的鲁棒性：

SupCon通过对比学习，模型学会关注样本间的相对关系而非绝对特征，对噪声更鲁棒



2. 温度参数 $\tau$ 如何影响模型的学习？如何选择合适的 $\tau$？
$\tau$ 的影响：


$\tau$ 较小（如0.05）：

分布更尖锐，模型更关注困难样本（hard negatives）
学习到的表示区分性更强
但可能训练不稳定，容易过拟合



$\tau$ 较大（如0.2）：

分布更平滑，对所有样本的关注更均匀
训练更稳定
但可能学习到的表示区分性较弱



选择策略：

起始值：从0.07开始（论文推荐值）
观察训练曲线：

如果损失下降很快但验证集性能差 → 降低$\tau$
如果训练不稳定或损失不下降 → 提高$\tau$


网格搜索：在[0.05, 0.1, 0.15, 0.2]范围内搜索
任务相关：

细粒度分类（类别相似度高）→ 较小的$\tau$
粗粒度分类（类别差异大）→ 较大的$\tau$



3. 在类别数量很多的情况下，SupCon损失的计算复杂度如何？如何优化？
复杂度分析：

时间复杂度：$O(N^2 \cdot d)$，其中$N$是batch size，$d$是特征维度
空间复杂度：$O(N^2)$（相似度矩阵）

优化策略：


减小batch size：

使用梯度累积保持有效batch size
或使用负样本采样（但会损失部分性能）



混合精度训练：

使用FP16/BF16降低内存和计算成本



分布式训练：

将batch分散到多个GPU，每个GPU计算部分损失



近似方法：

只计算部分负样本（如hard negative mining）
使用memory bank存储历史特征（类似MoCo）



损失近似：

使用NCE（Noise Contrastive Estimation）近似
或使用采样方法估计分母



4. SupCon与交叉熵损失结合使用时，如何平衡两者的权重？
结合方式：
$$ 
\mathcal{L}_{total} = \lambda_{sup} \mathcal{L}_{sup} + \lambda_{ce} \mathcal{L}_{ce}
$$ 
权重选择策略：


等权重：$\lambda_{sup} = \lambda_{ce} = 1.0$（常见起始点）


动态调整：

早期训练：$\lambda_{sup}$较大，学习好的表示
后期训练：$\lambda_{ce}$较大，微调分类边界



任务相关：

如果表示学习更重要（如few-shot）→ 增大$\lambda_{sup}$
如果分类精度更重要 → 增大$\lambda_{ce}$



实验验证：

在验证集上搜索：$\lambda_{sup} \in [0.5, 1.0, 1.5, 2.0]$
通常$\lambda_{sup} = 1.0, \lambda_{ce} = 0.5$效果较好



注意事项：

两个损失的尺度可能不同，需要归一化或调整权重
可以先用SupCon预训练，再用CE微调

5. 监督对比学习在少样本学习场景下的优势是什么？
优势分析：


更好的表示学习：

SupCon学习到的特征更具判别性和泛化能力
即使样本少，也能学到类别的本质特征



类内紧凑性：

显式拉近同类样本，形成紧凑的类内分布
在少样本情况下，这有助于减少类内方差



类间分离性：

显式推远异类样本，增大类间间隔
在少样本情况下，这有助于提高分类精度



数据效率：

每个样本都参与多个正样本对和负样本对的学习
充分利用有限的标注数据



泛化能力：

学习到的表示对数据增强、噪声等更鲁棒
在测试时遇到新样本时泛化更好



实际应用：

在few-shot learning中，先用SupCon在base classes上预训练
然后在novel classes上用few-shot learning方法微调
通常能取得比直接使用交叉熵更好的效果

]]></content>
      <categories>
        <category>论文精读</category>
        <category>计算机视觉</category>
      </categories>
      <tags>
        <tag>对比学习</tag>
        <tag>深度学习</tag>
        <tag>监督学习</tag>
      </tags>
  </entry>
  <entry>
    <title>基础知识--线性表</title>
    <url>/2025/02/%E7%BA%BF%E6%80%A7%E8%A1%A8/</url>
    <content><![CDATA[线性表
线性表是⼀对⼀的逻辑结构，线性表中除了表头元素每个元素有且仅有唯⼀⼀个前驱元素，除了表尾元素，每个结点都有唯⼀⼀个后继节点。
顺序存储（顺序表）
存取
顺序表随机存取，存取某个元素的时间复杂度为O(1)。
查找
平均时间复杂度O(n)
插入删除
平均时间复杂度O(n)，删除插⼊元素需要移动⼤量元素。（如果是删除最后⼀个元素或者在最后⼀个节点后⾯插⼊⼀个新的节点，则复杂度为O(1)，因为不需要移动元素）
链式存储（链表）
链表因其链状的结构，能方便地删除、插入数据，操作次数是 O(1)。但也因为这样，寻找、读取数据的效率不如数组高，在随机访问数据中的操作次数是 O(n)。
单链表
单链表的基本组成单元是节点 (Node)。 每个节点通常包含两个主要部分：

数据域 (Data): 用于存储实际的数据元素。 数据域可以是任何数据类型，例如整数、浮点数、字符、字符串，甚至更复杂的数据结构。
指针域 (Pointer) 或 下一个节点指针 (Next Pointer):  用于存储指向链表中下一个节点的地址（或引用）。  对于单链表，每个节点只有一个指针，指向它后面的节点。  链表的最后一个节点的指针域通常指向一个特殊值，表示链表的末尾，这个特殊值通常是 空指针 (NULL 或 None)。

创建链表
**头插法：**每次在链表头结点后⾯插⼊新的结点。头插法的元素顺序与插⼊顺序相反，类似于栈。
**尾插法：**每次在链表的尾结点插⼊新的结点，并且是尾结点更新（使尾指针指向新的尾结点）。尾插法得到的顺序与插⼊顺序相同，类似于队列。
查找
查找方式是线性的，平均和最坏情况下的时间复杂度均为 O(n)，其中 n 是链表中的节点数。
插入删除
在链表中插入或删除节点，通常只需要修改指针的指向，而不需要像数组那样移动大量的元素（特别是插入和删除中间位置的元素时）。  时间复杂度通常为 O(1) (在已知插入/删除位置的前驱节点的情况下)。
单链表的缺点

访问效率较低:  要访问链表中的某个特定节点，必须从头节点开始顺序遍历，直到找到目标节点。  无法像数组那样通过索引直接访问，访问时间复杂度为 O(n)，其中 n 是链表的长度。
存储开销:  每个节点除了存储数据外，还需要额外的空间存储指针，增加了存储开销。
不适合随机访问: 由于只能顺序访问，链表不适合需要频繁随机访问的应用场景。

双链表
双链表的节点 (Node) 结构在单链表的基础上增加了一个前驱指针：

前驱指针域 (Previous Pointer):  存储指向链表中前一个节点的地址（或引用）。 链表的头节点 (Head) 的前驱指针通常指向一个特殊值，表示链表头部，这个值通常是 空指针 (NULL 或 None)。
数据域 (Data):  与单链表相同，用于存储数据元素。
后继指针域 (Next Pointer):  与单链表相同，存储指向链表中下一个节点的地址（或引用）。 链表的尾节点 (Tail) 的后继指针通常指向一个特殊值，表示链表尾部，这个值通常是 空指针 (NULL 或 None)。

创建链表
创建一个空的双链表，通常将头指针和尾指针都初始化为 NULL。
查找
与单链表类似，双链表的查找也是线性的，时间复杂度为 O(n)。
双链表的优点

双向遍历:  可以从头到尾，也可以从尾到头双向遍历，提高了数据访问的灵活性。
删除节点更高效:  删除节点时，特别是删除中间节点和尾节点时，由于有前驱指针，可以更方便地找到前一个节点，无需像单链表那样需要从头开始遍历找到前驱节点。 这在某些情况下可以提高删除操作的效率。
某些操作更方便:  例如，在已知节点指针的情况下，插入和删除操作更加直接，不需要总是从头开始查找前驱节点。

双链表的缺点

存储开销更大:  每个节点需要额外的空间存储前驱指针，相比单链表，存储相同的数据需要更多的内存。
插入和删除操作更复杂:  虽然删除操作效率更高，但插入和删除操作的代码逻辑相对单链表来说更复杂，需要维护更多的指针关系（前驱和后继指针都需要更新）。
访问效率仍然较低:  虽然可以双向遍历，但访问链表中的特定节点仍然需要顺序遍历，随机访问效率仍然不如数组。

]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>链表</tag>
        <tag>线性表</tag>
      </tags>
  </entry>
  <entry>
    <title>基础知识--绪论</title>
    <url>/2025/02/%E7%BB%AA%E8%AE%BA/</url>
    <content><![CDATA[绪论
数据结构
数据结构是一门研究非数值计算程序设计中的操作对象，以及这些对象之间的关系和操作的学科。
逻辑结构
线性结构
一般线性表：线性表
特殊线性表：栈、队列、字符串
线性表的推广：数组、广义表
非线性结构
树结构：树、二叉树
图结构：有向图、无向图
集合结构
存储结构
顺序存储
逻辑上连续，物理上连续
优点：

随机访问高效：通过下标可直接访问元素，时间复杂度为 O(1)。
内存连续，缓存友好：数据连续存放，充分利用 CPU 缓存机制，访问效率高。
空间开销小：仅需存储数据，无需额外指针字段，内存利用率高。

缺点：

插入/删除效率低：在中间或头部操作时，需移动大量元素，时间复杂度为 O(n)。
固定容量：需预先分配连续内存空间，扩容需复制全部数据，动态扩展成本高。
内存浪费：若预分配空间过大，可能造成内存冗余。

链式存储
逻辑上不要求连续，物理上⼀定连续
优点：

动态内存分配：无需预先分配固定空间，按需动态扩展，内存利用率高。
插入/删除高效：仅需修改指针指向，时间复杂度为 O(1)（需先定位到操作位置）。
灵活性强：支持多种衍生结构（如双向链表、循环链表）。

缺点：


无法随机访问：查找元素需从头遍历，时间复杂度为 O(n)。


额外空间开销：每个节点需存储指针字段，占用更多内存。


内存碎片化：节点非连续存储，缓存命中率低，访问速度较慢。


算法的效率
算法是为了解决某类问题而规定的一个有限长的操作序列。
算法时间复杂度
一般情况，算法中基本语句重复执行的次数是问题规模n的某个函数f(n)，算法的时间量记作: T(n)=O(f(n))
算法空间复杂度
所⽤到的临时空间⼤⼩
]]></content>
      <categories>
        <category>数据结构与算法</category>
      </categories>
      <tags>
        <tag>数据结构与算法</tag>
        <tag>绪论</tag>
      </tags>
  </entry>
  <entry>
    <title>视觉表征学习综述：从像素到因果的认知飞跃</title>
    <url>/2025/12/%E8%A7%86%E8%A7%89%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/</url>
    <content><![CDATA[在计算机视觉领域，表征学习 (Representation Learning) 始终是核心问题。如何将原始的像素信息 (Pixels) 转换为具有高层语义的特征向量 (Features)，决定了下游任务（如分类、检测、分割）的性能上限。一个强大的视觉表征能够消除数据冗余，凸显语义信息，从而支持高级认知任务。高级视觉表征必须能够编码时空动态和因果关系，而非仅限于对静态对象身份的识别。
本文将结合最新的学术进展，全面梳理视觉表征学习的评估、演进、应用及未来挑战。
1. 视觉表征的评估体系
如何定义一个“好”的表征？通常通过下游任务的性能来量化：

目标检测 (Object Detection)：在 COCO 或 Pascal VOC 数据集上评估 mAP (mean Average Precision)，衡量检测准确度和定位精度。
图像分割 (Image Segmentation)：在 ADE20K 等数据集上评估 mIoU (mean Intersection over Union)，衡量像素级的边界贴合度和精度。
通用特征质量 (General Feature Quality)：通过 Linear Probing（冻结骨干网络，仅训练线性分类器）或 Fine-tuning 来评估。这衡量了特征的可迁移性 (Transferability) 和内在的语义可分性。

2. 迁移学习与特征泛化
视觉表征的真正价值，不在于其在训练数据上的表现，而在于其泛化能力。
迁移学习 (Transfer Learning) 是解决特定任务中标注数据稀缺的关键。一个高度鲁棒的表征必须能够封装广泛适用的知识，使得在各种领域和任务中只需进行最少的微调。研究表明，利用 ViTs 和 CNNs 进行的迁移学习能够高效提取特征，即使在极具挑战性的少样本 (Few-shot) 场景中，也能准确估计几何变换。
3. 主流范式演进
3.1 监督与自监督

监督学习：以 ResNet 为代表，依赖大规模标注数据。
自监督学习 (SSL)：

对比学习 (SimCLR, MoCo)：学习实例判别和不变性。
掩码图像建模 (MAE, BEiT)：学习上下文重建和完备性。



3.2 拓展维度：时空与因果

时空表征：VideoMAE 等方法证明了在视频中进行高比例掩码重建是高效的时空特征学习器。
因果表征：旨在发现数据背后的因果结构变量，提升模型在分布外 (OOD) 数据上的鲁棒性。

4. 高影响力应用场景
强大的视觉表征是推动现代 AI 应用突破的核心动力。
4.1 核心视觉任务
基于 CNNs 和 Transformer 的架构支持了自动驾驶的环境感知、机器人的复杂导航以及安全系统的威胁识别。目标检测不仅分类，还能精确定位，是这些系统的基石。
4.2 跨模态系统与检索
视觉语言模型 (VLMs) 桥接了文本和视觉数据，支持跨模态检索和视觉问答 (VQA)。这种能力使系统能够像人类一样，同时理解和关联不同形式的信息。
4.3 医疗影像与健康 (Medical Imaging)
多模态大语言模型 (MLLMs) 正在彻底改变放射学。

应用：结合 2D X射线、3D CT/MRI 和临床文本，自动生成放射学报告、进行 VQA 和交互式诊断支持。
挑战：在高风险临床环境中，仅有准确性是不够的。MLLMs 面临**“幻觉” (Hallucination)** 风险、决策缺乏透明度以及高计算需求等挑战。
方向：未来的重点是区域定位推理 (Region-grounded Reasoning)，即将模型输出明确链接到图像中的特定区域，以提高临床信任度。

5. 当前挑战
尽管进步巨大，但仍存在关键瓶颈：

效率与可扩展性：向大型基础模型 (Foundation Models) 的转变带来了巨大的计算需求，限制了其在实时检索等场景的部署。随着 ViTs 取代 CNNs，开发参数高效 (Parameter-efficient) 的学习方法至关重要。
数据与标注鸿沟：收集和标注均衡的多模态数据（包含文本、图像、视频）极其困难，且主观因素（如情绪判断）使标注更加复杂。
迁移能力限制：在一个数据类型上训练的模型，在面对不同模态输入时性能可能下降。

6. 未来趋势与战略建议
6.1 通用基础模型 (Universal Representation)
受 GPT-4 启发，视觉领域正探索通用感知表征。

Vision Bridge 等框架旨在通过基于流的建模，将图像块标记与基础视觉任务（分类、检测、分割、深度估计）连接起来。
目标：实现任务无关 (Task-agnostic) 的表征学习，无需引入外部数据即可实现强大的跨领域零样本迁移。

6.2 战略建议

架构权衡：

大规模数据 &amp; 全局理解：优先选择 Vision Transformers (ViT)。
资源受限 &amp; 小数据集：利用 CNNs 的强归纳偏置，或采用混合自监督策略（如 AC-MAE），融合对比损失以增强 ViT 在低数据量下的性能。


效率优化：重点设计更有效的训练方法，优化多模态数据融合技术（早期、晚期及混合融合）。
临床集成：在医疗领域，必须将重点放在增强透明度和可信度上，通过区域定位推理确保安全集成。



结语
视觉表征学习正处于从“单任务模型”向“通用基础模型”转型的关键时期。未来的表征将更加通用、高效，并能安全地服务于医疗等关键领域。

]]></content>
      <categories>
        <category>学术笔记</category>
      </categories>
      <tags>
        <tag>深度学习</tag>
        <tag>计算机视觉</tag>
        <tag>表征学习</tag>
        <tag>迁移学习</tag>
        <tag>多模态</tag>
        <tag>医疗AI</tag>
      </tags>
  </entry>
</search>
